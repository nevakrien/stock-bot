{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "84595fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_STOCKS=10\n",
    "import yahoo_fin as yf\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afa2b0",
   "metadata": {},
   "source": [
    "# getting data\n",
    "\n",
    "things we did to clean data:\n",
    "\n",
    "1. shamelessly copy:\n",
    "https://levelup.gitconnected.com/how-to-get-all-stock-symbols-a73925c16a1b\n",
    "\n",
    "2. we removed the tickers with $\n",
    "\n",
    "3. we added exception handeling that tries similer strings to the input (note that this is not implemented on the set itself but when fetching, leading to multiple requsts and potentialy to errors)\n",
    "4.  we just drop exceptions that are found when getting the data from online  (these are diffrent every day)\n",
    "\n",
    "# how are we keeping consistency? \n",
    "since the avilble stocks may change depending on the source of the data some extra steps need to be done in order to\n",
    "alow saves to work seemlesly \n",
    "\n",
    "\n",
    "basic plan:\n",
    "\n",
    "1. clean the data as much as possible \n",
    "\n",
    "2. save the embedings weights with their ticker string\n",
    "\n",
    "3. backup everything on git to alow us to fix it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0bece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame( si.tickers_sp500() )\n",
    "df2 = pd.DataFrame( si.tickers_nasdaq() )\n",
    "df3 = pd.DataFrame( si.tickers_dow() )\n",
    "df4 = pd.DataFrame( si.tickers_other() )\n",
    "\n",
    "sym1 = set( symbol for symbol in df1[0].values.tolist() )\n",
    "sym2 = set( symbol for symbol in df2[0].values.tolist() )\n",
    "sym3 = set( symbol for symbol in df3[0].values.tolist() )\n",
    "sym4 = set( symbol for symbol in df4[0].values.tolist() )\n",
    "\n",
    "symbols = set.union( sym1, sym2, sym3, sym4 )\n",
    "del(sym1, sym2, sym3, sym4,df1, df2, df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469a803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1584 unqualified stock symbols...\n",
      "There are 10628 qualified stock symbols...\n"
     ]
    }
   ],
   "source": [
    "my_list = ['W', 'R', 'P', 'Q']\n",
    "del_set = set()\n",
    "sav_set = set()\n",
    "\n",
    "for symbol in symbols:\n",
    "    if (len( symbol ) > 4 and symbol[-1] in my_list or \"$\" in symbol):\n",
    "        del_set.add( symbol )\n",
    "    else:\n",
    "        sav_set.add( symbol )\n",
    "sav_set.discard(\"\") \n",
    "\n",
    "ticker_list=list(sav_set)\n",
    "\n",
    "print( f'Removed {len( del_set )} unqualified stock symbols...' )\n",
    "print( f'There are {len( sav_set )} qualified stock symbols...' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d42362",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='01/01/2020' \n",
    "end='09/14/2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3c39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "\n",
    "def get_seiries(ticker,start,end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        raw = get_data(ticker.split(\".\")[0], start_date=start, end_date=end)[entry]\n",
    "    except: \n",
    "        try:\n",
    "            raw = get_data(ticker.replace(\".\",\"-\"), start_date=start, end_date=end)[entry]\n",
    "        except:\n",
    "            raw = get_data(ticker[0:4], start_date=start, end_date=end)[entry]\n",
    "    return raw/raw[0]\n",
    "\n",
    "def get_df(l,start,end,entry=\"adjclose\"):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        x=[executor.submit(lambda x: get_seiries(x,start,end,entry=entry),name)for name in l]\n",
    "        x=[a.result() for a in x]\n",
    "    for i,c in enumerate(x):\n",
    "        c.name=l[i]\n",
    "    return pd.DataFrame(x).transpose()\n",
    "\n",
    "def tester_func(name,start=start,end=end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        c= get_seiries(name,start,end,entry)\n",
    "        c.name=name\n",
    "        return (True,c)\n",
    "    except:\n",
    "        return (False,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread setup complete\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "error number 1: name=KDIV\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "error number 2: name=OAIM\n",
      "800\n",
      "error number 3: name=CTEST.O\n",
      "error number 4: name=EAI\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "error number 5: name=ZBZX\n",
      "1600\n",
      "error number 6: name=CTEST.E\n",
      "1700\n",
      "error number 7: name=ZJZZT\n",
      "error number 8: name=XTWY\n",
      "1800\n",
      "error number 9: name=ZXIET\n",
      "error number 10: name=ATEST.B\n",
      "1900\n",
      "2000\n",
      "error number 11: name=RCA\n",
      "2100\n",
      "error number 12: name=ZVZZT\n",
      "error number 13: name=LNKB\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "error number 14: name=CBX\n",
      "error number 15: name=GGLS\n",
      "error number 16: name=ATEST\n",
      "2700\n",
      "error number 17: name=IBO\n",
      "2800\n",
      "error number 18: name=ZBZZT\n",
      "2900\n",
      "error number 19: name=ZAZZT\n",
      "3000\n",
      "error number 20: name=ZCZZT\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "error number 21: name=ATEST.A\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "error number 22: name=ZEXIT\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "error number 23: name=DHCNL\n",
      "4100\n",
      "error number 24: name=ZXZZT\n",
      "4200\n",
      "error number 25: name=CBO\n",
      "4300\n",
      "error number 26: name=IBIT\n",
      "4400\n",
      "error number 27: name=ZXYZ.A\n",
      "4500\n",
      "4600\n",
      "error number 28: name=XTRE\n",
      "4700\n",
      "error number 29: name=XTEN\n",
      "error number 30: name=ZVZZC\n",
      "4800\n",
      "error number 31: name=CTEST.V\n",
      "error number 32: name=CTEST.G\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "error number 33: name=ZWZZT\n",
      "5200\n",
      "error number 34: name=NXL\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "error number 35: name=XHLF\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "error number 36: name=ZVV\n",
      "6300\n",
      "6400\n",
      "error number 37: name=FOXO\n",
      "6500\n",
      "error number 38: name=ATEST.C\n",
      "error number 39: name=XFIV\n",
      "6600\n",
      "error number 40: name=CTEST\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "error number 41: name=XTWO\n",
      "7100\n",
      "error number 42: name=THRD\n",
      "7200\n",
      "error number 43: name=OAEM\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "error number 44: name=TAFI\n",
      "7600\n",
      "error number 45: name=IGZ\n",
      "7700\n",
      "7800\n",
      "error number 46: name=CTEST.S\n",
      "7900\n",
      "error number 47: name=STRV\n",
      "8000\n",
      "error number 48: name=SFB\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "error number 49: name=CRBG\n",
      "error number 50: name=GRP.U\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "error number 51: name=YEAR\n",
      "8800\n",
      "error number 52: name=ZIEXT\n",
      "8900\n",
      "9000\n",
      "error number 53: name=DEFI\n",
      "9100\n",
      "error number 54: name=XSVN\n",
      "error number 55: name=CTEST.L\n",
      "9200\n",
      "error number 56: name=XONE\n",
      "9300\n",
      "error number 57: name=EMP\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "error number 58: name=ZTEST\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "error number 59: name=AMPX\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "mini=ticker_list\n",
    "errors=[]\n",
    "data=[]\n",
    "c=0\n",
    "x=list(range(len(mini)))\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(len(mini)):\n",
    "        x[i]=executor.submit(tester_func,mini[i])\n",
    "    \n",
    "    print(\"thread setup complete\")\n",
    "    \n",
    "    for i in range(len(mini)):\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "        r=x[i].result()\n",
    "        if (r[0]): \n",
    "            data.append(r[1])\n",
    "        else:\n",
    "            errors.append(r[1])\n",
    "            c+=1\n",
    "            print(f\"error number {c}: name={errors[-1]}\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e95aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>ONTO</th>\n",
       "      <th>NOGN</th>\n",
       "      <th>COWNL</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>HEPS</th>\n",
       "      <th>DXJ</th>\n",
       "      <th>FRBN</th>\n",
       "      <th>REX</th>\n",
       "      <th>PR</th>\n",
       "      <th>...</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>IGC</th>\n",
       "      <th>OPFI</th>\n",
       "      <th>JPS</th>\n",
       "      <th>CNDT</th>\n",
       "      <th>APYX</th>\n",
       "      <th>KRBN</th>\n",
       "      <th>GCV</th>\n",
       "      <th>FARM</th>\n",
       "      <th>WBIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.995231</td>\n",
       "      <td>0.985957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000731</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>1.021322</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008532</td>\n",
       "      <td>0.992476</td>\n",
       "      <td>0.993623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.970564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000548</td>\n",
       "      <td>0.996727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>1.068230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004231</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001001</td>\n",
       "      <td>0.923967</td>\n",
       "      <td>0.974148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "      <td>0.996580</td>\n",
       "      <td>0.992526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.976236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962479</td>\n",
       "      <td>1.066098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989657</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.945454</td>\n",
       "      <td>0.971798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006826</td>\n",
       "      <td>0.967852</td>\n",
       "      <td>0.989643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002558</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935004</td>\n",
       "      <td>0.982942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>1.015873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006826</td>\n",
       "      <td>0.941861</td>\n",
       "      <td>0.993095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>1.259090</td>\n",
       "      <td>1.821766</td>\n",
       "      <td>0.202832</td>\n",
       "      <td>1.134360</td>\n",
       "      <td>1.242030</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>1.268203</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.027596</td>\n",
       "      <td>1.611940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018092</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>1.948549</td>\n",
       "      <td>1.136384</td>\n",
       "      <td>0.343365</td>\n",
       "      <td>1.064245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>1.262720</td>\n",
       "      <td>1.890359</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>1.133779</td>\n",
       "      <td>1.254682</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>1.286874</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.047930</td>\n",
       "      <td>1.656716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019169</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.707403</td>\n",
       "      <td>1.895037</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.348153</td>\n",
       "      <td>1.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>1.298613</td>\n",
       "      <td>1.930597</td>\n",
       "      <td>0.156642</td>\n",
       "      <td>1.139096</td>\n",
       "      <td>1.276690</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>1.297093</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.062455</td>\n",
       "      <td>1.692964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027783</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.836742</td>\n",
       "      <td>0.674380</td>\n",
       "      <td>0.735605</td>\n",
       "      <td>1.894055</td>\n",
       "      <td>1.138421</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>1.073552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.311922</td>\n",
       "      <td>1.944910</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>1.133466</td>\n",
       "      <td>1.287960</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.064633</td>\n",
       "      <td>1.752665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036936</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.275127</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.692562</td>\n",
       "      <td>0.781434</td>\n",
       "      <td>2.017772</td>\n",
       "      <td>1.142494</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.074628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.270382</td>\n",
       "      <td>1.906562</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>1.125871</td>\n",
       "      <td>1.237671</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>1.272134</td>\n",
       "      <td>1.021298</td>\n",
       "      <td>1.025781</td>\n",
       "      <td>1.665245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.833275</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.727380</td>\n",
       "      <td>1.946095</td>\n",
       "      <td>1.109909</td>\n",
       "      <td>0.370041</td>\n",
       "      <td>1.055890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 10569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      ONTO      NOGN     COWNL      SIZE      HEPS  \\\n",
       "2020-01-02  1.000000  1.000000       NaN  1.000000  1.000000       NaN   \n",
       "2020-01-03  0.995231  0.985957       NaN  1.000731  0.995295       NaN   \n",
       "2020-01-06  0.997065  0.970564       NaN  1.000548  0.996727       NaN   \n",
       "2020-01-07  0.993397  0.976236       NaN  0.996894  0.996216       NaN   \n",
       "2020-01-08  0.989362  0.992709       NaN  1.002558  0.999489       NaN   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  1.259090  1.821766  0.202832  1.134360  1.242030  0.073716   \n",
       "2022-09-08  1.262720  1.890359  0.171704  1.133779  1.254682  0.077439   \n",
       "2022-09-09  1.298613  1.930597  0.156642  1.139096  1.276690  0.078183   \n",
       "2022-09-12  1.311922  1.944910  0.151622  1.133466  1.287960  0.083395   \n",
       "2022-09-13  1.270382  1.906562  0.149613  1.125871  1.237671  0.079672   \n",
       "\n",
       "                 DXJ      FRBN       REX        PR  ...      GOOD       IGC  \\\n",
       "2020-01-02  1.000000       NaN  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "2020-01-03  0.982692       NaN  1.003268  1.021322  ...  1.004701  1.000000   \n",
       "2020-01-06  0.990241       NaN  0.993101  1.068230  ...  1.004231  0.984127   \n",
       "2020-01-07  0.990425       NaN  0.962479  1.066098  ...  0.989657  0.984127   \n",
       "2020-01-08  0.995949       NaN  0.935004  0.982942  ...  0.991067  1.015873   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-07  1.268203  1.022312  1.027596  1.611940  ...  1.018092  0.873016   \n",
       "2022-09-08  1.286874  1.022312  1.047930  1.656716  ...  1.019169  0.888889   \n",
       "2022-09-09  1.297093  1.022312  1.062455  1.692964  ...  1.027783  0.873016   \n",
       "2022-09-12  1.295914  1.022312  1.064633  1.752665  ...  1.036936  0.920635   \n",
       "2022-09-13  1.272134  1.021298  1.025781  1.665245  ...  0.998710  0.904762   \n",
       "\n",
       "                OPFI       JPS      CNDT      APYX      KRBN       GCV  \\\n",
       "2020-01-02       NaN  1.000000  1.000000  1.000000       NaN  1.000000   \n",
       "2020-01-03       NaN  1.004004  0.987603  0.995300       NaN  1.008532   \n",
       "2020-01-06       NaN  1.001001  0.923967  0.974148       NaN  1.005120   \n",
       "2020-01-07       NaN  1.004004  0.945454  0.971798       NaN  1.006826   \n",
       "2020-01-08       NaN  1.004004  0.950413  0.967097       NaN  1.006826   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  0.265990  0.841365  0.669421  0.702703  1.948549  1.136384   \n",
       "2022-09-08  0.265990  0.835586  0.659504  0.707403  1.895037  1.124165   \n",
       "2022-09-09  0.268020  0.836742  0.674380  0.735605  1.894055  1.138421   \n",
       "2022-09-12  0.275127  0.841365  0.692562  0.781434  2.017772  1.142494   \n",
       "2022-09-13  0.256853  0.833275  0.669421  0.727380  1.946095  1.109909   \n",
       "\n",
       "                FARM      WBIG  \n",
       "2020-01-02  1.000000  1.000000  \n",
       "2020-01-03  0.992476  0.993623  \n",
       "2020-01-06  0.996580  0.992526  \n",
       "2020-01-07  0.967852  0.989643  \n",
       "2020-01-08  0.941861  0.993095  \n",
       "...              ...       ...  \n",
       "2022-09-07  0.343365  1.064245  \n",
       "2022-09-08  0.348153  1.064783  \n",
       "2022-09-09  0.374829  1.073552  \n",
       "2022-09-12  0.372093  1.074628  \n",
       "2022-09-13  0.370041  1.055890  \n",
       "\n",
       "[680 rows x 10569 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame(data).transpose()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a1a16e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>ONTO</th>\n",
       "      <th>NOGN</th>\n",
       "      <th>COWNL</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>HEPS</th>\n",
       "      <th>DXJ</th>\n",
       "      <th>FRBN</th>\n",
       "      <th>REX</th>\n",
       "      <th>PR</th>\n",
       "      <th>...</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>IGC</th>\n",
       "      <th>OPFI</th>\n",
       "      <th>JPS</th>\n",
       "      <th>CNDT</th>\n",
       "      <th>APYX</th>\n",
       "      <th>KRBN</th>\n",
       "      <th>GCV</th>\n",
       "      <th>FARM</th>\n",
       "      <th>WBIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-07</th>\n",
       "      <td>1.452672</td>\n",
       "      <td>2.259519</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.133254</td>\n",
       "      <td>1.303582</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>1.295589</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.149843</td>\n",
       "      <td>2.040512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081622</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.322843</td>\n",
       "      <td>0.882971</td>\n",
       "      <td>0.912397</td>\n",
       "      <td>0.853114</td>\n",
       "      <td>2.352104</td>\n",
       "      <td>1.213772</td>\n",
       "      <td>0.350889</td>\n",
       "      <td>1.125753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>1.437347</td>\n",
       "      <td>2.178774</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.120102</td>\n",
       "      <td>1.287057</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>1.291705</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.133866</td>\n",
       "      <td>1.997868</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062240</td>\n",
       "      <td>1.301587</td>\n",
       "      <td>0.354315</td>\n",
       "      <td>0.886438</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.836663</td>\n",
       "      <td>2.356522</td>\n",
       "      <td>1.211736</td>\n",
       "      <td>0.346785</td>\n",
       "      <td>1.116860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-09</th>\n",
       "      <td>1.403873</td>\n",
       "      <td>2.113962</td>\n",
       "      <td>1.005121</td>\n",
       "      <td>1.109142</td>\n",
       "      <td>1.253619</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>1.283938</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.151779</td>\n",
       "      <td>2.017058</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040166</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.332995</td>\n",
       "      <td>0.878348</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>2.339339</td>\n",
       "      <td>1.199516</td>\n",
       "      <td>0.350205</td>\n",
       "      <td>1.106767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10</th>\n",
       "      <td>1.378062</td>\n",
       "      <td>2.019984</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.098182</td>\n",
       "      <td>1.216088</td>\n",
       "      <td>0.067014</td>\n",
       "      <td>1.260830</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.120673</td>\n",
       "      <td>1.972281</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037474</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.338071</td>\n",
       "      <td>0.862168</td>\n",
       "      <td>0.819835</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>2.353577</td>\n",
       "      <td>1.230064</td>\n",
       "      <td>0.344049</td>\n",
       "      <td>1.097791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>1.324021</td>\n",
       "      <td>1.941399</td>\n",
       "      <td>1.004117</td>\n",
       "      <td>1.097174</td>\n",
       "      <td>1.162290</td>\n",
       "      <td>0.057930</td>\n",
       "      <td>1.237140</td>\n",
       "      <td>1.014199</td>\n",
       "      <td>1.035706</td>\n",
       "      <td>1.846482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.315736</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.737190</td>\n",
       "      <td>0.730905</td>\n",
       "      <td>2.291227</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.329685</td>\n",
       "      <td>1.077440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>1.259090</td>\n",
       "      <td>1.821766</td>\n",
       "      <td>0.202832</td>\n",
       "      <td>1.134360</td>\n",
       "      <td>1.242030</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>1.268203</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.027596</td>\n",
       "      <td>1.611940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018092</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>1.948549</td>\n",
       "      <td>1.136384</td>\n",
       "      <td>0.343365</td>\n",
       "      <td>1.064245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>1.262720</td>\n",
       "      <td>1.890359</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>1.133779</td>\n",
       "      <td>1.254682</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>1.286874</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.047930</td>\n",
       "      <td>1.656716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019169</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.707403</td>\n",
       "      <td>1.895037</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.348153</td>\n",
       "      <td>1.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>1.298613</td>\n",
       "      <td>1.930597</td>\n",
       "      <td>0.156642</td>\n",
       "      <td>1.139096</td>\n",
       "      <td>1.276690</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>1.297093</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.062455</td>\n",
       "      <td>1.692964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027783</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.836742</td>\n",
       "      <td>0.674380</td>\n",
       "      <td>0.735605</td>\n",
       "      <td>1.894055</td>\n",
       "      <td>1.138421</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>1.073552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.311922</td>\n",
       "      <td>1.944910</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>1.133466</td>\n",
       "      <td>1.287960</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.064633</td>\n",
       "      <td>1.752665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036936</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.275127</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.692562</td>\n",
       "      <td>0.781434</td>\n",
       "      <td>2.017772</td>\n",
       "      <td>1.142494</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.074628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.270382</td>\n",
       "      <td>1.906562</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>1.125871</td>\n",
       "      <td>1.237671</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>1.272134</td>\n",
       "      <td>1.021298</td>\n",
       "      <td>1.025781</td>\n",
       "      <td>1.665245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.833275</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.727380</td>\n",
       "      <td>1.946095</td>\n",
       "      <td>1.109909</td>\n",
       "      <td>0.370041</td>\n",
       "      <td>1.055890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      ONTO      NOGN     COWNL      SIZE      HEPS  \\\n",
       "2022-06-07  1.452672  2.259519  1.006125  1.133254  1.303582  0.074460   \n",
       "2022-06-08  1.437347  2.178774  1.006125  1.120102  1.287057  0.074460   \n",
       "2022-06-09  1.403873  2.113962  1.005121  1.109142  1.253619  0.070737   \n",
       "2022-06-10  1.378062  2.019984  1.006125  1.098182  1.216088  0.067014   \n",
       "2022-06-13  1.324021  1.941399  1.004117  1.097174  1.162290  0.057930   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  1.259090  1.821766  0.202832  1.134360  1.242030  0.073716   \n",
       "2022-09-08  1.262720  1.890359  0.171704  1.133779  1.254682  0.077439   \n",
       "2022-09-09  1.298613  1.930597  0.156642  1.139096  1.276690  0.078183   \n",
       "2022-09-12  1.311922  1.944910  0.151622  1.133466  1.287960  0.083395   \n",
       "2022-09-13  1.270382  1.906562  0.149613  1.125871  1.237671  0.079672   \n",
       "\n",
       "                 DXJ      FRBN       REX        PR  ...      GOOD       IGC  \\\n",
       "2022-06-07  1.295589  1.006085  1.149843  2.040512  ...  1.081622  0.666667   \n",
       "2022-06-08  1.291705  1.006085  1.133866  1.997868  ...  1.062240  1.301587   \n",
       "2022-06-09  1.283938  1.006085  1.151779  2.017058  ...  1.040166  0.984127   \n",
       "2022-06-10  1.260830  1.006085  1.120673  1.972281  ...  1.037474  0.825397   \n",
       "2022-06-13  1.237140  1.014199  1.035706  1.846482  ...  0.998710  0.761905   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-07  1.268203  1.022312  1.027596  1.611940  ...  1.018092  0.873016   \n",
       "2022-09-08  1.286874  1.022312  1.047930  1.656716  ...  1.019169  0.888889   \n",
       "2022-09-09  1.297093  1.022312  1.062455  1.692964  ...  1.027783  0.873016   \n",
       "2022-09-12  1.295914  1.022312  1.064633  1.752665  ...  1.036936  0.920635   \n",
       "2022-09-13  1.272134  1.021298  1.025781  1.665245  ...  0.998710  0.904762   \n",
       "\n",
       "                OPFI       JPS      CNDT      APYX      KRBN       GCV  \\\n",
       "2022-06-07  0.322843  0.882971  0.912397  0.853114  2.352104  1.213772   \n",
       "2022-06-08  0.354315  0.886438  0.890909  0.836663  2.356522  1.211736   \n",
       "2022-06-09  0.332995  0.878348  0.867769  0.881316  2.339339  1.199516   \n",
       "2022-06-10  0.338071  0.862168  0.819835  0.733255  2.353577  1.230064   \n",
       "2022-06-13  0.315736  0.835586  0.737190  0.730905  2.291227  1.124165   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  0.265990  0.841365  0.669421  0.702703  1.948549  1.136384   \n",
       "2022-09-08  0.265990  0.835586  0.659504  0.707403  1.895037  1.124165   \n",
       "2022-09-09  0.268020  0.836742  0.674380  0.735605  1.894055  1.138421   \n",
       "2022-09-12  0.275127  0.841365  0.692562  0.781434  2.017772  1.142494   \n",
       "2022-09-13  0.256853  0.833275  0.669421  0.727380  1.946095  1.109909   \n",
       "\n",
       "                FARM      WBIG  \n",
       "2022-06-07  0.350889  1.125753  \n",
       "2022-06-08  0.346785  1.116860  \n",
       "2022-06-09  0.350205  1.106767  \n",
       "2022-06-10  0.344049  1.097791  \n",
       "2022-06-13  0.329685  1.077440  \n",
       "...              ...       ...  \n",
       "2022-09-07  0.343365  1.064245  \n",
       "2022-09-08  0.348153  1.064783  \n",
       "2022-09-09  0.374829  1.073552  \n",
       "2022-09-12  0.372093  1.074628  \n",
       "2022-09-13  0.370041  1.055890  \n",
       "\n",
       "[68 rows x 10569 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=data_df.iloc[:-68]\n",
    "test_df=data_df.iloc[-68:]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "01a7d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644 stocks were droped\n"
     ]
    }
   ],
   "source": [
    "ticker_list=data_df.columns\n",
    "print(f\"{len(symbols)-len(ticker_list)} stocks were droped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efabaa",
   "metadata": {},
   "source": [
    "# preprocessing \n",
    "\n",
    "\n",
    "1. ticker: this is also used to select which stocks come to the model\n",
    "\n",
    "2. price: we take the ratio: (importantly we did drop some potentialy important indicators)\n",
    "\n",
    "3. date: the day and month are floating point numbers. while year and day of the week are embedings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "673271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "look=layers.StringLookup(vocabulary=ticker_list,num_oov_indices=0)\n",
    "inv_look=layers.StringLookup(vocabulary=ticker_list,invert=True,num_oov_indices=0)\n",
    "tick_embed=layers.Embedding(len(ticker_list)+1,512,embeddings_constraint= tf.keras.constraints.unit_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "47802c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17,), dtype=string, numpy=\n",
       "array([b'GRES', b'ONTO', b'NOGN', b'COWNL', b'SIZE', b'HEPS', b'DXJ',\n",
       "       b'FRBN', b'REX', b'PR', b'MDWD', b'LEVI', b'HMC', b'AIKI', b'SPUC',\n",
       "       b'FANG', b'SAVN'], dtype=object)>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices(ticker_list)\n",
    "exmple=dataset.batch(17).take(1).get_single_element()\n",
    "exmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "a701202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df[exmple.numpy().astype('U13')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "251a654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)],\n",
       " [range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)]]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def thread_distribute(l,f,n=1):\n",
    "    if(n==0):\n",
    "        return f(l)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor: \n",
    "        l=[executor.submit(lambda x: thread_distribute(x,f,n-1),x) for x in l]\n",
    "        l= [x.result() for x in l]\n",
    "    return l\n",
    "\n",
    "thread_distribute([range(5) for i in range(2)],lambda x: range(x),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "9d5f1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>HIMS</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>LPG</th>\n",
       "      <th>SAGAU</th>\n",
       "      <th>PAAS</th>\n",
       "      <th>DBEZ</th>\n",
       "      <th>SGHT</th>\n",
       "      <th>UUUU</th>\n",
       "      <th>BKCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-21</th>\n",
       "      <td>1.206258</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>1.083585</td>\n",
       "      <td>0.884772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.061079</td>\n",
       "      <td>1.195979</td>\n",
       "      <td>0.560299</td>\n",
       "      <td>4.187166</td>\n",
       "      <td>0.988241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>1.212308</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>1.091136</td>\n",
       "      <td>0.913746</td>\n",
       "      <td>1.002006</td>\n",
       "      <td>1.073151</td>\n",
       "      <td>1.206557</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>4.203209</td>\n",
       "      <td>1.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>1.222390</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>1.097009</td>\n",
       "      <td>0.894666</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.078756</td>\n",
       "      <td>1.214989</td>\n",
       "      <td>0.553433</td>\n",
       "      <td>4.251337</td>\n",
       "      <td>1.006396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.233279</td>\n",
       "      <td>0.665657</td>\n",
       "      <td>1.102882</td>\n",
       "      <td>0.898199</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.085224</td>\n",
       "      <td>1.225966</td>\n",
       "      <td>0.551045</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>1.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>1.233682</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>1.105399</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.080481</td>\n",
       "      <td>1.227315</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>4.358289</td>\n",
       "      <td>1.015171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1.416375</td>\n",
       "      <td>0.408081</td>\n",
       "      <td>1.007235</td>\n",
       "      <td>1.291697</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.947253</td>\n",
       "      <td>1.112089</td>\n",
       "      <td>0.256418</td>\n",
       "      <td>3.427807</td>\n",
       "      <td>0.846398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>1.414359</td>\n",
       "      <td>0.407071</td>\n",
       "      <td>1.007235</td>\n",
       "      <td>1.374517</td>\n",
       "      <td>1.006720</td>\n",
       "      <td>0.952427</td>\n",
       "      <td>1.103841</td>\n",
       "      <td>0.251940</td>\n",
       "      <td>3.278075</td>\n",
       "      <td>0.834016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1.434927</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>1.012688</td>\n",
       "      <td>1.343364</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.034347</td>\n",
       "      <td>1.119203</td>\n",
       "      <td>0.273731</td>\n",
       "      <td>3.598930</td>\n",
       "      <td>0.849421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>1.429281</td>\n",
       "      <td>0.410101</td>\n",
       "      <td>1.001781</td>\n",
       "      <td>1.372997</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.016238</td>\n",
       "      <td>1.108747</td>\n",
       "      <td>0.279104</td>\n",
       "      <td>3.508021</td>\n",
       "      <td>0.836843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06</th>\n",
       "      <td>1.432507</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>1.377556</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.000717</td>\n",
       "      <td>1.119571</td>\n",
       "      <td>0.284478</td>\n",
       "      <td>3.513369</td>\n",
       "      <td>0.843493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      HIMS      ROOF       LPG     SAGAU      PAAS  \\\n",
       "2021-12-21  1.206258  0.650505  1.083585  0.884772  1.000000  1.061079   \n",
       "2021-12-22  1.212308  0.654545  1.091136  0.913746  1.002006  1.073151   \n",
       "2021-12-23  1.222390  0.671717  1.097009  0.894666  1.001003  1.078756   \n",
       "2021-12-27  1.233279  0.665657  1.102882  0.898199  1.003009  1.085224   \n",
       "2021-12-28  1.233682  0.648485  1.105399  0.901026  1.003009  1.080481   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-05-31  1.416375  0.408081  1.007235  1.291697  1.018054  0.947253   \n",
       "2022-06-01  1.414359  0.407071  1.007235  1.374517  1.006720  0.952427   \n",
       "2022-06-02  1.434927  0.429293  1.012688  1.343364  1.008024  1.034347   \n",
       "2022-06-03  1.429281  0.410101  1.001781  1.372997  1.008024  1.016238   \n",
       "2022-06-06  1.432507  0.419192  0.997167  1.377556  1.008024  1.000717   \n",
       "\n",
       "                DBEZ      SGHT      UUUU      BKCI  \n",
       "2021-12-21  1.195979  0.560299  4.187166  0.988241  \n",
       "2021-12-22  1.206557  0.541493  4.203209  1.002106  \n",
       "2021-12-23  1.214989  0.553433  4.251337  1.006396  \n",
       "2021-12-27  1.225966  0.551045  4.545455  1.013611  \n",
       "2021-12-28  1.227315  0.519403  4.358289  1.015171  \n",
       "...              ...       ...       ...       ...  \n",
       "2022-05-31  1.112089  0.256418  3.427807  0.846398  \n",
       "2022-06-01  1.103841  0.251940  3.278075  0.834016  \n",
       "2022-06-02  1.119203  0.273731  3.598930  0.849421  \n",
       "2022-06-03  1.108747  0.279104  3.508021  0.836843  \n",
       "2022-06-06  1.119571  0.284478  3.513369  0.843493  \n",
       "\n",
       "[115 rows x 10 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_stocks(x,data_df=train_df):\n",
    "    a=tick_embed(look(ticker_list))\n",
    "    b=tick_embed(look(x))\n",
    "\n",
    "    b=b@tf.transpose(a)\n",
    "    b=tf.nn.top_k(b,NUM_STOCKS)\n",
    "\n",
    "\n",
    "    tickers=inv_look([list(x) for x in b[1].numpy()]).numpy().astype('U13')\n",
    "    \n",
    "    return [[data_df[x] for x in sub] for sub in tickers]\n",
    "    #return thread_distribute(tickers,lambda x: data_df[x],2)\n",
    "\n",
    "a=choose_stocks(exmple)\n",
    "\n",
    "pd.DataFrame(a[0]).transpose().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d8a28548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-02', '2020-01-03', '2020-01-06', '2020-01-07',\n",
       "               '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-13',\n",
       "               '2020-01-14', '2020-01-15',\n",
       "               ...\n",
       "               '2022-05-23', '2022-05-24', '2022-05-25', '2022-05-26',\n",
       "               '2022-05-27', '2022-05-31', '2022-06-01', '2022-06-02',\n",
       "               '2022-06-03', '2022-06-06'],\n",
       "              dtype='datetime64[ns]', length=612, freq=None)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9fd4c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.06666666666666667, 0.08333333333333333, 0)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_encode(a):\n",
    "    #a=a.index\n",
    "    return (a.day_of_week,a.day/30,a.month/12,(a.year-2020))\n",
    "    \n",
    "time_encode(data_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "23d387f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(17, 10, 612), dtype=int32, numpy=\n",
       " array([[[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]]])>,\n",
       " <tf.Tensor: shape=(17, 10, 612), dtype=float64, numpy=\n",
       " array([[[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         ...,\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]]])>,\n",
       " <tf.Tensor: shape=(17, 10, 612), dtype=float64, numpy=\n",
       " array([[[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         ...,\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]]])>,\n",
       " <tf.Tensor: shape=(17, 10, 612), dtype=int32, numpy=\n",
       " array([[[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]]])>]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_tensors(a):\n",
    "    x=thread_distribute(a,lambda x:time_encode(x.index),2)\n",
    "    x=[thread_distribute(x,lambda x: x[i],2) for i in range(4)]\n",
    "    return [tf.constant(x) for x in x]\n",
    "\n",
    "time_tensors(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa725f",
   "metadata": {},
   "source": [
    "# time handeling \n",
    "\n",
    "problems with the data in curent time format:\n",
    "\n",
    "1. there are null entries especialy from before a company was made \n",
    "2. the time diffrence between entries isnt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "16159624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, ...,  True,  True,  True],\n",
       "       [ True,  True, False, ...,  True,  True,  True],\n",
       "       [ True,  True, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=np.logical_not(data_df.isna().to_numpy())\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a993565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>HIMS</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>LPG</th>\n",
       "      <th>SAGAU</th>\n",
       "      <th>PAAS</th>\n",
       "      <th>DBEZ</th>\n",
       "      <th>SGHT</th>\n",
       "      <th>UUUU</th>\n",
       "      <th>BKCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-21</th>\n",
       "      <td>1.206258</td>\n",
       "      <td>0.650505</td>\n",
       "      <td>1.083585</td>\n",
       "      <td>0.884772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.061079</td>\n",
       "      <td>1.195979</td>\n",
       "      <td>0.560299</td>\n",
       "      <td>4.187166</td>\n",
       "      <td>0.988241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-22</th>\n",
       "      <td>1.212308</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>1.091136</td>\n",
       "      <td>0.913746</td>\n",
       "      <td>1.002006</td>\n",
       "      <td>1.073151</td>\n",
       "      <td>1.206557</td>\n",
       "      <td>0.541493</td>\n",
       "      <td>4.203209</td>\n",
       "      <td>1.002106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>1.222390</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>1.097009</td>\n",
       "      <td>0.894666</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.078756</td>\n",
       "      <td>1.214989</td>\n",
       "      <td>0.553433</td>\n",
       "      <td>4.251337</td>\n",
       "      <td>1.006396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.233279</td>\n",
       "      <td>0.665657</td>\n",
       "      <td>1.102882</td>\n",
       "      <td>0.898199</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.085224</td>\n",
       "      <td>1.225966</td>\n",
       "      <td>0.551045</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>1.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>1.233682</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>1.105399</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.080481</td>\n",
       "      <td>1.227315</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>4.358289</td>\n",
       "      <td>1.015171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1.416375</td>\n",
       "      <td>0.408081</td>\n",
       "      <td>1.007235</td>\n",
       "      <td>1.291697</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.947253</td>\n",
       "      <td>1.112089</td>\n",
       "      <td>0.256418</td>\n",
       "      <td>3.427807</td>\n",
       "      <td>0.846398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>1.414359</td>\n",
       "      <td>0.407071</td>\n",
       "      <td>1.007235</td>\n",
       "      <td>1.374517</td>\n",
       "      <td>1.006720</td>\n",
       "      <td>0.952427</td>\n",
       "      <td>1.103841</td>\n",
       "      <td>0.251940</td>\n",
       "      <td>3.278075</td>\n",
       "      <td>0.834016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1.434927</td>\n",
       "      <td>0.429293</td>\n",
       "      <td>1.012688</td>\n",
       "      <td>1.343364</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.034347</td>\n",
       "      <td>1.119203</td>\n",
       "      <td>0.273731</td>\n",
       "      <td>3.598930</td>\n",
       "      <td>0.849421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>1.429281</td>\n",
       "      <td>0.410101</td>\n",
       "      <td>1.001781</td>\n",
       "      <td>1.372997</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.016238</td>\n",
       "      <td>1.108747</td>\n",
       "      <td>0.279104</td>\n",
       "      <td>3.508021</td>\n",
       "      <td>0.836843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06</th>\n",
       "      <td>1.432507</td>\n",
       "      <td>0.419192</td>\n",
       "      <td>0.997167</td>\n",
       "      <td>1.377556</td>\n",
       "      <td>1.008024</td>\n",
       "      <td>1.000717</td>\n",
       "      <td>1.119571</td>\n",
       "      <td>0.284478</td>\n",
       "      <td>3.513369</td>\n",
       "      <td>0.843493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      HIMS      ROOF       LPG     SAGAU      PAAS  \\\n",
       "2021-12-21  1.206258  0.650505  1.083585  0.884772  1.000000  1.061079   \n",
       "2021-12-22  1.212308  0.654545  1.091136  0.913746  1.002006  1.073151   \n",
       "2021-12-23  1.222390  0.671717  1.097009  0.894666  1.001003  1.078756   \n",
       "2021-12-27  1.233279  0.665657  1.102882  0.898199  1.003009  1.085224   \n",
       "2021-12-28  1.233682  0.648485  1.105399  0.901026  1.003009  1.080481   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-05-31  1.416375  0.408081  1.007235  1.291697  1.018054  0.947253   \n",
       "2022-06-01  1.414359  0.407071  1.007235  1.374517  1.006720  0.952427   \n",
       "2022-06-02  1.434927  0.429293  1.012688  1.343364  1.008024  1.034347   \n",
       "2022-06-03  1.429281  0.410101  1.001781  1.372997  1.008024  1.016238   \n",
       "2022-06-06  1.432507  0.419192  0.997167  1.377556  1.008024  1.000717   \n",
       "\n",
       "                DBEZ      SGHT      UUUU      BKCI  \n",
       "2021-12-21  1.195979  0.560299  4.187166  0.988241  \n",
       "2021-12-22  1.206557  0.541493  4.203209  1.002106  \n",
       "2021-12-23  1.214989  0.553433  4.251337  1.006396  \n",
       "2021-12-27  1.225966  0.551045  4.545455  1.013611  \n",
       "2021-12-28  1.227315  0.519403  4.358289  1.015171  \n",
       "...              ...       ...       ...       ...  \n",
       "2022-05-31  1.112089  0.256418  3.427807  0.846398  \n",
       "2022-06-01  1.103841  0.251940  3.278075  0.834016  \n",
       "2022-06-02  1.119203  0.273731  3.598930  0.849421  \n",
       "2022-06-03  1.108747  0.279104  3.508021  0.836843  \n",
       "2022-06-06  1.119571  0.284478  3.513369  0.843493  \n",
       "\n",
       "[115 rows x 10 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_stocks_df(x,data_df=train_df):\n",
    "    a=tick_embed(look(ticker_list))\n",
    "    b=tick_embed(look(x))\n",
    "\n",
    "    b=b@tf.transpose(a)\n",
    "    b=tf.nn.top_k(b,NUM_STOCKS)\n",
    "\n",
    "\n",
    "    tickers=inv_look([list(x) for x in b[1].numpy()]).numpy().astype('U13')\n",
    "    \n",
    "    \n",
    "    return [pd.DataFrame([data_df[x] for x in sub]).transpose().dropna() for sub in tickers]\n",
    "\n",
    "v=choose_stocks_df(exmple)\n",
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f75c44e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorShape([17, 612]), tf.int32),\n",
       " (TensorShape([17, 612]), tf.float32),\n",
       " (TensorShape([17, 612]), tf.float32),\n",
       " (TensorShape([17, 612]), tf.int32),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 10]), tf.string)]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to add the tickers strings/ints\n",
    "def get_xs(v):\n",
    "    t=[x.index for x in v]\n",
    "    t=thread_distribute(t,time_encode,2)\n",
    "    #t=[[x[i] for x in t] for i in range(4)]\n",
    "    t=[thread_distribute(t,lambda x: x[i],2) for i in range(4)]\n",
    "    #thread_distribute(t,len,2)\n",
    "    t=[tf.ragged.constant(x) for x in t]\n",
    "    \n",
    "    x=thread_distribute(v,lambda x: x.to_numpy(),1)\n",
    "    vals=tf.concat(x,axis=0)\n",
    "    lengths=[len(s) for s in x]\n",
    "    x=tf.RaggedTensor.from_row_lengths(vals,lengths)\n",
    "    #[x.shape for x in x]\n",
    "    \n",
    "    \"padding\"\n",
    "    x=(x+1).to_tensor()-1\n",
    "    t=[(x+1).to_tensor()-1 for x in t] \n",
    "    \n",
    "    x=tf.transpose(x,[2,0,1])\n",
    "    t.extend(x) \n",
    "    \n",
    "    tickers=tf.constant([x.transpose().index for x in v])\n",
    "    t.append(tickers)\n",
    "    return t\n",
    "\n",
    "xs=get_xs(v)\n",
    "[(x.shape,x.dtype) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "755a743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(x) for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "e8e380cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>HIMS</th>\n",
       "      <th>ROOF</th>\n",
       "      <th>LPG</th>\n",
       "      <th>SAGAU</th>\n",
       "      <th>PAAS</th>\n",
       "      <th>DBEZ</th>\n",
       "      <th>SGHT</th>\n",
       "      <th>UUUU</th>\n",
       "      <th>BKCI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-23</th>\n",
       "      <td>1.222390</td>\n",
       "      <td>0.671717</td>\n",
       "      <td>1.097009</td>\n",
       "      <td>0.894666</td>\n",
       "      <td>1.001003</td>\n",
       "      <td>1.078756</td>\n",
       "      <td>1.214989</td>\n",
       "      <td>0.553433</td>\n",
       "      <td>4.251337</td>\n",
       "      <td>1.006396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-27</th>\n",
       "      <td>1.233279</td>\n",
       "      <td>0.665657</td>\n",
       "      <td>1.102882</td>\n",
       "      <td>0.898199</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.085224</td>\n",
       "      <td>1.225966</td>\n",
       "      <td>0.551045</td>\n",
       "      <td>4.545455</td>\n",
       "      <td>1.013611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>1.233682</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>1.105399</td>\n",
       "      <td>0.901026</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.080481</td>\n",
       "      <td>1.227315</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>4.358289</td>\n",
       "      <td>1.015171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>1.231262</td>\n",
       "      <td>0.614141</td>\n",
       "      <td>1.112111</td>\n",
       "      <td>0.905973</td>\n",
       "      <td>1.003009</td>\n",
       "      <td>1.058923</td>\n",
       "      <td>1.226027</td>\n",
       "      <td>0.518209</td>\n",
       "      <td>4.235294</td>\n",
       "      <td>1.012831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>1.230053</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>1.118823</td>\n",
       "      <td>0.896079</td>\n",
       "      <td>1.004012</td>\n",
       "      <td>1.077894</td>\n",
       "      <td>1.224280</td>\n",
       "      <td>0.528060</td>\n",
       "      <td>4.064171</td>\n",
       "      <td>1.010160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-11</th>\n",
       "      <td>1.331280</td>\n",
       "      <td>0.314141</td>\n",
       "      <td>0.950182</td>\n",
       "      <td>1.360080</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.945960</td>\n",
       "      <td>1.043592</td>\n",
       "      <td>0.219403</td>\n",
       "      <td>2.925134</td>\n",
       "      <td>0.790628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-12</th>\n",
       "      <td>1.320391</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.958992</td>\n",
       "      <td>1.347163</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.905862</td>\n",
       "      <td>1.051349</td>\n",
       "      <td>0.228657</td>\n",
       "      <td>2.802139</td>\n",
       "      <td>0.789283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13</th>\n",
       "      <td>1.349428</td>\n",
       "      <td>0.348485</td>\n",
       "      <td>0.978708</td>\n",
       "      <td>1.167086</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.933456</td>\n",
       "      <td>1.079220</td>\n",
       "      <td>0.244478</td>\n",
       "      <td>3.122995</td>\n",
       "      <td>0.810830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16</th>\n",
       "      <td>1.363544</td>\n",
       "      <td>0.350505</td>\n",
       "      <td>0.982484</td>\n",
       "      <td>1.221033</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.938199</td>\n",
       "      <td>1.078423</td>\n",
       "      <td>0.242985</td>\n",
       "      <td>3.165775</td>\n",
       "      <td>0.811064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-17</th>\n",
       "      <td>1.387741</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>1.008493</td>\n",
       "      <td>1.181522</td>\n",
       "      <td>1.018054</td>\n",
       "      <td>0.953289</td>\n",
       "      <td>1.095747</td>\n",
       "      <td>0.259403</td>\n",
       "      <td>3.486631</td>\n",
       "      <td>0.825124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      HIMS      ROOF       LPG     SAGAU      PAAS  \\\n",
       "2021-12-23  1.222390  0.671717  1.097009  0.894666  1.001003  1.078756   \n",
       "2021-12-27  1.233279  0.665657  1.102882  0.898199  1.003009  1.085224   \n",
       "2021-12-28  1.233682  0.648485  1.105399  0.901026  1.003009  1.080481   \n",
       "2021-12-29  1.231262  0.614141  1.112111  0.905973  1.003009  1.058923   \n",
       "2021-12-30  1.230053  0.644444  1.118823  0.896079  1.004012  1.077894   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-05-11  1.331280  0.314141  0.950182  1.360080  1.018054  0.945960   \n",
       "2022-05-12  1.320391  0.323232  0.958992  1.347163  1.018054  0.905862   \n",
       "2022-05-13  1.349428  0.348485  0.978708  1.167086  1.018054  0.933456   \n",
       "2022-05-16  1.363544  0.350505  0.982484  1.221033  1.018054  0.938199   \n",
       "2022-05-17  1.387741  0.372727  1.008493  1.181522  1.018054  0.953289   \n",
       "\n",
       "                DBEZ      SGHT      UUUU      BKCI  \n",
       "2021-12-23  1.214989  0.553433  4.251337  1.006396  \n",
       "2021-12-27  1.225966  0.551045  4.545455  1.013611  \n",
       "2021-12-28  1.227315  0.519403  4.358289  1.015171  \n",
       "2021-12-29  1.226027  0.518209  4.235294  1.012831  \n",
       "2021-12-30  1.224280  0.528060  4.064171  1.010160  \n",
       "...              ...       ...       ...       ...  \n",
       "2022-05-11  1.043592  0.219403  2.925134  0.790628  \n",
       "2022-05-12  1.051349  0.228657  2.802139  0.789283  \n",
       "2022-05-13  1.079220  0.244478  3.122995  0.810830  \n",
       "2022-05-16  1.078423  0.242985  3.165775  0.811064  \n",
       "2022-05-17  1.095747  0.259403  3.486631  0.825124  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_seq(x,LEN=100):\n",
    "    l=len(x)\n",
    "    if(l<LEN):\n",
    "        return x \n",
    "    \n",
    "    start=np.random.randint(l-LEN)\n",
    "    return x.iloc[start:start+LEN]\n",
    "sample_seq(v[-1]) \n",
    "sample_seq(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "af077c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=[sample_seq(x) for x in v]\n",
    "y=[s.iloc[1:,0] for s in base]\n",
    "x=[s[:-1] for s in base]\n",
    "x=get_xs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "dd0f22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.436988115310669\n"
     ]
    }
   ],
   "source": [
    "def get_numbers(tickers):\n",
    "    v=choose_stocks_df(tickers)\n",
    "    base=[sample_seq(x) for x in v]\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "73d7c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 10), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None)]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs=[tf.TensorSpec.from_tensor(x) for x in n]\n",
    "s=[list(x.shape) for x in specs]\n",
    "for x in s:\n",
    "    x[0]=None\n",
    "specs=[tf.TensorSpec(s[i],specs[i].dtype) for i in range(len(specs))]\n",
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "3332fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 3), 4)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_x(*args):\n",
    "    return args[:-1]\n",
    "\n",
    "def gather_y(*args):\n",
    "    return args[-1]\n",
    "\n",
    "gather_x(1,2,3,4),gather_y(1,2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a5a8e",
   "metadata": {},
   "source": [
    "# train dataset \n",
    "because of the need to use the dataset as a refrence type in the pandas df we are forcing tensorflow to run the whole thing eagerly. \n",
    "\n",
    "it shouldnt be a major issue since most the heavy lifting is done in pandas which is optimized c code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "aa0fa0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 3,  4,  0, ..., -1, -1, -1],\n",
       "         [ 0,  1,  2, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 2,  4,  0, ...,  2,  3,  0],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 0,  1,  2, ..., -1, -1, -1]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.79999995,  0.83333325,  0.9333334 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.6       ,  0.6333333 ,  0.66666675, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.79999995,  0.8666667 ,  0.9666667 , ...,  0.4333334 ,\n",
       "           0.4666667 ,  0.6       ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.23333335,  0.26666665,  0.29999995, ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.16666663,  0.16666663,  0.16666663, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.33333337,  0.33333337,  0.33333337, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.91666675,  0.91666675,  0.91666675, ...,  0.33333337,\n",
       "           0.33333337,  0.33333337],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.16666663,  0.16666663,  0.16666663, ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  1,  1, ...,  2,  2,  2],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ..., -1, -1, -1]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.84806367,  1.89330246,  1.90257087, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.03303047,  1.03330391,  1.03658316, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.13963116,  1.10114003,  1.09188253, ...,  1.18164578,\n",
       "           1.17717355,  1.16276321],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.3710198 ,  1.38360915,  1.40551087, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.41046753,  0.39782418,  0.3990003 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 2.93947551,  2.84744762,  2.95436207, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.05722254,  1.03631506,  1.04379651, ...,  1.05127789,\n",
       "           1.04545449,  1.04306853],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.10480529,  1.1084157 ,  1.13260598, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.18823531,  1.2186275 ,  1.22549022, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.00397196,  1.00296443,  1.00397196, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.10788033,  1.09063579,  1.10331564, ...,  1.19359607,\n",
       "           1.19714642,  1.19799179],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.61024702,  0.63586456,  0.68709973, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.98572862,  0.98693466,  0.98693466, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.25774816,  1.28102508,  1.32020545, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 2.27586196,  2.24137924,  2.27586196, ...,  2.17241379,\n",
       "           2.07931035,  2.06551709],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.        ,  1.01419882,  1.00709946, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.60062751,  1.62837851,  1.56394787, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.        ,  0.98955256,  0.99144494, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.03312599,  1.01161255,  1.01916353, ...,  1.07432836,\n",
       "           1.07413316,  1.07686774],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.61714772,  0.59083194,  0.58998302, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.31963981,  1.3593534 ,  1.35837455, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.90104888,  1.87666863,  1.8961111 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.372196  ,  1.31664156,  1.29904925, ...,  1.27590154,\n",
       "           1.27219791,  1.27312384],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.2339397 ,  1.25072795,  1.26856552, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.        ,  1.02050561,  1.01918141, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.56935819,  0.5672878 ,  0.55279506, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.48443135,  1.42673293,  1.46409023, ...,  1.22484749,\n",
       "           1.19578318,  1.18694263],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.27553304,  1.28698022,  1.30024423, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.99881957,  0.99958791,  1.01495435, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.0139796 ,  1.0139796 ,  1.0139796 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.09368715,  1.08050616,  1.09435443, ...,  1.24084687,\n",
       "           1.24034622,  1.23801036],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 6.2503129 ,  6.65331682,  6.8385483 , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.29599273,  0.28597452,  0.30418944, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.35608561,  1.39443458,  1.36310266, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.98408901,  0.99562746,  0.992753  , ...,  0.89967609,\n",
       "           0.88627531,  0.87995951],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.9757576 ,  0.9757576 ,  0.9757576 , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.12280697,  1.10233915,  1.21929824, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.71661059,  0.70987653,  0.69809202, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.07213637,  1.07399307,  1.07543715, ...,  0.97496944,\n",
       "           0.97043092,  0.96713013],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.14758179,  1.19410544,  1.17564364, ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 10), dtype=string, numpy=\n",
       "  array([[b'BOOM', b'TGR', b'MTW', b'PYPS', b'AGS', b'FEMY', b'ABOS',\n",
       "          b'TBLD', b'VLU', b'ANZUU'],\n",
       "         [b'SITE', b'DSGN', b'OWL', b'MTVC', b'ARVN', b'FNX', b'DUHP',\n",
       "          b'NAN', b'BGRY', b'CGRN'],\n",
       "         [b'USHY', b'CIVI', b'FUMB', b'VMC', b'GRNR', b'NANR', b'CLBT',\n",
       "          b'BRKH', b'SKYY', b'SCWX'],\n",
       "         [b'NBTX', b'FNF', b'SUB', b'SWIM', b'AME', b'NBSE', b'REX',\n",
       "          b'PIPP', b'DRCT', b'GUT'],\n",
       "         [b'OBSV', b'BWAQ', b'IDV', b'SGH', b'NEPT', b'NAPR', b'GMVD',\n",
       "          b'ARKG', b'EACPU', b'ARLO'],\n",
       "         [b'HOTH', b'KPRX', b'HYLN', b'BIZD', b'NOMD', b'BOOM', b'IMCV',\n",
       "          b'BIOT', b'LAB', b'FTFT'],\n",
       "         [b'AGI', b'TBLA', b'ATER', b'MDRX', b'CARS', b'PVI', b'SRLN',\n",
       "          b'PAUG', b'ACES', b'BOAC'],\n",
       "         [b'HEPS', b'FLL', b'IQSU', b'ATOS', b'VECO', b'NACP', b'TRMB',\n",
       "          b'TSPQ', b'BNO', b'APRE'],\n",
       "         [b'ATI', b'HCVIU', b'IQMD', b'BTTX', b'DBEU', b'VSS', b'HYZN',\n",
       "          b'RKLB', b'PSI', b'GVAL'],\n",
       "         [b'HL', b'FDTS', b'CBRG', b'SCZ', b'EVA', b'OPEN', b'DDWM',\n",
       "          b'JNPR', b'HPLTU', b'DRTT'],\n",
       "         [b'SBAC', b'NRDY', b'TBNK', b'AZAO', b'IVOG', b'PESI', b'SGG',\n",
       "          b'VTAQU', b'NTEST.C', b'XLY'],\n",
       "         [b'ARCH', b'PCX', b'PSP', b'LINC', b'SDGA', b'IBTX', b'MYNA',\n",
       "          b'MSA', b'LMNR', b'AOS'],\n",
       "         [b'SCKT', b'ARYE', b'TYO', b'PULM', b'VFMO', b'FGBI', b'EAOK',\n",
       "          b'CLAA', b'NBCT', b'OHAA'],\n",
       "         [b'EPD', b'RCLF', b'WEA', b'ONTX', b'CMSA', b'GIFI', b'FOCS',\n",
       "          b'EMCA', b'BTB', b'BSBE'],\n",
       "         [b'ITA', b'NUSI', b'SPOT', b'TANNZ', b'SOXX', b'KE', b'IMGN',\n",
       "          b'NFNT.U', b'CSLMU', b'MUI'],\n",
       "         [b'DHHCU', b'DSTX', b'HLLY', b'CPRT', b'SCHC', b'MAA', b'EWK',\n",
       "          b'RMAX', b'CHUY', b'APACU'],\n",
       "         [b'NDMO', b'LMND', b'AMP', b'LOKM.U', b'POW', b'JHSC', b'FLCB',\n",
       "          b'DWACU', b'AMG', b'EZU'],\n",
       "         [b'EFIX', b'FYX', b'USEP', b'AGTI', b'PONO', b'PRAA', b'HAPP',\n",
       "          b'SQEW', b'TPH', b'TYME'],\n",
       "         [b'HIII', b'EPSN', b'PFL', b'WFIG', b'MFDX', b'ETN', b'BRSH',\n",
       "          b'JMBS', b'IRRX.U', b'UWM'],\n",
       "         [b'CNOB', b'HERO', b'AMNA', b'LNDC', b'AHPI', b'FDEM', b'XBOC',\n",
       "          b'EFSC', b'INFN', b'BSBE'],\n",
       "         [b'WOMN', b'SRRK', b'MHO', b'ANVS', b'MGRB', b'AGNCN', b'BTU',\n",
       "          b'GPMT', b'HEWC', b'MCAC'],\n",
       "         [b'PBAX', b'GMDA', b'ATA.U', b'AFIB', b'IAE', b'BROG', b'IVR',\n",
       "          b'EVNT', b'ESPO', b'AKA'],\n",
       "         [b'NXTG', b'RSLS', b'KRYS', b'MEG', b'DVYA', b'TX', b'FDLO',\n",
       "          b'AEIS', b'VRNS', b'DRD'],\n",
       "         [b'SCLEU', b'ZIONL', b'TTE', b'DSPC', b'EDEN', b'ALDX', b'GRVY',\n",
       "          b'BTF', b'VIA', b'IYLD'],\n",
       "         [b'CMPR', b'HYS', b'IAI', b'APH', b'QVMS', b'GLS', b'UAV',\n",
       "          b'HEPA', b'CNXA', b'IMVT'],\n",
       "         [b'BW', b'DBB', b'INZY', b'AVDL', b'BEN', b'WTMAU', b'WEL',\n",
       "          b'IEA', b'HLT', b'PAFO'],\n",
       "         [b'ABIO', b'CREG', b'PSA', b'MOOD', b'STCN', b'AZYO', b'MRKR',\n",
       "          b'AVAL', b'AFGE', b'CRAI'],\n",
       "         [b'TEL', b'NUVL', b'GBLI', b'MSGS', b'KB', b'SANA', b'EMLP',\n",
       "          b'MNKD', b'PEN', b'OXACU'],\n",
       "         [b'MMYT', b'KE', b'ECOW', b'CHKP', b'EYE', b'UBER', b'ACR',\n",
       "          b'NNDM', b'SMWB', b'SOR'],\n",
       "         [b'KW', b'NUDV', b'EVRG', b'POET', b'EEMD', b'HONE', b'QULL',\n",
       "          b'XEL', b'TBJL', b'BSMT'],\n",
       "         [b'PR', b'DSGX', b'JGRO', b'BANF', b'RMM', b'PMD', b'IBLC',\n",
       "          b'RZA', b'EMCB', b'AAMC'],\n",
       "         [b'ATVI', b'JRSH', b'VLD', b'APCA.U', b'WE', b'BOE', b'FTA',\n",
       "          b'CALX', b'EGGF.U', b'MTG']], dtype=object)>),\n",
       " <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       " array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 1.44628978,  1.61095738,  1.56220868, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.88872766,  0.87131109,  0.83986456, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.43489826,  1.45279507,  1.43209091, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 1.595414  ,  1.57396195,  1.635512  , ...,  1.1043678 ,\n",
       "          1.13942424,  1.09346949],\n",
       "        [ 1.26624729,  1.30327963,  1.29592495, ..., -1.        ,\n",
       "         -1.        , -1.        ]])>)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "train_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=train_dataset.map(gather_x)\n",
    "dataset_y=train_dataset.map(gather_y)\n",
    "train_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=train_dataset.take(1).get_single_element()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "04dd2a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 10), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "9f498909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': (<tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[ 1,  2,  3, ...,  0,  1,  2],\n",
       "         [ 0,  1,  2, ..., -1, -1, -1],\n",
       "         [ 4,  0,  1, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  2,  3, ...,  0,  1,  2],\n",
       "         [ 4,  0,  1, ...,  3,  4,  1],\n",
       "         [ 2,  3,  0, ...,  2,  3,  4]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[ 0.13333333,  0.16666663,  0.20000005, ...,  0.76666665,\n",
       "           0.79999995,  0.83333325],\n",
       "         [ 0.23333335,  0.26666665,  0.29999995, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.13333333,  0.23333335,  0.26666665, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.9333334 ,  0.9666667 ,  1.        , ...,  0.5333333 ,\n",
       "           0.5666666 ,  0.6       ],\n",
       "         [ 0.23333335,  0.33333337,  0.36666667, ...,  0.8666667 ,\n",
       "           0.9       ,  1.0333333 ],\n",
       "         [ 0.73333335,  0.76666665,  0.9       , ...,  0.36666667,\n",
       "           0.39999998,  0.4333334 ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[ 0.08333337,  0.08333337,  0.08333337, ...,  0.41666663,\n",
       "           0.41666663,  0.41666663],\n",
       "         [ 0.25      ,  0.25      ,  0.25      , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.25      ,  0.25      ,  0.25      , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.        ,  1.        ,  1.        , ...,  0.41666663,\n",
       "           0.41666663,  0.41666663],\n",
       "         [ 0.08333337,  0.08333337,  0.08333337, ...,  0.41666663,\n",
       "           0.41666663,  0.41666663],\n",
       "         [ 1.        ,  1.        ,  1.        , ...,  0.41666663,\n",
       "           0.41666663,  0.41666663]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[ 2,  2,  2, ...,  2,  2,  2],\n",
       "         [ 2,  2,  2, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  1,  1, ...,  2,  2,  2],\n",
       "         [ 2,  2,  2, ...,  2,  2,  2],\n",
       "         [ 1,  1,  1, ...,  2,  2,  2]])>),\n",
       " 'prices': (<tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[ 1.08113697,  1.08797566,  1.09108424, ...,  0.99875812,\n",
       "           1.00188701,  0.99625496],\n",
       "         [ 1.98076933,  1.87743574,  1.86255242, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.39403547,  1.34260851,  1.3307963 , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.54402515,  0.53144655,  0.5408805 , ...,  0.46855345,\n",
       "           0.4716981 ,  0.44654086],\n",
       "         [ 1.19452219,  1.18235436,  1.19532276, ...,  1.04914942,\n",
       "           1.06115701,  1.05507322],\n",
       "         [ 0.90929635,  0.91926885,  0.92214375, ...,  0.87920305,\n",
       "           0.87344485,  0.88820023]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[ 1.24194648,  1.23271151,  1.25557604, ...,  1.27105266,\n",
       "           1.28207093,  1.29308919],\n",
       "         [ 1.        ,  1.00212142,  1.00111119, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 3.60673499,  3.99657505,  4.37842449, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.41784306,  1.42543928,  1.41801962, ...,  1.10268825,\n",
       "           1.1314833 ,  1.05216462],\n",
       "         [ 1.        ,  1.00505052,  1.00505052, ...,  1.01010105,\n",
       "           1.01010105,  1.01010105],\n",
       "         [ 1.0059701 ,  1.00995019,  1.00995019, ...,  0.99950248,\n",
       "           0.99502486,  0.99502486]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[ 1.12083331,  1.0666666 ,  1.11249999, ...,  0.18749999,\n",
       "           0.17499999,  0.17499999],\n",
       "         [ 1.33570471,  1.30732411,  1.33257148, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.60867604,  0.56168101,  0.55761413, ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.06949062,  1.07246144,  1.07331024, ...,  1.02166121,\n",
       "           1.0281056 ,  1.01693526],\n",
       "         [ 0.79439721,  0.81940967,  0.81390699, ...,  0.50525265,\n",
       "           0.5217609 ,  0.51825912],\n",
       "         [ 0.47711748,  0.483265  ,  0.49180325, ...,  0.41495899,\n",
       "           0.41700819,  0.42418032]])>),\n",
       " 'tickers': <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       " array([[ 0.98479083,  0.98298975,  0.97148283, ...,  0.91314789,\n",
       "          0.91244747,  0.91354814],\n",
       "        [ 1.64144728,  1.61957537,  1.70092883, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.43428837,  0.43397696,  0.42541263, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.5472126 ,  1.5178662 ,  1.52275724, ...,  2.73411555,\n",
       "          2.79769953,  2.68846533],\n",
       "        [ 1.74348851,  1.73605806,  1.75171492, ...,  1.67172174,\n",
       "          1.69780911,  1.65521749],\n",
       "        [ 2.969697  ,  3.020202  ,  2.989899  , ...,  3.010101  ,\n",
       "          2.959596  ,  3.080808  ]])>}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut23(x):\n",
    "    return {\"time\":x[:4],\"prices\":x[4:7],\"tickers\":x[7]}\n",
    "\n",
    "cut23(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8e894",
   "metadata": {},
   "source": [
    "# validation dataset \n",
    "on infrance the best results would probably be achived by runing on every time entry with at least some memory of the past\n",
    "\n",
    "that means there would need to be some precomputation which we can make diffrent for timesetep. \n",
    "\n",
    "this is rediclously slow and combersom to write so our validation is just gona look mostly like the training. \n",
    "after choosing the stocks we would want to work with we are going to think of test behivior \n",
    "\n",
    "we may want to just train a new model from scratch only on that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "f2547e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5385427474975586\n"
     ]
    }
   ],
   "source": [
    "def get_val_numbers(tickers):\n",
    "    base=choose_stocks_df(tickers,test_df)\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_val_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e57350b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "val_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_val_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=val_dataset.map(gather_x)\n",
    "dataset_y=val_dataset.map(gather_y)\n",
    "val_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=val_dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cfc689e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 67), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 10), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53839d1",
   "metadata": {},
   "source": [
    "# the model\n",
    "\n",
    "**the dataset is dependent on the model!!!** this means we have some considerations on how it should look like:\n",
    "\n",
    "* there has to be an attention mechanisem on embeding space. (using only the sampling embedings dot product) \n",
    "* embedings convergnce and stabilety greatly effects the models training. (we may want to consider reverse regularization)\n",
    "*  at least some part of the model should be seprable by stock, in order to reduce noise from data sampeling\n",
    "* it would defintly help if we add residual conections to the embedings to alow gradients to flow to the embedings\n",
    "\n",
    "*side note: the padding used is -1, seems like it should propgate to the loss*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4b96c37c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 32) dtype=float32 (created by layer 'tf.concat_77')>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the inputs\n",
    "inputs=[layers.Input([None,],dtype=x.dtype) for x in specs[:-2]]\n",
    "inputs.append(layers.Input(specs[-2].shape[1:],dtype=specs[-2].dtype,name=\"tickers\"))\n",
    "\n",
    "#time encoding\n",
    "time_depndent=[tf.expand_dims(x,-1) for x in inputs[:-1]] \n",
    "time_depndent=[layers.Masking(-1)(x) for x in time_depndent] \n",
    "\n",
    "\n",
    "day_embeding=layers.Embedding(7,7)(time_depndent[0])\n",
    "year_embeding=layers.Embedding(3,5)(time_depndent[3]) \n",
    "\n",
    "day_embeding=layers.TimeDistributed(layers.Reshape([7]))(day_embeding)\n",
    "year_embeding=layers.TimeDistributed(layers.Reshape([5]))(year_embeding)\n",
    "\n",
    "t=tf.concat(time_depndent[1:3],-1)\n",
    "t=layers.Dense(20)(t) \n",
    "\n",
    "time_encode=tf.concat([day_embeding,t,year_embeding],-1)\n",
    "time_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "e9ed4589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 10) dtype=float32 (created by layer 'tf.nn.softmax_6')>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tickers=look(inputs[-1])\n",
    "tickers=tick_embed(tickers)\n",
    "origin=tf.expand_dims(tickers[:,0],-2)\n",
    "origin=layers.Permute([2,1])(origin)\n",
    "attention=tickers@origin\n",
    "attention=layers.Permute([2,1])(attention)\n",
    "attention=tf.nn.softmax(attention)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "b7b5eaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10, 33) dtype=float32 (created by layer 'dense_19')>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp=layers.Dense(33)(tickers)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "36b0bf13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_246')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_247')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_248')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_249')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_250')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_251')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_252')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_253')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_254')>,\n",
       " <KerasTensor: shape=(None, None, 1, 16) dtype=float32 (created by layer 'tf.expand_dims_255')>]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"need to add stock conditioning\"\n",
    "prices=time_depndent[4:4+NUM_STOCKS]\n",
    "s=[layers.Concatenate(-1)([time_encode,x]) for x in prices]\n",
    "\n",
    "#adding ticker information (while not alowing it to effect the mask)\n",
    "masks=[x._keras_mask for x in s] \n",
    "s=[layers.Add()([s[i],comp[:,i]]) for i in range(len(s))]\n",
    "\n",
    "stock_layer=layers.LSTM(16,return_sequences=True)\n",
    "s=[stock_layer(s[i],mask=masks[i]) for i in range(len(s))]\n",
    "stock_layer=layers.GRU(16,return_sequences=True)\n",
    "s=[stock_layer(x) for x in s]\n",
    "\n",
    "s=[tf.expand_dims(x,-2) for x in s]\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "1c98f2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 16) dtype=float32 (created by layer 'time_distributed_53')>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumorized=attention@layers.Concatenate(-2)(s)\n",
    "sumorized=layers.TimeDistributed(layers.Reshape([16]))(sumorized)\n",
    "sumorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "a1ee2360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None) dtype=float32 (created by layer 'global_max_pooling1d_4')>"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=layers.LSTM(8,return_sequences=True,)(sumorized)\n",
    "x=layers.LayerNormalization()(x)\n",
    "x=layers.Permute([2,1])(x)\n",
    "x=layers.GlobalMaxPool1D()(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6c850530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_284 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_285 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_286 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_287 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_231 (TFOpLambda  (None, None, 1)     0           ['input_284[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_232 (TFOpLambda  (None, None, 1)     0           ['input_285[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_233 (TFOpLambda  (None, None, 1)     0           ['input_286[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_234 (TFOpLambda  (None, None, 1)     0           ['input_287[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tickers (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " masking_228 (Masking)          (None, None, 1)      0           ['tf.expand_dims_231[0][0]']     \n",
      "                                                                                                  \n",
      " masking_229 (Masking)          (None, None, 1)      0           ['tf.expand_dims_232[0][0]']     \n",
      "                                                                                                  \n",
      " masking_230 (Masking)          (None, None, 1)      0           ['tf.expand_dims_233[0][0]']     \n",
      "                                                                                                  \n",
      " masking_231 (Masking)          (None, None, 1)      0           ['tf.expand_dims_234[0][0]']     \n",
      "                                                                                                  \n",
      " string_lookup_2 (StringLookup)  multiple            0           ['tickers[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_49 (Embedding)       (None, None, 1, 7)   49          ['masking_228[0][0]']            \n",
      "                                                                                                  \n",
      " tf.concat_76 (TFOpLambda)      (None, None, 2)      0           ['masking_229[0][0]',            \n",
      "                                                                  'masking_230[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_50 (Embedding)       (None, None, 1, 5)   15          ['masking_231[0][0]']            \n",
      "                                                                                                  \n",
      " input_288 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_289 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_290 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_291 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_292 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_293 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_294 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_295 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_296 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_297 (InputLayer)         [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_46 (Embedding)       multiple             5411840     ['string_lookup_2[15][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_50 (TimeDistr  (None, None, 7)     0           ['embedding_49[0][0]']           \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, None, 20)     60          ['tf.concat_76[0][0]']           \n",
      "                                                                                                  \n",
      " time_distributed_51 (TimeDistr  (None, None, 5)     0           ['embedding_50[0][0]']           \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " tf.expand_dims_235 (TFOpLambda  (None, None, 1)     0           ['input_288[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_236 (TFOpLambda  (None, None, 1)     0           ['input_289[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_237 (TFOpLambda  (None, None, 1)     0           ['input_290[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_238 (TFOpLambda  (None, None, 1)     0           ['input_291[0][0]']              \n",
      " )                                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.expand_dims_239 (TFOpLambda  (None, None, 1)     0           ['input_292[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_240 (TFOpLambda  (None, None, 1)     0           ['input_293[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_241 (TFOpLambda  (None, None, 1)     0           ['input_294[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_242 (TFOpLambda  (None, None, 1)     0           ['input_295[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_243 (TFOpLambda  (None, None, 1)     0           ['input_296[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_244 (TFOpLambda  (None, None, 1)     0           ['input_297[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.concat_77 (TFOpLambda)      (None, None, 32)     0           ['time_distributed_50[0][0]',    \n",
      "                                                                  'dense_18[0][0]',               \n",
      "                                                                  'time_distributed_51[0][0]']    \n",
      "                                                                                                  \n",
      " masking_232 (Masking)          (None, None, 1)      0           ['tf.expand_dims_235[0][0]']     \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 10, 33)       16929       ['embedding_46[14][0]']          \n",
      "                                                                                                  \n",
      " masking_233 (Masking)          (None, None, 1)      0           ['tf.expand_dims_236[0][0]']     \n",
      "                                                                                                  \n",
      " masking_234 (Masking)          (None, None, 1)      0           ['tf.expand_dims_237[0][0]']     \n",
      "                                                                                                  \n",
      " masking_235 (Masking)          (None, None, 1)      0           ['tf.expand_dims_238[0][0]']     \n",
      "                                                                                                  \n",
      " masking_236 (Masking)          (None, None, 1)      0           ['tf.expand_dims_239[0][0]']     \n",
      "                                                                                                  \n",
      " masking_237 (Masking)          (None, None, 1)      0           ['tf.expand_dims_240[0][0]']     \n",
      "                                                                                                  \n",
      " masking_238 (Masking)          (None, None, 1)      0           ['tf.expand_dims_241[0][0]']     \n",
      "                                                                                                  \n",
      " masking_239 (Masking)          (None, None, 1)      0           ['tf.expand_dims_242[0][0]']     \n",
      "                                                                                                  \n",
      " masking_240 (Masking)          (None, None, 1)      0           ['tf.expand_dims_243[0][0]']     \n",
      "                                                                                                  \n",
      " masking_241 (Masking)          (None, None, 1)      0           ['tf.expand_dims_244[0][0]']     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_37 (S  (None, 512)         0           ['embedding_46[14][0]']          \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_232[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_38 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_233[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_39 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_234[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_40 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_235[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_41 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_36 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_236[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_42 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_37 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_237[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_43 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " concatenate_38 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_238[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_44 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_39 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_239[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_45 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_40 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_240[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_46 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " concatenate_41 (Concatenate)   (None, None, 33)     0           ['tf.concat_77[0][0]',           \n",
      "                                                                  'masking_241[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_47 (S  (None, 33)          0           ['dense_19[0][0]']               \n",
      " licingOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_245 (TFOpLambda  (None, 1, 512)      0           ['tf.__operators__.getitem_37[0][\n",
      " )                                                               0]']                             \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, None, 33)     0           ['concatenate_32[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_38[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, None, 33)     0           ['concatenate_33[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_39[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, None, 33)     0           ['concatenate_34[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_40[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, None, 33)     0           ['concatenate_35[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_41[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, None, 33)     0           ['concatenate_36[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_42[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, None, 33)     0           ['concatenate_37[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_43[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, None, 33)     0           ['concatenate_38[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_44[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, None, 33)     0           ['concatenate_39[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_45[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, None, 33)     0           ['concatenate_40[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_46[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, None, 33)     0           ['concatenate_41[0][0]',         \n",
      "                                                                  'tf.__operators__.getitem_47[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " permute_13 (Permute)           (None, 512, 1)       0           ['tf.expand_dims_245[0][0]']     \n",
      "                                                                                                  \n",
      " lstm_30 (LSTM)                 (None, None, 16)     3200        ['add_17[0][0]',                 \n",
      "                                                                  'add_18[0][0]',                 \n",
      "                                                                  'add_19[0][0]',                 \n",
      "                                                                  'add_20[0][0]',                 \n",
      "                                                                  'add_21[0][0]',                 \n",
      "                                                                  'add_22[0][0]',                 \n",
      "                                                                  'add_23[0][0]',                 \n",
      "                                                                  'add_24[0][0]',                 \n",
      "                                                                  'add_25[0][0]',                 \n",
      "                                                                  'add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_12 (TFOpLambd  (None, 10, 1)       0           ['embedding_46[14][0]',          \n",
      " a)                                                               'permute_13[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " gru_18 (GRU)                   (None, None, 16)     1632        ['lstm_30[0][0]',                \n",
      "                                                                  'lstm_30[1][0]',                \n",
      "                                                                  'lstm_30[2][0]',                \n",
      "                                                                  'lstm_30[3][0]',                \n",
      "                                                                  'lstm_30[4][0]',                \n",
      "                                                                  'lstm_30[5][0]',                \n",
      "                                                                  'lstm_30[6][0]',                \n",
      "                                                                  'lstm_30[7][0]',                \n",
      "                                                                  'lstm_30[8][0]',                \n",
      "                                                                  'lstm_30[9][0]']                \n",
      "                                                                                                  \n",
      " permute_14 (Permute)           (None, 1, 10)        0           ['tf.linalg.matmul_12[0][0]']    \n",
      "                                                                                                  \n",
      " tf.expand_dims_246 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[0][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_247 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[1][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_248 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[2][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_249 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[3][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_250 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[4][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_251 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[5][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_252 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[6][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_253 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[7][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_254 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[8][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims_255 (TFOpLambda  (None, None, 1, 16)  0          ['gru_18[9][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.softmax_6 (TFOpLambda)   (None, 1, 10)        0           ['permute_14[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_45 (Concatenate)   (None, None, 10, 16  0           ['tf.expand_dims_246[0][0]',     \n",
      "                                )                                 'tf.expand_dims_247[0][0]',     \n",
      "                                                                  'tf.expand_dims_248[0][0]',     \n",
      "                                                                  'tf.expand_dims_249[0][0]',     \n",
      "                                                                  'tf.expand_dims_250[0][0]',     \n",
      "                                                                  'tf.expand_dims_251[0][0]',     \n",
      "                                                                  'tf.expand_dims_252[0][0]',     \n",
      "                                                                  'tf.expand_dims_253[0][0]',     \n",
      "                                                                  'tf.expand_dims_254[0][0]',     \n",
      "                                                                  'tf.expand_dims_255[0][0]']     \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_16 (TFOpLambd  (None, None, 1, 16)  0          ['tf.nn.softmax_6[0][0]',        \n",
      " a)                                                               'concatenate_45[0][0]']         \n",
      "                                                                                                  \n",
      " time_distributed_53 (TimeDistr  (None, None, 16)    0           ['tf.linalg.matmul_16[0][0]']    \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " lstm_41 (LSTM)                 (None, None, 8)      800         ['time_distributed_53[0][0]']    \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, None, 8)     16          ['lstm_41[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " permute_19 (Permute)           (None, 8, None)      0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_4 (Global  (None, None)        0           ['permute_19[0][0]']             \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,434,541\n",
      "Trainable params: 5,434,541\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Model(inputs,x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "9bd09b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 240, in call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\losses_utils.py\", line 198, in squeeze_or_expand_dimensions\n        y_true, y_pred = tf.cond(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 107, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf.cond_13\" (type TFOpLambda).\n    \n    To be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52E50>, found return value of type KerasTensor, which is not a Tensor or ExtensionType.\n    \n    Call arguments received by layer \"tf.cond_13\" (type TFOpLambda):\n      • pred=tf.Tensor(shape=(), dtype=bool)\n      • true_fn=<function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52E50>\n      • false_fn=<function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52EE0>\n      • name=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5868/3948528117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\losses.py\", line 240, in call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\losses_utils.py\", line 198, in squeeze_or_expand_dimensions\n        y_true, y_pred = tf.cond(\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 107, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: Exception encountered when calling layer \"tf.cond_13\" (type TFOpLambda).\n    \n    To be compatible with tf.function, Python functions must return zero or more Tensors or ExtensionTypes or None values; in compilation of <function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52E50>, found return value of type KerasTensor, which is not a Tensor or ExtensionType.\n    \n    Call arguments received by layer \"tf.cond_13\" (type TFOpLambda):\n      • pred=tf.Tensor(shape=(), dtype=bool)\n      • true_fn=<function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52E50>\n      • false_fn=<function remove_squeezable_dimensions.<locals>.<lambda> at 0x000001D31AC52EE0>\n      • name=None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"mse\")\n",
    "model.fit(train_dataset,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a790e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
