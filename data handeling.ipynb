{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84595fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import yahoo_fin as yf\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afa2b0",
   "metadata": {},
   "source": [
    "# getting data\n",
    "\n",
    "things we did to clean data:\n",
    "\n",
    "1. shamelessly copy:\n",
    "https://levelup.gitconnected.com/how-to-get-all-stock-symbols-a73925c16a1b\n",
    "\n",
    "2. we removed the tickers with $\n",
    "\n",
    "3. we added exception handeling that tries similer strings to the input (note that this is not implemented on the set itself but when fetching, leading to multiple requsts and potentialy to errors)\n",
    "4.  we just drop exceptions that are found when getting the data from online  (these are diffrent every day)\n",
    "\n",
    "# how are we keeping consistency? \n",
    "since the avilble stocks may change depending on the source of the data some extra steps need to be done in order to\n",
    "alow saves to work seemlesly \n",
    "\n",
    "\n",
    "basic plan:\n",
    "\n",
    "1. clean the data as much as possible \n",
    "\n",
    "2. save the embedings weights with their ticker string\n",
    "\n",
    "3. backup everything on git to alow us to fix it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0bece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame( si.tickers_sp500() )\n",
    "df2 = pd.DataFrame( si.tickers_nasdaq() )\n",
    "df3 = pd.DataFrame( si.tickers_dow() )\n",
    "df4 = pd.DataFrame( si.tickers_other() )\n",
    "\n",
    "sym1 = set( symbol for symbol in df1[0].values.tolist() )\n",
    "sym2 = set( symbol for symbol in df2[0].values.tolist() )\n",
    "sym3 = set( symbol for symbol in df3[0].values.tolist() )\n",
    "sym4 = set( symbol for symbol in df4[0].values.tolist() )\n",
    "\n",
    "symbols = set.union( sym1, sym2, sym3, sym4 )\n",
    "del(sym1, sym2, sym3, sym4,df1, df2, df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469a803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1584 unqualified stock symbols...\n",
      "There are 10628 qualified stock symbols...\n"
     ]
    }
   ],
   "source": [
    "my_list = ['W', 'R', 'P', 'Q']\n",
    "del_set = set()\n",
    "sav_set = set()\n",
    "\n",
    "for symbol in symbols:\n",
    "    if (len( symbol ) > 4 and symbol[-1] in my_list or \"$\" in symbol):\n",
    "        del_set.add( symbol )\n",
    "    else:\n",
    "        sav_set.add( symbol )\n",
    "sav_set.discard(\"\") \n",
    "\n",
    "ticker_list=list(sav_set)\n",
    "\n",
    "print( f'Removed {len( del_set )} unqualified stock symbols...' )\n",
    "print( f'There are {len( sav_set )} qualified stock symbols...' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d42362",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='01/01/2020' \n",
    "end='09/14/2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3c39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "\n",
    "def get_seiries(ticker,start,end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        raw = get_data(ticker.split(\".\")[0], start_date=start, end_date=end)[entry]\n",
    "    except: \n",
    "        try:\n",
    "            raw = get_data(ticker.replace(\".\",\"-\"), start_date=start, end_date=end)[entry]\n",
    "        except:\n",
    "            raw = get_data(ticker[0:4], start_date=start, end_date=end)[entry]\n",
    "    return raw/raw[0]\n",
    "\n",
    "def get_df(l,start,end,entry=\"adjclose\"):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        x=[executor.submit(lambda x: get_seiries(x,start,end,entry=entry),name)for name in l]\n",
    "        x=[a.result() for a in x]\n",
    "    for i,c in enumerate(x):\n",
    "        c.name=l[i]\n",
    "    return pd.DataFrame(x).transpose()\n",
    "\n",
    "def tester_func(name,start=start,end=end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        c= get_seiries(name,start,end,entry)\n",
    "        c.name=name\n",
    "        return (True,c)\n",
    "    except:\n",
    "        return (False,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread setup complete\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "error number 1: name=KDIV\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "error number 2: name=OAIM\n",
      "800\n",
      "error number 3: name=CTEST.O\n",
      "error number 4: name=EAI\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "error number 5: name=ZBZX\n",
      "1600\n",
      "error number 6: name=CTEST.E\n",
      "1700\n",
      "error number 7: name=ZJZZT\n",
      "error number 8: name=XTWY\n",
      "1800\n",
      "error number 9: name=ZXIET\n",
      "error number 10: name=ATEST.B\n",
      "1900\n",
      "2000\n",
      "error number 11: name=RCA\n",
      "2100\n",
      "error number 12: name=ZVZZT\n",
      "error number 13: name=LNKB\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "error number 14: name=CBX\n",
      "error number 15: name=GGLS\n",
      "error number 16: name=ATEST\n",
      "2700\n",
      "error number 17: name=IBO\n",
      "2800\n",
      "error number 18: name=ZBZZT\n",
      "2900\n",
      "error number 19: name=ZAZZT\n",
      "3000\n",
      "error number 20: name=ZCZZT\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "error number 21: name=ATEST.A\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "error number 22: name=ZEXIT\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "error number 23: name=DHCNL\n",
      "4100\n",
      "error number 24: name=ZXZZT\n",
      "4200\n",
      "error number 25: name=CBO\n",
      "4300\n",
      "error number 26: name=IBIT\n",
      "4400\n",
      "error number 27: name=ZXYZ.A\n",
      "4500\n",
      "4600\n",
      "error number 28: name=XTRE\n",
      "4700\n",
      "error number 29: name=XTEN\n",
      "error number 30: name=ZVZZC\n",
      "4800\n",
      "error number 31: name=CTEST.V\n",
      "error number 32: name=CTEST.G\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "error number 33: name=ZWZZT\n",
      "5200\n",
      "error number 34: name=NXL\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "error number 35: name=XHLF\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "error number 36: name=ZVV\n",
      "6300\n",
      "6400\n",
      "error number 37: name=FOXO\n",
      "6500\n",
      "error number 38: name=ATEST.C\n",
      "error number 39: name=XFIV\n",
      "6600\n",
      "error number 40: name=CTEST\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "error number 41: name=XTWO\n",
      "7100\n",
      "error number 42: name=THRD\n",
      "7200\n",
      "error number 43: name=OAEM\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "error number 44: name=TAFI\n",
      "7600\n",
      "error number 45: name=IGZ\n",
      "7700\n",
      "7800\n",
      "error number 46: name=CTEST.S\n",
      "7900\n",
      "error number 47: name=STRV\n",
      "8000\n",
      "error number 48: name=SFB\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "error number 49: name=CRBG\n",
      "error number 50: name=GRP.U\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "error number 51: name=YEAR\n",
      "8800\n",
      "error number 52: name=ZIEXT\n",
      "8900\n",
      "9000\n",
      "error number 53: name=DEFI\n",
      "9100\n",
      "error number 54: name=XSVN\n",
      "error number 55: name=CTEST.L\n",
      "9200\n",
      "error number 56: name=XONE\n",
      "9300\n",
      "error number 57: name=EMP\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "error number 58: name=ZTEST\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "error number 59: name=AMPX\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "mini=ticker_list\n",
    "errors=[]\n",
    "data=[]\n",
    "c=0\n",
    "x=list(range(len(mini)))\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(len(mini)):\n",
    "        x[i]=executor.submit(tester_func,mini[i])\n",
    "    \n",
    "    print(\"thread setup complete\")\n",
    "    \n",
    "    for i in range(len(mini)):\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "        r=x[i].result()\n",
    "        if (r[0]): \n",
    "            data.append(r[1])\n",
    "        else:\n",
    "            errors.append(r[1])\n",
    "            c+=1\n",
    "            print(f\"error number {c}: name={errors[-1]}\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e95aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>ONTO</th>\n",
       "      <th>NOGN</th>\n",
       "      <th>COWNL</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>HEPS</th>\n",
       "      <th>DXJ</th>\n",
       "      <th>FRBN</th>\n",
       "      <th>REX</th>\n",
       "      <th>PR</th>\n",
       "      <th>...</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>IGC</th>\n",
       "      <th>OPFI</th>\n",
       "      <th>JPS</th>\n",
       "      <th>CNDT</th>\n",
       "      <th>APYX</th>\n",
       "      <th>KRBN</th>\n",
       "      <th>GCV</th>\n",
       "      <th>FARM</th>\n",
       "      <th>WBIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.995231</td>\n",
       "      <td>0.985957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000731</td>\n",
       "      <td>0.995295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.982692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>1.021322</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.987603</td>\n",
       "      <td>0.995300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008532</td>\n",
       "      <td>0.992476</td>\n",
       "      <td>0.993623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.970564</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000548</td>\n",
       "      <td>0.996727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>1.068230</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004231</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.001001</td>\n",
       "      <td>0.923967</td>\n",
       "      <td>0.974148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005120</td>\n",
       "      <td>0.996580</td>\n",
       "      <td>0.992526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.976236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996894</td>\n",
       "      <td>0.996216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.962479</td>\n",
       "      <td>1.066098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.989657</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.945454</td>\n",
       "      <td>0.971798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006826</td>\n",
       "      <td>0.967852</td>\n",
       "      <td>0.989643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.992709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002558</td>\n",
       "      <td>0.999489</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.995949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.935004</td>\n",
       "      <td>0.982942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.991067</td>\n",
       "      <td>1.015873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.004004</td>\n",
       "      <td>0.950413</td>\n",
       "      <td>0.967097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.006826</td>\n",
       "      <td>0.941861</td>\n",
       "      <td>0.993095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>1.259090</td>\n",
       "      <td>1.821766</td>\n",
       "      <td>0.202832</td>\n",
       "      <td>1.134360</td>\n",
       "      <td>1.242030</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>1.268203</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.027596</td>\n",
       "      <td>1.611940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018092</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>1.948549</td>\n",
       "      <td>1.136384</td>\n",
       "      <td>0.343365</td>\n",
       "      <td>1.064245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>1.262720</td>\n",
       "      <td>1.890359</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>1.133779</td>\n",
       "      <td>1.254682</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>1.286874</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.047930</td>\n",
       "      <td>1.656716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019169</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.707403</td>\n",
       "      <td>1.895037</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.348153</td>\n",
       "      <td>1.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>1.298613</td>\n",
       "      <td>1.930597</td>\n",
       "      <td>0.156642</td>\n",
       "      <td>1.139096</td>\n",
       "      <td>1.276690</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>1.297093</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.062455</td>\n",
       "      <td>1.692964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027783</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.836742</td>\n",
       "      <td>0.674380</td>\n",
       "      <td>0.735605</td>\n",
       "      <td>1.894055</td>\n",
       "      <td>1.138421</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>1.073552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.311922</td>\n",
       "      <td>1.944910</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>1.133466</td>\n",
       "      <td>1.287960</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.064633</td>\n",
       "      <td>1.752665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036936</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.275127</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.692562</td>\n",
       "      <td>0.781434</td>\n",
       "      <td>2.017772</td>\n",
       "      <td>1.142494</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.074628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.270382</td>\n",
       "      <td>1.906562</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>1.125871</td>\n",
       "      <td>1.237671</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>1.272134</td>\n",
       "      <td>1.021298</td>\n",
       "      <td>1.025781</td>\n",
       "      <td>1.665245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.833275</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.727380</td>\n",
       "      <td>1.946095</td>\n",
       "      <td>1.109909</td>\n",
       "      <td>0.370041</td>\n",
       "      <td>1.055890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows × 10569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      ONTO      NOGN     COWNL      SIZE      HEPS  \\\n",
       "2020-01-02  1.000000  1.000000       NaN  1.000000  1.000000       NaN   \n",
       "2020-01-03  0.995231  0.985957       NaN  1.000731  0.995295       NaN   \n",
       "2020-01-06  0.997065  0.970564       NaN  1.000548  0.996727       NaN   \n",
       "2020-01-07  0.993397  0.976236       NaN  0.996894  0.996216       NaN   \n",
       "2020-01-08  0.989362  0.992709       NaN  1.002558  0.999489       NaN   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  1.259090  1.821766  0.202832  1.134360  1.242030  0.073716   \n",
       "2022-09-08  1.262720  1.890359  0.171704  1.133779  1.254682  0.077439   \n",
       "2022-09-09  1.298613  1.930597  0.156642  1.139096  1.276690  0.078183   \n",
       "2022-09-12  1.311922  1.944910  0.151622  1.133466  1.287960  0.083395   \n",
       "2022-09-13  1.270382  1.906562  0.149613  1.125871  1.237671  0.079672   \n",
       "\n",
       "                 DXJ      FRBN       REX        PR  ...      GOOD       IGC  \\\n",
       "2020-01-02  1.000000       NaN  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "2020-01-03  0.982692       NaN  1.003268  1.021322  ...  1.004701  1.000000   \n",
       "2020-01-06  0.990241       NaN  0.993101  1.068230  ...  1.004231  0.984127   \n",
       "2020-01-07  0.990425       NaN  0.962479  1.066098  ...  0.989657  0.984127   \n",
       "2020-01-08  0.995949       NaN  0.935004  0.982942  ...  0.991067  1.015873   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-07  1.268203  1.022312  1.027596  1.611940  ...  1.018092  0.873016   \n",
       "2022-09-08  1.286874  1.022312  1.047930  1.656716  ...  1.019169  0.888889   \n",
       "2022-09-09  1.297093  1.022312  1.062455  1.692964  ...  1.027783  0.873016   \n",
       "2022-09-12  1.295914  1.022312  1.064633  1.752665  ...  1.036936  0.920635   \n",
       "2022-09-13  1.272134  1.021298  1.025781  1.665245  ...  0.998710  0.904762   \n",
       "\n",
       "                OPFI       JPS      CNDT      APYX      KRBN       GCV  \\\n",
       "2020-01-02       NaN  1.000000  1.000000  1.000000       NaN  1.000000   \n",
       "2020-01-03       NaN  1.004004  0.987603  0.995300       NaN  1.008532   \n",
       "2020-01-06       NaN  1.001001  0.923967  0.974148       NaN  1.005120   \n",
       "2020-01-07       NaN  1.004004  0.945454  0.971798       NaN  1.006826   \n",
       "2020-01-08       NaN  1.004004  0.950413  0.967097       NaN  1.006826   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  0.265990  0.841365  0.669421  0.702703  1.948549  1.136384   \n",
       "2022-09-08  0.265990  0.835586  0.659504  0.707403  1.895037  1.124165   \n",
       "2022-09-09  0.268020  0.836742  0.674380  0.735605  1.894055  1.138421   \n",
       "2022-09-12  0.275127  0.841365  0.692562  0.781434  2.017772  1.142494   \n",
       "2022-09-13  0.256853  0.833275  0.669421  0.727380  1.946095  1.109909   \n",
       "\n",
       "                FARM      WBIG  \n",
       "2020-01-02  1.000000  1.000000  \n",
       "2020-01-03  0.992476  0.993623  \n",
       "2020-01-06  0.996580  0.992526  \n",
       "2020-01-07  0.967852  0.989643  \n",
       "2020-01-08  0.941861  0.993095  \n",
       "...              ...       ...  \n",
       "2022-09-07  0.343365  1.064245  \n",
       "2022-09-08  0.348153  1.064783  \n",
       "2022-09-09  0.374829  1.073552  \n",
       "2022-09-12  0.372093  1.074628  \n",
       "2022-09-13  0.370041  1.055890  \n",
       "\n",
       "[680 rows x 10569 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame(data).transpose()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44ff54e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>ONTO</th>\n",
       "      <th>NOGN</th>\n",
       "      <th>COWNL</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>HEPS</th>\n",
       "      <th>DXJ</th>\n",
       "      <th>FRBN</th>\n",
       "      <th>REX</th>\n",
       "      <th>PR</th>\n",
       "      <th>...</th>\n",
       "      <th>GOOD</th>\n",
       "      <th>IGC</th>\n",
       "      <th>OPFI</th>\n",
       "      <th>JPS</th>\n",
       "      <th>CNDT</th>\n",
       "      <th>APYX</th>\n",
       "      <th>KRBN</th>\n",
       "      <th>GCV</th>\n",
       "      <th>FARM</th>\n",
       "      <th>WBIG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-07</th>\n",
       "      <td>1.452672</td>\n",
       "      <td>2.259519</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.133254</td>\n",
       "      <td>1.303582</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>1.295589</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.149843</td>\n",
       "      <td>2.040512</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081622</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.322843</td>\n",
       "      <td>0.882971</td>\n",
       "      <td>0.912397</td>\n",
       "      <td>0.853114</td>\n",
       "      <td>2.352104</td>\n",
       "      <td>1.213772</td>\n",
       "      <td>0.350889</td>\n",
       "      <td>1.125753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>1.437347</td>\n",
       "      <td>2.178774</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.120102</td>\n",
       "      <td>1.287057</td>\n",
       "      <td>0.074460</td>\n",
       "      <td>1.291705</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.133866</td>\n",
       "      <td>1.997868</td>\n",
       "      <td>...</td>\n",
       "      <td>1.062240</td>\n",
       "      <td>1.301587</td>\n",
       "      <td>0.354315</td>\n",
       "      <td>0.886438</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.836663</td>\n",
       "      <td>2.356522</td>\n",
       "      <td>1.211736</td>\n",
       "      <td>0.346785</td>\n",
       "      <td>1.116860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-09</th>\n",
       "      <td>1.403873</td>\n",
       "      <td>2.113962</td>\n",
       "      <td>1.005121</td>\n",
       "      <td>1.109142</td>\n",
       "      <td>1.253619</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>1.283938</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.151779</td>\n",
       "      <td>2.017058</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040166</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.332995</td>\n",
       "      <td>0.878348</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.881316</td>\n",
       "      <td>2.339339</td>\n",
       "      <td>1.199516</td>\n",
       "      <td>0.350205</td>\n",
       "      <td>1.106767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10</th>\n",
       "      <td>1.378062</td>\n",
       "      <td>2.019984</td>\n",
       "      <td>1.006125</td>\n",
       "      <td>1.098182</td>\n",
       "      <td>1.216088</td>\n",
       "      <td>0.067014</td>\n",
       "      <td>1.260830</td>\n",
       "      <td>1.006085</td>\n",
       "      <td>1.120673</td>\n",
       "      <td>1.972281</td>\n",
       "      <td>...</td>\n",
       "      <td>1.037474</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.338071</td>\n",
       "      <td>0.862168</td>\n",
       "      <td>0.819835</td>\n",
       "      <td>0.733255</td>\n",
       "      <td>2.353577</td>\n",
       "      <td>1.230064</td>\n",
       "      <td>0.344049</td>\n",
       "      <td>1.097791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>1.324021</td>\n",
       "      <td>1.941399</td>\n",
       "      <td>1.004117</td>\n",
       "      <td>1.097174</td>\n",
       "      <td>1.162290</td>\n",
       "      <td>0.057930</td>\n",
       "      <td>1.237140</td>\n",
       "      <td>1.014199</td>\n",
       "      <td>1.035706</td>\n",
       "      <td>1.846482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.315736</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.737190</td>\n",
       "      <td>0.730905</td>\n",
       "      <td>2.291227</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.329685</td>\n",
       "      <td>1.077440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-07</th>\n",
       "      <td>1.259090</td>\n",
       "      <td>1.821766</td>\n",
       "      <td>0.202832</td>\n",
       "      <td>1.134360</td>\n",
       "      <td>1.242030</td>\n",
       "      <td>0.073716</td>\n",
       "      <td>1.268203</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.027596</td>\n",
       "      <td>1.611940</td>\n",
       "      <td>...</td>\n",
       "      <td>1.018092</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>1.948549</td>\n",
       "      <td>1.136384</td>\n",
       "      <td>0.343365</td>\n",
       "      <td>1.064245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-08</th>\n",
       "      <td>1.262720</td>\n",
       "      <td>1.890359</td>\n",
       "      <td>0.171704</td>\n",
       "      <td>1.133779</td>\n",
       "      <td>1.254682</td>\n",
       "      <td>0.077439</td>\n",
       "      <td>1.286874</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.047930</td>\n",
       "      <td>1.656716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.019169</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.265990</td>\n",
       "      <td>0.835586</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.707403</td>\n",
       "      <td>1.895037</td>\n",
       "      <td>1.124165</td>\n",
       "      <td>0.348153</td>\n",
       "      <td>1.064783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-09</th>\n",
       "      <td>1.298613</td>\n",
       "      <td>1.930597</td>\n",
       "      <td>0.156642</td>\n",
       "      <td>1.139096</td>\n",
       "      <td>1.276690</td>\n",
       "      <td>0.078183</td>\n",
       "      <td>1.297093</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.062455</td>\n",
       "      <td>1.692964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027783</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.836742</td>\n",
       "      <td>0.674380</td>\n",
       "      <td>0.735605</td>\n",
       "      <td>1.894055</td>\n",
       "      <td>1.138421</td>\n",
       "      <td>0.374829</td>\n",
       "      <td>1.073552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.311922</td>\n",
       "      <td>1.944910</td>\n",
       "      <td>0.151622</td>\n",
       "      <td>1.133466</td>\n",
       "      <td>1.287960</td>\n",
       "      <td>0.083395</td>\n",
       "      <td>1.295914</td>\n",
       "      <td>1.022312</td>\n",
       "      <td>1.064633</td>\n",
       "      <td>1.752665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036936</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.275127</td>\n",
       "      <td>0.841365</td>\n",
       "      <td>0.692562</td>\n",
       "      <td>0.781434</td>\n",
       "      <td>2.017772</td>\n",
       "      <td>1.142494</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.074628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.270382</td>\n",
       "      <td>1.906562</td>\n",
       "      <td>0.149613</td>\n",
       "      <td>1.125871</td>\n",
       "      <td>1.237671</td>\n",
       "      <td>0.079672</td>\n",
       "      <td>1.272134</td>\n",
       "      <td>1.021298</td>\n",
       "      <td>1.025781</td>\n",
       "      <td>1.665245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.256853</td>\n",
       "      <td>0.833275</td>\n",
       "      <td>0.669421</td>\n",
       "      <td>0.727380</td>\n",
       "      <td>1.946095</td>\n",
       "      <td>1.109909</td>\n",
       "      <td>0.370041</td>\n",
       "      <td>1.055890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 10569 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES      ONTO      NOGN     COWNL      SIZE      HEPS  \\\n",
       "2022-06-07  1.452672  2.259519  1.006125  1.133254  1.303582  0.074460   \n",
       "2022-06-08  1.437347  2.178774  1.006125  1.120102  1.287057  0.074460   \n",
       "2022-06-09  1.403873  2.113962  1.005121  1.109142  1.253619  0.070737   \n",
       "2022-06-10  1.378062  2.019984  1.006125  1.098182  1.216088  0.067014   \n",
       "2022-06-13  1.324021  1.941399  1.004117  1.097174  1.162290  0.057930   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  1.259090  1.821766  0.202832  1.134360  1.242030  0.073716   \n",
       "2022-09-08  1.262720  1.890359  0.171704  1.133779  1.254682  0.077439   \n",
       "2022-09-09  1.298613  1.930597  0.156642  1.139096  1.276690  0.078183   \n",
       "2022-09-12  1.311922  1.944910  0.151622  1.133466  1.287960  0.083395   \n",
       "2022-09-13  1.270382  1.906562  0.149613  1.125871  1.237671  0.079672   \n",
       "\n",
       "                 DXJ      FRBN       REX        PR  ...      GOOD       IGC  \\\n",
       "2022-06-07  1.295589  1.006085  1.149843  2.040512  ...  1.081622  0.666667   \n",
       "2022-06-08  1.291705  1.006085  1.133866  1.997868  ...  1.062240  1.301587   \n",
       "2022-06-09  1.283938  1.006085  1.151779  2.017058  ...  1.040166  0.984127   \n",
       "2022-06-10  1.260830  1.006085  1.120673  1.972281  ...  1.037474  0.825397   \n",
       "2022-06-13  1.237140  1.014199  1.035706  1.846482  ...  0.998710  0.761905   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-07  1.268203  1.022312  1.027596  1.611940  ...  1.018092  0.873016   \n",
       "2022-09-08  1.286874  1.022312  1.047930  1.656716  ...  1.019169  0.888889   \n",
       "2022-09-09  1.297093  1.022312  1.062455  1.692964  ...  1.027783  0.873016   \n",
       "2022-09-12  1.295914  1.022312  1.064633  1.752665  ...  1.036936  0.920635   \n",
       "2022-09-13  1.272134  1.021298  1.025781  1.665245  ...  0.998710  0.904762   \n",
       "\n",
       "                OPFI       JPS      CNDT      APYX      KRBN       GCV  \\\n",
       "2022-06-07  0.322843  0.882971  0.912397  0.853114  2.352104  1.213772   \n",
       "2022-06-08  0.354315  0.886438  0.890909  0.836663  2.356522  1.211736   \n",
       "2022-06-09  0.332995  0.878348  0.867769  0.881316  2.339339  1.199516   \n",
       "2022-06-10  0.338071  0.862168  0.819835  0.733255  2.353577  1.230064   \n",
       "2022-06-13  0.315736  0.835586  0.737190  0.730905  2.291227  1.124165   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-07  0.265990  0.841365  0.669421  0.702703  1.948549  1.136384   \n",
       "2022-09-08  0.265990  0.835586  0.659504  0.707403  1.895037  1.124165   \n",
       "2022-09-09  0.268020  0.836742  0.674380  0.735605  1.894055  1.138421   \n",
       "2022-09-12  0.275127  0.841365  0.692562  0.781434  2.017772  1.142494   \n",
       "2022-09-13  0.256853  0.833275  0.669421  0.727380  1.946095  1.109909   \n",
       "\n",
       "                FARM      WBIG  \n",
       "2022-06-07  0.350889  1.125753  \n",
       "2022-06-08  0.346785  1.116860  \n",
       "2022-06-09  0.350205  1.106767  \n",
       "2022-06-10  0.344049  1.097791  \n",
       "2022-06-13  0.329685  1.077440  \n",
       "...              ...       ...  \n",
       "2022-09-07  0.343365  1.064245  \n",
       "2022-09-08  0.348153  1.064783  \n",
       "2022-09-09  0.374829  1.073552  \n",
       "2022-09-12  0.372093  1.074628  \n",
       "2022-09-13  0.370041  1.055890  \n",
       "\n",
       "[68 rows x 10569 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=data_df.iloc[:-68]\n",
    "test_df=data_df.iloc[-68:]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a7d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644 stocks were droped\n"
     ]
    }
   ],
   "source": [
    "ticker_list=data_df.columns\n",
    "print(f\"{len(symbols)-len(ticker_list)} stocks were droped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efabaa",
   "metadata": {},
   "source": [
    "# preprocessing \n",
    "\n",
    "\n",
    "1. ticker: this is also used to select which stocks come to the model\n",
    "\n",
    "2. price: we take the ratio: (importantly we did drop some potentialy important indicators)\n",
    "\n",
    "3. date: the day and month are floating point numbers. while year and day of the week are embedings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "673271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "look=layers.StringLookup(vocabulary=ticker_list,num_oov_indices=0)\n",
    "inv_look=layers.StringLookup(vocabulary=ticker_list,invert=True,num_oov_indices=0)\n",
    "tick_embed=layers.Embedding(len(ticker_list)+1,512,embeddings_constraint= tf.keras.constraints.unit_norm)\n",
    "day_embed=layers.Embedding(7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47802c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17,), dtype=string, numpy=\n",
       "array([b'GRES', b'ONTO', b'NOGN', b'COWNL', b'SIZE', b'HEPS', b'DXJ',\n",
       "       b'FRBN', b'REX', b'PR', b'MDWD', b'LEVI', b'HMC', b'AIKI', b'SPUC',\n",
       "       b'FANG', b'SAVN'], dtype=object)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices(ticker_list)\n",
    "exmple=dataset.batch(17).take(1).get_single_element()\n",
    "exmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a701202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df[exmple.numpy().astype('U13')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251a654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)],\n",
       " [range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def thread_distribute(l,f,n=1):\n",
    "    if(n==0):\n",
    "        return f(l)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor: \n",
    "        l=[executor.submit(lambda x: thread_distribute(x,f,n-1),x) for x in l]\n",
    "        l= [x.result() for x in l]\n",
    "    return l\n",
    "\n",
    "thread_distribute([range(5) for i in range(2)],lambda x: range(x),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d5f1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>MPC</th>\n",
       "      <th>CSTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.995231</td>\n",
       "      <td>0.940559</td>\n",
       "      <td>0.994751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.996063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.955258</td>\n",
       "      <td>0.988845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.945243</td>\n",
       "      <td>0.991470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1.416375</td>\n",
       "      <td>1.823218</td>\n",
       "      <td>0.617824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>1.414359</td>\n",
       "      <td>1.861191</td>\n",
       "      <td>0.640204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1.434927</td>\n",
       "      <td>1.867639</td>\n",
       "      <td>0.664618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>1.429281</td>\n",
       "      <td>1.891819</td>\n",
       "      <td>0.637491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06</th>\n",
       "      <td>1.432507</td>\n",
       "      <td>1.959346</td>\n",
       "      <td>0.663940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES       MPC      CSTE\n",
       "2020-01-02  1.000000  1.000000  1.000000\n",
       "2020-01-03  0.995231  0.940559  0.994751\n",
       "2020-01-06  0.997065  0.940397  0.996063\n",
       "2020-01-07  0.993397  0.955258  0.988845\n",
       "2020-01-08  0.989362  0.945243  0.991470\n",
       "...              ...       ...       ...\n",
       "2022-05-31  1.416375  1.823218  0.617824\n",
       "2022-06-01  1.414359  1.861191  0.640204\n",
       "2022-06-02  1.434927  1.867639  0.664618\n",
       "2022-06-03  1.429281  1.891819  0.637491\n",
       "2022-06-06  1.432507  1.959346  0.663940\n",
       "\n",
       "[612 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_stocks(x,data_df=train_df):\n",
    "    a=tick_embed(look(ticker_list))\n",
    "    b=tick_embed(look(x))\n",
    "\n",
    "    b=b@tf.transpose(a)\n",
    "    b=tf.nn.top_k(b,3)\n",
    "\n",
    "\n",
    "    tickers=inv_look([list(x) for x in b[1].numpy()]).numpy().astype('U13')\n",
    "    \n",
    "    return [[data_df[x] for x in sub] for sub in tickers]\n",
    "    #return thread_distribute(tickers,lambda x: data_df[x],2)\n",
    "\n",
    "a=choose_stocks(exmple)\n",
    "\n",
    "pd.DataFrame(a[0]).transpose().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8a28548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-02', '2020-01-03', '2020-01-06', '2020-01-07',\n",
       "               '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-13',\n",
       "               '2020-01-14', '2020-01-15',\n",
       "               ...\n",
       "               '2022-05-23', '2022-05-24', '2022-05-25', '2022-05-26',\n",
       "               '2022-05-27', '2022-05-31', '2022-06-01', '2022-06-02',\n",
       "               '2022-06-03', '2022-06-06'],\n",
       "              dtype='datetime64[ns]', length=612, freq=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fd4c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.06666666666666667, 0.08333333333333333, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_encode(a):\n",
    "    #a=a.index\n",
    "    return (a.day_of_week,a.day/30,a.month/12,(a.year-2020))\n",
    "    \n",
    "time_encode(data_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d387f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(17, 3, 612), dtype=int32, numpy=\n",
       " array([[[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]],\n",
       " \n",
       "        [[3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0],\n",
       "         [3, 4, 0, ..., 3, 4, 0]]])>,\n",
       " <tf.Tensor: shape=(17, 3, 612), dtype=float64, numpy=\n",
       " array([[[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]],\n",
       " \n",
       "        [[0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ],\n",
       "         [0.06666667, 0.1       , 0.2       , ..., 0.06666667,\n",
       "          0.1       , 0.2       ]]])>,\n",
       " <tf.Tensor: shape=(17, 3, 612), dtype=float64, numpy=\n",
       " array([[[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]],\n",
       " \n",
       "        [[0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ],\n",
       "         [0.08333333, 0.08333333, 0.08333333, ..., 0.5       ,\n",
       "          0.5       , 0.5       ]]])>,\n",
       " <tf.Tensor: shape=(17, 3, 612), dtype=int32, numpy=\n",
       " array([[[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]],\n",
       " \n",
       "        [[0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 2, 2, 2]]])>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_tensors(a):\n",
    "    x=thread_distribute(a,lambda x:time_encode(x.index),2)\n",
    "    x=[thread_distribute(x,lambda x: x[i],2) for i in range(4)]\n",
    "    return [tf.constant(x) for x in x]\n",
    "\n",
    "time_tensors(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa725f",
   "metadata": {},
   "source": [
    "# time handeling \n",
    "\n",
    "problems with the data in curent time format:\n",
    "\n",
    "1. there are null entries especialy from before a company was made \n",
    "2. the time diffrence between entries isnt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16159624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, ...,  True,  True,  True],\n",
       "       [ True,  True, False, ...,  True,  True,  True],\n",
       "       [ True,  True, False, ...,  True,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=np.logical_not(data_df.isna().to_numpy())\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a993565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>MPC</th>\n",
       "      <th>CSTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>0.995231</td>\n",
       "      <td>0.940559</td>\n",
       "      <td>0.994751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>0.997065</td>\n",
       "      <td>0.940397</td>\n",
       "      <td>0.996063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>0.993397</td>\n",
       "      <td>0.955258</td>\n",
       "      <td>0.988845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.945243</td>\n",
       "      <td>0.991470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>1.416375</td>\n",
       "      <td>1.823218</td>\n",
       "      <td>0.617824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>1.414359</td>\n",
       "      <td>1.861191</td>\n",
       "      <td>0.640204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1.434927</td>\n",
       "      <td>1.867639</td>\n",
       "      <td>0.664618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>1.429281</td>\n",
       "      <td>1.891819</td>\n",
       "      <td>0.637491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06</th>\n",
       "      <td>1.432507</td>\n",
       "      <td>1.959346</td>\n",
       "      <td>0.663940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES       MPC      CSTE\n",
       "2020-01-02  1.000000  1.000000  1.000000\n",
       "2020-01-03  0.995231  0.940559  0.994751\n",
       "2020-01-06  0.997065  0.940397  0.996063\n",
       "2020-01-07  0.993397  0.955258  0.988845\n",
       "2020-01-08  0.989362  0.945243  0.991470\n",
       "...              ...       ...       ...\n",
       "2022-05-31  1.416375  1.823218  0.617824\n",
       "2022-06-01  1.414359  1.861191  0.640204\n",
       "2022-06-02  1.434927  1.867639  0.664618\n",
       "2022-06-03  1.429281  1.891819  0.637491\n",
       "2022-06-06  1.432507  1.959346  0.663940\n",
       "\n",
       "[612 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_stocks_df(x,data_df=train_df):\n",
    "    a=tick_embed(look(ticker_list))\n",
    "    b=tick_embed(look(x))\n",
    "\n",
    "    b=b@tf.transpose(a)\n",
    "    b=tf.nn.top_k(b,3)\n",
    "\n",
    "\n",
    "    tickers=inv_look([list(x) for x in b[1].numpy()]).numpy().astype('U13')\n",
    "    \n",
    "    \n",
    "    return [pd.DataFrame([data_df[x] for x in sub]).transpose().dropna() for sub in tickers]\n",
    "\n",
    "v=choose_stocks_df(exmple)\n",
    "v[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f75c44e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorShape([17, 612]), tf.int32),\n",
       " (TensorShape([17, 612]), tf.float32),\n",
       " (TensorShape([17, 612]), tf.float32),\n",
       " (TensorShape([17, 612]), tf.int32),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 612]), tf.float64),\n",
       " (TensorShape([17, 3]), tf.string)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to add the tickers strings/ints\n",
    "def get_xs(v):\n",
    "    t=[x.index for x in v]\n",
    "    t=thread_distribute(t,time_encode,2)\n",
    "    #t=[[x[i] for x in t] for i in range(4)]\n",
    "    t=[thread_distribute(t,lambda x: x[i],2) for i in range(4)]\n",
    "    #thread_distribute(t,len,2)\n",
    "    t=[tf.ragged.constant(x) for x in t]\n",
    "    \n",
    "    x=thread_distribute(v,lambda x: x.to_numpy(),1)\n",
    "    vals=tf.concat(x,axis=0)\n",
    "    lengths=[len(s) for s in x]\n",
    "    x=tf.RaggedTensor.from_row_lengths(vals,lengths)\n",
    "    #[x.shape for x in x]\n",
    "    \n",
    "    \"padding\"\n",
    "    x=(x+1).to_tensor()-1\n",
    "    t=[(x+1).to_tensor()-1 for x in t] \n",
    "    \n",
    "    x=tf.transpose(x,[2,0,1])\n",
    "    t.extend(x) \n",
    "    \n",
    "    tickers=tf.constant([x.transpose().index for x in v])\n",
    "    t.append(tickers)\n",
    "    return t\n",
    "\n",
    "xs=get_xs(v)\n",
    "[(x.shape,x.dtype) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "755a743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(x) for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8e380cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRES</th>\n",
       "      <th>MPC</th>\n",
       "      <th>CSTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-12</th>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.607526</td>\n",
       "      <td>0.728346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-15</th>\n",
       "      <td>0.918562</td>\n",
       "      <td>0.627766</td>\n",
       "      <td>0.743438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-16</th>\n",
       "      <td>0.926632</td>\n",
       "      <td>0.641038</td>\n",
       "      <td>0.774934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-17</th>\n",
       "      <td>0.918562</td>\n",
       "      <td>0.615987</td>\n",
       "      <td>0.767060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-18</th>\n",
       "      <td>0.920763</td>\n",
       "      <td>0.638218</td>\n",
       "      <td>0.746719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>0.935070</td>\n",
       "      <td>0.474798</td>\n",
       "      <td>0.682415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>0.913059</td>\n",
       "      <td>0.463176</td>\n",
       "      <td>0.648950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>0.920396</td>\n",
       "      <td>0.485577</td>\n",
       "      <td>0.641076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>0.922230</td>\n",
       "      <td>0.496862</td>\n",
       "      <td>0.633202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-02</th>\n",
       "      <td>0.938371</td>\n",
       "      <td>0.527179</td>\n",
       "      <td>0.662730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GRES       MPC      CSTE\n",
       "2020-06-12  0.913793  0.607526  0.728346\n",
       "2020-06-15  0.918562  0.627766  0.743438\n",
       "2020-06-16  0.926632  0.641038  0.774934\n",
       "2020-06-17  0.918562  0.615987  0.767060\n",
       "2020-06-18  0.920763  0.638218  0.746719\n",
       "...              ...       ...       ...\n",
       "2020-10-27  0.935070  0.474798  0.682415\n",
       "2020-10-28  0.913059  0.463176  0.648950\n",
       "2020-10-29  0.920396  0.485577  0.641076\n",
       "2020-10-30  0.922230  0.496862  0.633202\n",
       "2020-11-02  0.938371  0.527179  0.662730\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_seq(x,LEN=100):\n",
    "    l=len(x)\n",
    "    if(l<LEN):\n",
    "        return x \n",
    "    \n",
    "    start=np.random.randint(l-LEN)\n",
    "    return x.iloc[start:start+LEN]\n",
    "sample_seq(v[-1]) \n",
    "sample_seq(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af077c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "base=[sample_seq(x) for x in v]\n",
    "y=[s.iloc[1:,0] for s in base]\n",
    "x=[s[:-1] for s in base]\n",
    "x=get_xs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "dd0f22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0266008377075195\n"
     ]
    }
   ],
   "source": [
    "def get_numbers(tickers):\n",
    "    v=choose_stocks_df(tickers)\n",
    "    base=[sample_seq(x) for x in v]\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73d7c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 3), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs=[tf.TensorSpec.from_tensor(x) for x in n]\n",
    "s=[list(x.shape) for x in specs]\n",
    "for x in s:\n",
    "    x[0]=None\n",
    "specs=[tf.TensorSpec(s[i],specs[i].dtype) for i in range(len(specs))]\n",
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3332fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 3), 4)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_x(*args):\n",
    "    return args[:-1]\n",
    "\n",
    "def gather_y(*args):\n",
    "    return args[-1]\n",
    "\n",
    "gather_x(1,2,3,4),gather_y(1,2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c202fac",
   "metadata": {},
   "source": [
    "# train dataset \n",
    "because of the need to use the dataset as a refrence type in the pandas df we are forcing tensorflow to run the whole thing eagerly. \n",
    "\n",
    "it shouldnt be a major issue since most the heavy lifting is done in pandas which is optimized c code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "aa0fa0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "train_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=train_dataset.map(gather_x)\n",
    "dataset_y=train_dataset.map(gather_y)\n",
    "train_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=train_dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "04dd2a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 3), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37c7bed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': (<tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[1, 2, 3, ..., 4, 0, 1],\n",
       "         [1, 2, 3, ..., 1, 2, 3],\n",
       "         [1, 2, 3, ..., 2, 3, 4],\n",
       "         ...,\n",
       "         [3, 4, 0, ..., 2, 3, 4],\n",
       "         [2, 3, 4, ..., 2, 3, 4],\n",
       "         [3, 4, 0, ..., 2, 3, 4]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[0.9       , 0.9333334 , 0.9666667 , ..., 0.33333337, 0.4333334 ,\n",
       "          0.4666667 ],\n",
       "         [0.6333333 , 0.66666675, 0.70000005, ..., 0.26666665, 0.29999995,\n",
       "          0.33333337],\n",
       "         [0.4333334 , 0.4666667 , 0.5       , ..., 0.10000002, 0.13333333,\n",
       "          0.16666663],\n",
       "         ...,\n",
       "         [1.        , 1.0333333 , 0.10000002, ..., 0.6       , 0.6333333 ,\n",
       "          0.66666675],\n",
       "         [0.10000002, 0.13333333, 0.16666663, ..., 0.76666665, 0.79999995,\n",
       "          0.83333325],\n",
       "         [0.20000005, 0.23333335, 0.33333337, ..., 0.83333325, 0.8666667 ,\n",
       "          0.9       ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[0.58333325, 0.58333325, 0.58333325, ..., 1.        , 1.        ,\n",
       "          1.        ],\n",
       "         [0.83333325, 0.83333325, 0.83333325, ..., 0.25      , 0.25      ,\n",
       "          0.25      ],\n",
       "         [0.83333325, 0.83333325, 0.83333325, ..., 0.25      , 0.25      ,\n",
       "          0.25      ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 0.08333337, ..., 0.41666663, 0.41666663,\n",
       "          0.41666663],\n",
       "         [0.91666675, 0.91666675, 0.91666675, ..., 0.25      , 0.25      ,\n",
       "          0.25      ],\n",
       "         [0.08333337, 0.08333337, 0.08333337, ..., 0.41666663, 0.41666663,\n",
       "          0.41666663]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 1, ..., 2, 2, 2],\n",
       "         [0, 0, 0, ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 2, ..., 2, 2, 2],\n",
       "         [1, 1, 1, ..., 2, 2, 2],\n",
       "         [2, 2, 2, ..., 2, 2, 2]])>),\n",
       " 'prices': (<tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[1.32813342, 1.33566432, 1.34211945, ..., 1.4410974 , 1.47552448,\n",
       "          1.48574506],\n",
       "         [0.99694397, 1.0186757 , 1.00271647, ..., 0.70424446, 0.73480471,\n",
       "          0.71273342],\n",
       "         [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
       "          1.        ],\n",
       "         ...,\n",
       "         [0.50103779, 0.4894147 , 0.51681196, ..., 0.24034872, 0.2601356 ,\n",
       "          0.2620728 ],\n",
       "         [1.29986033, 1.28487036, 1.29080849, ..., 1.02166716, 1.04374699,\n",
       "          1.04806071],\n",
       "         [0.62190814, 0.60777388, 0.60777388, ..., 0.40989399, 0.4240283 ,\n",
       "          0.45229682]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[0.73853029, 0.74890289, 0.72608316, ..., 0.76342459, 0.75720103,\n",
       "          0.76342459],\n",
       "         [0.77647061, 0.76862748, 0.77058826, ..., 0.29313726, 0.30784315,\n",
       "          0.30588235],\n",
       "         [0.99800395, 0.99800395, 1.        , ..., 1.0429141 , 1.0319361 ,\n",
       "          1.01996006],\n",
       "         ...,\n",
       "         [0.97332021, 0.97727277, 0.97727277, ..., 0.95553362, 0.95750985,\n",
       "          0.95553362],\n",
       "         [5.00798731, 4.84025564, 4.72044726, ..., 2.30830684, 2.18450475,\n",
       "          2.12460075],\n",
       "         [0.89694041, 0.89210959, 0.88298451, ..., 0.37144393, 0.37573807,\n",
       "          0.39989265]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[1.45823095, 1.4609258 , 1.46140479, ..., 1.59308935, 1.59147255,\n",
       "          1.53057062],\n",
       "         [1.0433313 , 1.04036282, 1.05066997, ..., 0.85058756, 0.88394151,\n",
       "          0.87948883],\n",
       "         [0.52739723, 0.52226025, 0.51369862, ..., 1.14212327, 1.07876713,\n",
       "          1.08561644],\n",
       "         ...,\n",
       "         [1.08813327, 1.08538886, 1.09362187, ..., 1.36695882, 1.37217304,\n",
       "          1.33731984],\n",
       "         [1.62996872, 1.61347359, 1.67412475, ..., 1.35843405, 1.36680852,\n",
       "          1.37645183],\n",
       "         [1.29806114, 1.33883399, 1.34754459, ..., 1.33234742, 1.33679534,\n",
       "          1.35644056]])>),\n",
       " 'tickers': <tf.Tensor: shape=(32, 3), dtype=string, numpy=\n",
       " array([[b'SFM', b'QUAD', b'CRM'],\n",
       "        [b'PUBM', b'CLOV', b'NUGO'],\n",
       "        [b'SVA', b'SST', b'SCX'],\n",
       "        [b'ACBAU', b'FSTR', b'CFFS'],\n",
       "        [b'ACRO.U', b'FJUN', b'DAM'],\n",
       "        [b'ACHC', b'ONEY', b'SSUS'],\n",
       "        [b'BWAQ', b'FLCH', b'FRST'],\n",
       "        [b'ECC', b'VPG', b'PCCTU'],\n",
       "        [b'BSCP', b'IWFH', b'OPRT'],\n",
       "        [b'PSNL', b'MCG', b'PETZ'],\n",
       "        [b'FCOM', b'FEM', b'ASR'],\n",
       "        [b'EES', b'IDNA', b'HTBI'],\n",
       "        [b'EHTH', b'GD', b'CCEL'],\n",
       "        [b'JHME', b'THLV', b'AMRX'],\n",
       "        [b'TBLT', b'LDP', b'UTL'],\n",
       "        [b'IWX', b'MGK', b'AIRC'],\n",
       "        [b'GLEEU', b'WRND', b'EAST'],\n",
       "        [b'BSTZ', b'BIL', b'UFPI'],\n",
       "        [b'KULR', b'TCOA.U', b'FR'],\n",
       "        [b'NMM', b'JSCP', b'OSTRU'],\n",
       "        [b'MGC', b'BBSC', b'UTZ'],\n",
       "        [b'BPAY', b'IAT', b'SDG'],\n",
       "        [b'BVXV', b'AMNB', b'MDRX'],\n",
       "        [b'WSC', b'IHYF', b'JUSA'],\n",
       "        [b'FRTY', b'STIM', b'MDY'],\n",
       "        [b'KLAQU', b'GDXJ', b'LUMO'],\n",
       "        [b'MET', b'ACM', b'MVBF'],\n",
       "        [b'CNTQ', b'NVOS', b'DBP'],\n",
       "        [b'EAOR', b'GNACU', b'J'],\n",
       "        [b'BIGC', b'DNAB', b'MEOH'],\n",
       "        [b'LEA', b'SUNW', b'SYBT'],\n",
       "        [b'TENX', b'EGHT', b'RIO']], dtype=object)>}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut23(x):\n",
    "    return {\"time\":x[:4],\"prices\":x[4:7],\"tickers\":x[7]}\n",
    "\n",
    "cut23(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a57f34a",
   "metadata": {},
   "source": [
    "# validation dataset \n",
    "on infrance the best results would probably be achived by runing on every time entry with at least some memory of the past\n",
    "\n",
    "that means there would need to be some precomputation which we can make diffrent for timesetep. \n",
    "\n",
    "this is rediclously slow and combersom to write so our validation is just gona look mostly like the training. \n",
    "after choosing the stocks we would want to work with we are going to think of test behivior \n",
    "\n",
    "we may want to just train a new model from scratch only on that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78c9e75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6580774784088135\n"
     ]
    }
   ],
   "source": [
    "def get_val_numbers(tickers):\n",
    "    base=choose_stocks_df(tickers,test_df)\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_val_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1647a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "val_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_val_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=val_dataset.map(gather_x)\n",
    "dataset_y=val_dataset.map(gather_y)\n",
    "val_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=val_dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "485a0339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 67), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 67), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 3), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af1813a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
