{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84595fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin\n",
    "NUM_STOCKS=10\n",
    "import yahoo_fin as yf\n",
    "from yahoo_fin.stock_info import get_data\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21afa2b0",
   "metadata": {},
   "source": [
    "# getting data\n",
    "\n",
    "things we did to clean data:\n",
    "\n",
    "1. shamelessly copy:\n",
    "https://levelup.gitconnected.com/how-to-get-all-stock-symbols-a73925c16a1b\n",
    "\n",
    "2. we removed the tickers with $\n",
    "\n",
    "3. we added exception handeling that tries similer strings to the input (note that this is not implemented on the set itself but when fetching, leading to multiple requsts and potentialy to errors)\n",
    "4.  we just drop exceptions that are found when getting the data from online  (these are diffrent every day)\n",
    "\n",
    "# how are we keeping consistency? \n",
    "since the avilble stocks may change depending on the source of the data some extra steps need to be done in order to\n",
    "alow saves to work seemlesly \n",
    "\n",
    "\n",
    "basic plan:\n",
    "\n",
    "1. clean the data as much as possible \n",
    "\n",
    "2. save the embedings weights with their ticker string\n",
    "\n",
    "3. backup everything on git to alow us to fix it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b0bece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame( si.tickers_sp500() )\n",
    "df2 = pd.DataFrame( si.tickers_nasdaq() )\n",
    "df3 = pd.DataFrame( si.tickers_dow() )\n",
    "df4 = pd.DataFrame( si.tickers_other() )\n",
    "\n",
    "sym1 = set( symbol for symbol in df1[0].values.tolist() )\n",
    "sym2 = set( symbol for symbol in df2[0].values.tolist() )\n",
    "sym3 = set( symbol for symbol in df3[0].values.tolist() )\n",
    "sym4 = set( symbol for symbol in df4[0].values.tolist() )\n",
    "\n",
    "symbols = set.union( sym1, sym2, sym3, sym4 )\n",
    "del(sym1, sym2, sym3, sym4,df1, df2, df3, df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "469a803d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1582 unqualified stock symbols...\n",
      "There are 10623 qualified stock symbols...\n"
     ]
    }
   ],
   "source": [
    "my_list = ['W', 'R', 'P', 'Q']\n",
    "del_set = set()\n",
    "sav_set = set()\n",
    "\n",
    "for symbol in symbols:\n",
    "    if (len( symbol ) > 4 and symbol[-1] in my_list or \"$\" in symbol):\n",
    "        del_set.add( symbol )\n",
    "    else:\n",
    "        sav_set.add( symbol )\n",
    "sav_set.discard(\"\") \n",
    "\n",
    "ticker_list=list(sav_set)\n",
    "\n",
    "print( f'Removed {len( del_set )} unqualified stock symbols...' )\n",
    "print( f'There are {len( sav_set )} qualified stock symbols...' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5d42362",
   "metadata": {},
   "outputs": [],
   "source": [
    "start='01/01/2020' \n",
    "end='09/19/2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3c39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures \n",
    "\n",
    "def get_seiries(ticker,start,end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        raw = get_data(ticker.split(\".\")[0], start_date=start, end_date=end)[entry]\n",
    "    except: \n",
    "        try:\n",
    "            raw = get_data(ticker.replace(\".\",\"-\"), start_date=start, end_date=end)[entry]\n",
    "        except:\n",
    "            raw = get_data(ticker[0:4], start_date=start, end_date=end)[entry]\n",
    "    return raw/raw[0]\n",
    "\n",
    "def get_df(l,start,end,entry=\"adjclose\"):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        x=[executor.submit(lambda x: get_seiries(x,start,end,entry=entry),name)for name in l]\n",
    "        x=[a.result() for a in x]\n",
    "    for i,c in enumerate(x):\n",
    "        c.name=l[i]\n",
    "    return pd.DataFrame(x).transpose()\n",
    "\n",
    "def tester_func(name,start=start,end=end,entry=\"adjclose\"):\n",
    "    try:\n",
    "        c= get_seiries(name,start,end,entry)\n",
    "        c.name=name\n",
    "        return (True,c)\n",
    "    except:\n",
    "        return (False,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "586c18bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thread setup complete\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "error number 1: name=EMP\n",
      "400\n",
      "error number 2: name=XTWY\n",
      "500\n",
      "600\n",
      "error number 3: name=ZCZZT\n",
      "error number 4: name=KDIV\n",
      "700\n",
      "800\n",
      "error number 5: name=RCA\n",
      "900\n",
      "1000\n",
      "error number 6: name=ZXYZ.A\n",
      "1100\n",
      "error number 7: name=ATEST.C\n",
      "1200\n",
      "error number 8: name=ZXZZT\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "error number 9: name=DHCNL\n",
      "1800\n",
      "1900\n",
      "error number 10: name=ZBZX\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "error number 11: name=ZJZZT\n",
      "2400\n",
      "2500\n",
      "error number 12: name=CBO\n",
      "2600\n",
      "2700\n",
      "error number 13: name=SFB\n",
      "error number 14: name=CTEST.S\n",
      "2800\n",
      "error number 15: name=ZXIET\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "error number 16: name=ZVV\n",
      "3200\n",
      "error number 17: name=ATEST.A\n",
      "3300\n",
      "error number 18: name=ATEST\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "error number 19: name=CTEST.O\n",
      "3800\n",
      "3900\n",
      "error number 20: name=GRP.U\n",
      "4000\n",
      "error number 21: name=CTEST.G\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "error number 22: name=IGZ\n",
      "4400\n",
      "error number 23: name=IBO\n",
      "4500\n",
      "error number 24: name=ZBZZT\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "error number 25: name=XTWO\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "error number 26: name=ZVZZT\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "error number 27: name=ZEXIT\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "error number 28: name=CTEST\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "error number 29: name=HOLO\n",
      "error number 30: name=EAI\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "error number 31: name=CBX\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "error number 32: name=ZAZZT\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "error number 33: name=XTRE\n",
      "error number 34: name=CTEST.V\n",
      "8200\n",
      "error number 35: name=ZVZZC\n",
      "8300\n",
      "8400\n",
      "error number 36: name=RUM\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "error number 37: name=ZTEST\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "error number 38: name=XSVN\n",
      "9300\n",
      "9400\n",
      "error number 39: name=ZWZZT\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "error number 40: name=XTEN\n",
      "9800\n",
      "9900\n",
      "error number 41: name=XFIV\n",
      "10000\n",
      "10100\n",
      "error number 42: name=ATEST.B\n",
      "10200\n",
      "error number 43: name=ZIEXT\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "error number 44: name=CTEST.E\n",
      "error number 45: name=CTEST.L\n",
      "10600\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "mini=ticker_list\n",
    "errors=[]\n",
    "data=[]\n",
    "c=0\n",
    "x=list(range(len(mini)))\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    for i in range(len(mini)):\n",
    "        x[i]=executor.submit(tester_func,mini[i])\n",
    "    \n",
    "    print(\"thread setup complete\")\n",
    "    \n",
    "    for i in range(len(mini)):\n",
    "        if(i%100==0):\n",
    "            print(i)\n",
    "        r=x[i].result()\n",
    "        if (r[0]): \n",
    "            data.append(r[1])\n",
    "        else:\n",
    "            errors.append(r[1])\n",
    "            c+=1\n",
    "            print(f\"error number {c}: name={errors[-1]}\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2e95aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTAAU</th>\n",
       "      <th>FVAL</th>\n",
       "      <th>RYU</th>\n",
       "      <th>PKBK</th>\n",
       "      <th>PLM</th>\n",
       "      <th>PNF</th>\n",
       "      <th>FNCB</th>\n",
       "      <th>QGRO</th>\n",
       "      <th>UXIN</th>\n",
       "      <th>ONEV</th>\n",
       "      <th>...</th>\n",
       "      <th>CLVT</th>\n",
       "      <th>FDP</th>\n",
       "      <th>MYNZ</th>\n",
       "      <th>BXMX</th>\n",
       "      <th>NQP</th>\n",
       "      <th>REMG</th>\n",
       "      <th>MDJH</th>\n",
       "      <th>FSBW</th>\n",
       "      <th>OAIE</th>\n",
       "      <th>SCOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993187</td>\n",
       "      <td>1.001432</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984150</td>\n",
       "      <td>0.986998</td>\n",
       "      <td>0.992088</td>\n",
       "      <td>0.986900</td>\n",
       "      <td>0.994473</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004086</td>\n",
       "      <td>1.004358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>1.001412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897288</td>\n",
       "      <td>0.993946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993868</td>\n",
       "      <td>1.001623</td>\n",
       "      <td>0.991157</td>\n",
       "      <td>1.115385</td>\n",
       "      <td>0.987752</td>\n",
       "      <td>0.986998</td>\n",
       "      <td>0.994725</td>\n",
       "      <td>1.082969</td>\n",
       "      <td>0.993410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004670</td>\n",
       "      <td>0.995352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990525</td>\n",
       "      <td>1.004237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.001434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992400</td>\n",
       "      <td>1.000286</td>\n",
       "      <td>0.987138</td>\n",
       "      <td>1.115385</td>\n",
       "      <td>1.005764</td>\n",
       "      <td>0.960993</td>\n",
       "      <td>0.996923</td>\n",
       "      <td>1.048035</td>\n",
       "      <td>0.991907</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002335</td>\n",
       "      <td>0.985764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985423</td>\n",
       "      <td>1.007768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.003390</td>\n",
       "      <td>0.981361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.996253</td>\n",
       "      <td>1.000286</td>\n",
       "      <td>0.997990</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>1.003602</td>\n",
       "      <td>0.964539</td>\n",
       "      <td>1.005275</td>\n",
       "      <td>1.052402</td>\n",
       "      <td>0.993988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996497</td>\n",
       "      <td>0.994771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992711</td>\n",
       "      <td>1.008474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958983</td>\n",
       "      <td>0.981520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.00499</td>\n",
       "      <td>1.239907</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.073983</td>\n",
       "      <td>1.292308</td>\n",
       "      <td>0.770535</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>1.390525</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>1.253491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711617</td>\n",
       "      <td>0.758444</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>1.155949</td>\n",
       "      <td>0.925426</td>\n",
       "      <td>0.802848</td>\n",
       "      <td>0.654237</td>\n",
       "      <td>0.958590</td>\n",
       "      <td>1.045259</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.00499</td>\n",
       "      <td>1.182837</td>\n",
       "      <td>1.229249</td>\n",
       "      <td>1.038421</td>\n",
       "      <td>1.253846</td>\n",
       "      <td>0.742903</td>\n",
       "      <td>0.965929</td>\n",
       "      <td>1.329366</td>\n",
       "      <td>0.314410</td>\n",
       "      <td>1.207910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687099</td>\n",
       "      <td>0.759042</td>\n",
       "      <td>0.339758</td>\n",
       "      <td>1.122516</td>\n",
       "      <td>0.919188</td>\n",
       "      <td>0.782947</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.958590</td>\n",
       "      <td>1.020960</td>\n",
       "      <td>1.00202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>1.00499</td>\n",
       "      <td>1.186875</td>\n",
       "      <td>1.240453</td>\n",
       "      <td>1.039369</td>\n",
       "      <td>1.276923</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.933607</td>\n",
       "      <td>1.337315</td>\n",
       "      <td>0.301310</td>\n",
       "      <td>1.199983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676007</td>\n",
       "      <td>0.741710</td>\n",
       "      <td>0.331444</td>\n",
       "      <td>1.123351</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.786589</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.951027</td>\n",
       "      <td>1.014845</td>\n",
       "      <td>1.00202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>1.00499</td>\n",
       "      <td>1.175569</td>\n",
       "      <td>1.212295</td>\n",
       "      <td>1.043162</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.718429</td>\n",
       "      <td>1.029329</td>\n",
       "      <td>1.318327</td>\n",
       "      <td>0.299127</td>\n",
       "      <td>1.193022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636894</td>\n",
       "      <td>0.734537</td>\n",
       "      <td>0.329592</td>\n",
       "      <td>1.108307</td>\n",
       "      <td>0.900477</td>\n",
       "      <td>0.778146</td>\n",
       "      <td>0.650847</td>\n",
       "      <td>0.950040</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>1.00303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.00499</td>\n",
       "      <td>1.160764</td>\n",
       "      <td>1.208924</td>\n",
       "      <td>1.058336</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.711324</td>\n",
       "      <td>1.028086</td>\n",
       "      <td>1.302209</td>\n",
       "      <td>0.301310</td>\n",
       "      <td>1.180542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617046</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.336357</td>\n",
       "      <td>1.096605</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.769437</td>\n",
       "      <td>0.673220</td>\n",
       "      <td>0.946752</td>\n",
       "      <td>0.971718</td>\n",
       "      <td>1.00303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>683 rows × 10578 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              UTAAU      FVAL       RYU      PKBK       PLM       PNF  \\\n",
       "2020-01-02      NaN  1.000000  1.000000  1.000000  1.000000  1.000000   \n",
       "2020-01-03      NaN  0.993187  1.001432  0.988746  1.000000  0.984150   \n",
       "2020-01-06      NaN  0.993868  1.001623  0.991157  1.115385  0.987752   \n",
       "2020-01-07      NaN  0.992400  1.000286  0.987138  1.115385  1.005764   \n",
       "2020-01-08      NaN  0.996253  1.000286  0.997990  1.269231  1.003602   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "2022-09-12  1.00499  1.239907  1.263158  1.073983  1.292308  0.770535   \n",
       "2022-09-13  1.00499  1.182837  1.229249  1.038421  1.253846  0.742903   \n",
       "2022-09-14  1.00499  1.186875  1.240453  1.039369  1.276923  0.732640   \n",
       "2022-09-15  1.00499  1.175569  1.212295  1.043162  1.269231  0.718429   \n",
       "2022-09-16  1.00499  1.160764  1.208924  1.058336  1.269231  0.711324   \n",
       "\n",
       "                FNCB      QGRO      UXIN      ONEV  ...      CLVT       FDP  \\\n",
       "2020-01-02  1.000000  1.000000  1.000000  1.000000  ...  1.000000  1.000000   \n",
       "2020-01-03  0.986998  0.992088  0.986900  0.994473  ...  1.004086  1.004358   \n",
       "2020-01-06  0.986998  0.994725  1.082969  0.993410  ...  1.004670  0.995352   \n",
       "2020-01-07  0.960993  0.996923  1.048035  0.991907  ...  1.002335  0.985764   \n",
       "2020-01-08  0.964539  1.005275  1.052402  0.993988  ...  0.996497  0.994771   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-12  0.982090  1.390525  0.313100  1.253491  ...  0.711617  0.758444   \n",
       "2022-09-13  0.965929  1.329366  0.314410  1.207910  ...  0.687099  0.759042   \n",
       "2022-09-14  0.933607  1.337315  0.301310  1.199983  ...  0.676007  0.741710   \n",
       "2022-09-15  1.029329  1.318327  0.299127  1.193022  ...  0.636894  0.734537   \n",
       "2022-09-16  1.028086  1.302209  0.301310  1.180542  ...  0.617046  0.744100   \n",
       "\n",
       "                MYNZ      BXMX       NQP      REMG      MDJH      FSBW  \\\n",
       "2020-01-02       NaN  1.000000  1.000000       NaN  1.000000  1.000000   \n",
       "2020-01-03       NaN  0.990525  1.001412       NaN  0.897288  0.993946   \n",
       "2020-01-06       NaN  0.990525  1.004237       NaN  0.983051  1.001434   \n",
       "2020-01-07       NaN  0.985423  1.007768       NaN  1.003390  0.981361   \n",
       "2020-01-08       NaN  0.992711  1.008474       NaN  0.958983  0.981520   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-12  0.338624  1.155949  0.925426  0.802848  0.654237  0.958590   \n",
       "2022-09-13  0.339758  1.122516  0.919188  0.782947  0.661017  0.958590   \n",
       "2022-09-14  0.331444  1.123351  0.911392  0.786589  0.633898  0.951027   \n",
       "2022-09-15  0.329592  1.108307  0.900477  0.778146  0.650847  0.950040   \n",
       "2022-09-16  0.336357  1.096605  0.898138  0.769437  0.673220  0.946752   \n",
       "\n",
       "                OAIE     SCOB  \n",
       "2020-01-02       NaN      NaN  \n",
       "2020-01-03       NaN      NaN  \n",
       "2020-01-06       NaN      NaN  \n",
       "2020-01-07       NaN      NaN  \n",
       "2020-01-08       NaN      NaN  \n",
       "...              ...      ...  \n",
       "2022-09-12  1.045259  1.00000  \n",
       "2022-09-13  1.020960  1.00202  \n",
       "2022-09-14  1.014845  1.00202  \n",
       "2022-09-15  0.997707  1.00303  \n",
       "2022-09-16  0.971718  1.00303  \n",
       "\n",
       "[683 rows x 10578 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.DataFrame(data).transpose()\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "485bf67c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTAAU</th>\n",
       "      <th>FVAL</th>\n",
       "      <th>RYU</th>\n",
       "      <th>PKBK</th>\n",
       "      <th>PLM</th>\n",
       "      <th>PNF</th>\n",
       "      <th>FNCB</th>\n",
       "      <th>QGRO</th>\n",
       "      <th>UXIN</th>\n",
       "      <th>ONEV</th>\n",
       "      <th>...</th>\n",
       "      <th>CLVT</th>\n",
       "      <th>FDP</th>\n",
       "      <th>MYNZ</th>\n",
       "      <th>BXMX</th>\n",
       "      <th>NQP</th>\n",
       "      <th>REMG</th>\n",
       "      <th>MDJH</th>\n",
       "      <th>FSBW</th>\n",
       "      <th>OAIE</th>\n",
       "      <th>SCOB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-09</th>\n",
       "      <td>1.039920</td>\n",
       "      <td>1.250674</td>\n",
       "      <td>1.170057</td>\n",
       "      <td>1.116184</td>\n",
       "      <td>1.130769</td>\n",
       "      <td>0.756324</td>\n",
       "      <td>0.927391</td>\n",
       "      <td>1.331574</td>\n",
       "      <td>0.193450</td>\n",
       "      <td>1.228102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843549</td>\n",
       "      <td>0.736928</td>\n",
       "      <td>0.414588</td>\n",
       "      <td>1.143411</td>\n",
       "      <td>0.965187</td>\n",
       "      <td>0.843179</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.987200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10</th>\n",
       "      <td>1.039920</td>\n",
       "      <td>1.214064</td>\n",
       "      <td>1.160241</td>\n",
       "      <td>1.086311</td>\n",
       "      <td>1.111539</td>\n",
       "      <td>0.750798</td>\n",
       "      <td>0.944795</td>\n",
       "      <td>1.286754</td>\n",
       "      <td>0.181659</td>\n",
       "      <td>1.205335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815528</td>\n",
       "      <td>0.726768</td>\n",
       "      <td>0.414210</td>\n",
       "      <td>1.123351</td>\n",
       "      <td>0.951153</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.970757</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-13</th>\n",
       "      <td>1.008982</td>\n",
       "      <td>1.162110</td>\n",
       "      <td>1.103925</td>\n",
       "      <td>1.027041</td>\n",
       "      <td>1.019231</td>\n",
       "      <td>0.740535</td>\n",
       "      <td>0.943552</td>\n",
       "      <td>1.222063</td>\n",
       "      <td>0.174672</td>\n",
       "      <td>1.164331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.351474</td>\n",
       "      <td>1.078217</td>\n",
       "      <td>0.931663</td>\n",
       "      <td>0.806755</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.962865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.991919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-14</th>\n",
       "      <td>1.007984</td>\n",
       "      <td>1.160764</td>\n",
       "      <td>1.072990</td>\n",
       "      <td>1.021351</td>\n",
       "      <td>1.023077</td>\n",
       "      <td>0.728692</td>\n",
       "      <td>0.934850</td>\n",
       "      <td>1.225154</td>\n",
       "      <td>0.177729</td>\n",
       "      <td>1.156702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771162</td>\n",
       "      <td>0.711228</td>\n",
       "      <td>0.336735</td>\n",
       "      <td>1.043948</td>\n",
       "      <td>0.905935</td>\n",
       "      <td>0.817715</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>0.956288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-15</th>\n",
       "      <td>1.016966</td>\n",
       "      <td>1.177454</td>\n",
       "      <td>1.078642</td>\n",
       "      <td>1.065922</td>\n",
       "      <td>1.065385</td>\n",
       "      <td>0.739745</td>\n",
       "      <td>1.024357</td>\n",
       "      <td>1.247233</td>\n",
       "      <td>0.187336</td>\n",
       "      <td>1.165642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798599</td>\n",
       "      <td>0.708539</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.058993</td>\n",
       "      <td>0.903596</td>\n",
       "      <td>0.831225</td>\n",
       "      <td>0.545763</td>\n",
       "      <td>0.954973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-12</th>\n",
       "      <td>1.004990</td>\n",
       "      <td>1.239907</td>\n",
       "      <td>1.263158</td>\n",
       "      <td>1.073983</td>\n",
       "      <td>1.292308</td>\n",
       "      <td>0.770535</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>1.390525</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>1.253491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711617</td>\n",
       "      <td>0.758444</td>\n",
       "      <td>0.338624</td>\n",
       "      <td>1.155949</td>\n",
       "      <td>0.925426</td>\n",
       "      <td>0.802848</td>\n",
       "      <td>0.654237</td>\n",
       "      <td>0.958590</td>\n",
       "      <td>1.045259</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-13</th>\n",
       "      <td>1.004990</td>\n",
       "      <td>1.182837</td>\n",
       "      <td>1.229249</td>\n",
       "      <td>1.038421</td>\n",
       "      <td>1.253846</td>\n",
       "      <td>0.742903</td>\n",
       "      <td>0.965929</td>\n",
       "      <td>1.329366</td>\n",
       "      <td>0.314410</td>\n",
       "      <td>1.207910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687099</td>\n",
       "      <td>0.759042</td>\n",
       "      <td>0.339758</td>\n",
       "      <td>1.122516</td>\n",
       "      <td>0.919188</td>\n",
       "      <td>0.782947</td>\n",
       "      <td>0.661017</td>\n",
       "      <td>0.958590</td>\n",
       "      <td>1.020960</td>\n",
       "      <td>1.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-14</th>\n",
       "      <td>1.004990</td>\n",
       "      <td>1.186875</td>\n",
       "      <td>1.240453</td>\n",
       "      <td>1.039369</td>\n",
       "      <td>1.276923</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.933607</td>\n",
       "      <td>1.337315</td>\n",
       "      <td>0.301310</td>\n",
       "      <td>1.199983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676007</td>\n",
       "      <td>0.741710</td>\n",
       "      <td>0.331444</td>\n",
       "      <td>1.123351</td>\n",
       "      <td>0.911392</td>\n",
       "      <td>0.786589</td>\n",
       "      <td>0.633898</td>\n",
       "      <td>0.951027</td>\n",
       "      <td>1.014845</td>\n",
       "      <td>1.002020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-15</th>\n",
       "      <td>1.004990</td>\n",
       "      <td>1.175569</td>\n",
       "      <td>1.212295</td>\n",
       "      <td>1.043162</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.718429</td>\n",
       "      <td>1.029329</td>\n",
       "      <td>1.318327</td>\n",
       "      <td>0.299127</td>\n",
       "      <td>1.193022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636894</td>\n",
       "      <td>0.734537</td>\n",
       "      <td>0.329592</td>\n",
       "      <td>1.108307</td>\n",
       "      <td>0.900477</td>\n",
       "      <td>0.778146</td>\n",
       "      <td>0.650847</td>\n",
       "      <td>0.950040</td>\n",
       "      <td>0.997707</td>\n",
       "      <td>1.003030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09-16</th>\n",
       "      <td>1.004990</td>\n",
       "      <td>1.160764</td>\n",
       "      <td>1.208924</td>\n",
       "      <td>1.058336</td>\n",
       "      <td>1.269231</td>\n",
       "      <td>0.711324</td>\n",
       "      <td>1.028086</td>\n",
       "      <td>1.302209</td>\n",
       "      <td>0.301310</td>\n",
       "      <td>1.180542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617046</td>\n",
       "      <td>0.744100</td>\n",
       "      <td>0.336357</td>\n",
       "      <td>1.096605</td>\n",
       "      <td>0.898138</td>\n",
       "      <td>0.769437</td>\n",
       "      <td>0.673220</td>\n",
       "      <td>0.946752</td>\n",
       "      <td>0.971718</td>\n",
       "      <td>1.003030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 10578 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UTAAU      FVAL       RYU      PKBK       PLM       PNF  \\\n",
       "2022-06-09  1.039920  1.250674  1.170057  1.116184  1.130769  0.756324   \n",
       "2022-06-10  1.039920  1.214064  1.160241  1.086311  1.111539  0.750798   \n",
       "2022-06-13  1.008982  1.162110  1.103925  1.027041  1.019231  0.740535   \n",
       "2022-06-14  1.007984  1.160764  1.072990  1.021351  1.023077  0.728692   \n",
       "2022-06-15  1.016966  1.177454  1.078642  1.065922  1.065385  0.739745   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-12  1.004990  1.239907  1.263158  1.073983  1.292308  0.770535   \n",
       "2022-09-13  1.004990  1.182837  1.229249  1.038421  1.253846  0.742903   \n",
       "2022-09-14  1.004990  1.186875  1.240453  1.039369  1.276923  0.732640   \n",
       "2022-09-15  1.004990  1.175569  1.212295  1.043162  1.269231  0.718429   \n",
       "2022-09-16  1.004990  1.160764  1.208924  1.058336  1.269231  0.711324   \n",
       "\n",
       "                FNCB      QGRO      UXIN      ONEV  ...      CLVT       FDP  \\\n",
       "2022-06-09  0.927391  1.331574  0.193450  1.228102  ...  0.843549  0.736928   \n",
       "2022-06-10  0.944795  1.286754  0.181659  1.205335  ...  0.815528  0.726768   \n",
       "2022-06-13  0.943552  1.222063  0.174672  1.164331  ...  0.800934  0.707642   \n",
       "2022-06-14  0.934850  1.225154  0.177729  1.156702  ...  0.771162  0.711228   \n",
       "2022-06-15  1.024357  1.247233  0.187336  1.165642  ...  0.798599  0.708539   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2022-09-12  0.982090  1.390525  0.313100  1.253491  ...  0.711617  0.758444   \n",
       "2022-09-13  0.965929  1.329366  0.314410  1.207910  ...  0.687099  0.759042   \n",
       "2022-09-14  0.933607  1.337315  0.301310  1.199983  ...  0.676007  0.741710   \n",
       "2022-09-15  1.029329  1.318327  0.299127  1.193022  ...  0.636894  0.734537   \n",
       "2022-09-16  1.028086  1.302209  0.301310  1.180542  ...  0.617046  0.744100   \n",
       "\n",
       "                MYNZ      BXMX       NQP      REMG      MDJH      FSBW  \\\n",
       "2022-06-09  0.414588  1.143411  0.965187  0.843179  0.542373  0.987200   \n",
       "2022-06-10  0.414210  1.123351  0.951153  0.834437  0.633898  0.970757   \n",
       "2022-06-13  0.351474  1.078217  0.931663  0.806755  0.633898  0.962865   \n",
       "2022-06-14  0.336735  1.043948  0.905935  0.817715  0.603390  0.956288   \n",
       "2022-06-15  0.388889  1.058993  0.903596  0.831225  0.545763  0.954973   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-09-12  0.338624  1.155949  0.925426  0.802848  0.654237  0.958590   \n",
       "2022-09-13  0.339758  1.122516  0.919188  0.782947  0.661017  0.958590   \n",
       "2022-09-14  0.331444  1.123351  0.911392  0.786589  0.633898  0.951027   \n",
       "2022-09-15  0.329592  1.108307  0.900477  0.778146  0.650847  0.950040   \n",
       "2022-09-16  0.336357  1.096605  0.898138  0.769437  0.673220  0.946752   \n",
       "\n",
       "                OAIE      SCOB  \n",
       "2022-06-09       NaN  0.990909  \n",
       "2022-06-10       NaN  0.992929  \n",
       "2022-06-13       NaN  0.991919  \n",
       "2022-06-14       NaN  0.990909  \n",
       "2022-06-15       NaN  0.990404  \n",
       "...              ...       ...  \n",
       "2022-09-12  1.045259  1.000000  \n",
       "2022-09-13  1.020960  1.002020  \n",
       "2022-09-14  1.014845  1.002020  \n",
       "2022-09-15  0.997707  1.003030  \n",
       "2022-09-16  0.971718  1.003030  \n",
       "\n",
       "[69 rows x 10578 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=data_df.iloc[:-69]\n",
    "test_df=data_df.iloc[-69:]\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01a7d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1628 stocks were droped\n"
     ]
    }
   ],
   "source": [
    "ticker_list=data_df.columns\n",
    "print(f\"{len(symbols)-len(ticker_list)} stocks were droped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7efabaa",
   "metadata": {},
   "source": [
    "# preprocessing \n",
    "\n",
    "\n",
    "1. ticker: this is also used to select which stocks come to the model\n",
    "\n",
    "2. price: we take the ratio: (importantly we did drop some potentialy important indicators)\n",
    "\n",
    "3. date: the day and month are floating point numbers. while year and day of the week are embedings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "673271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "look=layers.StringLookup(vocabulary=ticker_list,num_oov_indices=0)\n",
    "inv_look=layers.StringLookup(vocabulary=ticker_list,invert=True,num_oov_indices=0)\n",
    "tick_embed=layers.Embedding(len(ticker_list)+1,512)#,embeddings_constraint= tf.keras.constraints.unit_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d4ce3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=layers.Input([],dtype=tf.string)\n",
    "x=look(inputs)\n",
    "x=tick_embed(x)\n",
    "x=layers.UnitNormalization()(x)\n",
    "ticker_model=tf.keras.Model(inputs,x)\n",
    "ticker_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47802c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(17,), dtype=string, numpy=\n",
       "array([b'UTAAU', b'FVAL', b'RYU', b'PKBK', b'PLM', b'PNF', b'FNCB',\n",
       "       b'QGRO', b'UXIN', b'ONEV', b'NORW', b'RE', b'DUOT', b'RIBT',\n",
       "       b'IAG', b'HIPO', b'UI'], dtype=object)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices(ticker_list)\n",
    "exmple=dataset.batch(17).take(1).get_single_element()\n",
    "exmple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a701202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df[exmple.numpy().astype('U13')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "251a654f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)],\n",
       " [range(0, 0), range(0, 1), range(0, 2), range(0, 3), range(0, 4)]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def thread_distribute(l,f,n=1):\n",
    "    #print(type(l))\n",
    "    if(n==0):\n",
    "        return f(l)\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor: \n",
    "        l=[executor.submit(lambda x: thread_distribute(x,f,n-1),x) for x in l]\n",
    "        l= [x.result() for x in l]\n",
    "    return l\n",
    "\n",
    "thread_distribute([range(5) for i in range(2)],lambda x: range(x),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8a28548",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1408/3319905055.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a[0][0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9fd4c11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.06666666666666667, 0.08333333333333333, 0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def time_encode(a):\n",
    "    #a=a.index\n",
    "    #print(type(a))\n",
    "    return (a.day_of_week,a.day/30,a.month/12,(a.year-2020))\n",
    "    \n",
    "time_encode(data_df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a993565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTAAU</th>\n",
       "      <th>VTEB</th>\n",
       "      <th>AB</th>\n",
       "      <th>PFMT</th>\n",
       "      <th>NYMTL</th>\n",
       "      <th>CWS</th>\n",
       "      <th>VEEE</th>\n",
       "      <th>OXLCM</th>\n",
       "      <th>MCR</th>\n",
       "      <th>MPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.054594</td>\n",
       "      <td>2.001236</td>\n",
       "      <td>2.366072</td>\n",
       "      <td>0.975455</td>\n",
       "      <td>1.349973</td>\n",
       "      <td>0.413885</td>\n",
       "      <td>1.089973</td>\n",
       "      <td>1.164135</td>\n",
       "      <td>0.903909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>0.999002</td>\n",
       "      <td>1.055746</td>\n",
       "      <td>2.000843</td>\n",
       "      <td>2.294643</td>\n",
       "      <td>0.977435</td>\n",
       "      <td>1.331377</td>\n",
       "      <td>0.387183</td>\n",
       "      <td>1.092565</td>\n",
       "      <td>1.158578</td>\n",
       "      <td>0.891272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>0.999002</td>\n",
       "      <td>1.054594</td>\n",
       "      <td>2.065843</td>\n",
       "      <td>2.348214</td>\n",
       "      <td>0.979810</td>\n",
       "      <td>1.348339</td>\n",
       "      <td>0.440587</td>\n",
       "      <td>1.090405</td>\n",
       "      <td>1.180805</td>\n",
       "      <td>0.926209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>1.002994</td>\n",
       "      <td>1.054210</td>\n",
       "      <td>2.083177</td>\n",
       "      <td>2.553571</td>\n",
       "      <td>0.978306</td>\n",
       "      <td>1.362138</td>\n",
       "      <td>0.457944</td>\n",
       "      <td>1.089973</td>\n",
       "      <td>1.187751</td>\n",
       "      <td>0.961146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>1.001996</td>\n",
       "      <td>1.054017</td>\n",
       "      <td>2.039843</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>0.979612</td>\n",
       "      <td>1.369239</td>\n",
       "      <td>0.507343</td>\n",
       "      <td>1.094725</td>\n",
       "      <td>1.183584</td>\n",
       "      <td>0.956686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-02</th>\n",
       "      <td>1.007485</td>\n",
       "      <td>0.976248</td>\n",
       "      <td>1.756433</td>\n",
       "      <td>2.366072</td>\n",
       "      <td>0.903405</td>\n",
       "      <td>1.202706</td>\n",
       "      <td>0.419092</td>\n",
       "      <td>1.094077</td>\n",
       "      <td>0.955936</td>\n",
       "      <td>0.828445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-03</th>\n",
       "      <td>1.010978</td>\n",
       "      <td>0.976440</td>\n",
       "      <td>1.730097</td>\n",
       "      <td>2.303571</td>\n",
       "      <td>0.906968</td>\n",
       "      <td>1.194882</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>1.097317</td>\n",
       "      <td>0.953099</td>\n",
       "      <td>0.825443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-06</th>\n",
       "      <td>1.006387</td>\n",
       "      <td>0.974520</td>\n",
       "      <td>1.757243</td>\n",
       "      <td>2.357143</td>\n",
       "      <td>0.898654</td>\n",
       "      <td>1.200616</td>\n",
       "      <td>0.417891</td>\n",
       "      <td>1.096367</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.799179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-07</th>\n",
       "      <td>1.009980</td>\n",
       "      <td>0.972407</td>\n",
       "      <td>1.792899</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>0.903009</td>\n",
       "      <td>1.210450</td>\n",
       "      <td>0.413885</td>\n",
       "      <td>1.094293</td>\n",
       "      <td>0.947426</td>\n",
       "      <td>0.821691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-08</th>\n",
       "      <td>1.039920</td>\n",
       "      <td>0.970871</td>\n",
       "      <td>1.745898</td>\n",
       "      <td>2.258929</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>1.192792</td>\n",
       "      <td>0.413885</td>\n",
       "      <td>1.086949</td>\n",
       "      <td>0.941753</td>\n",
       "      <td>0.787923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UTAAU      VTEB        AB      PFMT     NYMTL       CWS  \\\n",
       "2021-12-02  1.000000  1.054594  2.001236  2.366072  0.975455  1.349973   \n",
       "2021-12-03  0.999002  1.055746  2.000843  2.294643  0.977435  1.331377   \n",
       "2021-12-06  0.999002  1.054594  2.065843  2.348214  0.979810  1.348339   \n",
       "2021-12-07  1.002994  1.054210  2.083177  2.553571  0.978306  1.362138   \n",
       "2021-12-08  1.001996  1.054017  2.039843  2.625000  0.979612  1.369239   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-06-02  1.007485  0.976248  1.756433  2.366072  0.903405  1.202706   \n",
       "2022-06-03  1.010978  0.976440  1.730097  2.303571  0.906968  1.194882   \n",
       "2022-06-06  1.006387  0.974520  1.757243  2.357143  0.898654  1.200616   \n",
       "2022-06-07  1.009980  0.972407  1.792899  2.285714  0.903009  1.210450   \n",
       "2022-06-08  1.039920  0.970871  1.745898  2.258929  0.902098  1.192792   \n",
       "\n",
       "                VEEE     OXLCM       MCR       MPX  \n",
       "2021-12-02  0.413885  1.089973  1.164135  0.903909  \n",
       "2021-12-03  0.387183  1.092565  1.158578  0.891272  \n",
       "2021-12-06  0.440587  1.090405  1.180805  0.926209  \n",
       "2021-12-07  0.457944  1.089973  1.187751  0.961146  \n",
       "2021-12-08  0.507343  1.094725  1.183584  0.956686  \n",
       "...              ...       ...       ...       ...  \n",
       "2022-06-02  0.419092  1.094077  0.955936  0.828445  \n",
       "2022-06-03  0.420561  1.097317  0.953099  0.825443  \n",
       "2022-06-06  0.417891  1.096367  0.946008  0.799179  \n",
       "2022-06-07  0.413885  1.094293  0.947426  0.821691  \n",
       "2022-06-08  0.413885  1.086949  0.941753  0.787923  \n",
       "\n",
       "[130 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def choose_stocks_df(x,data_df=train_df):\n",
    "    a=ticker_model(ticker_list)\n",
    "    b=ticker_model(x)\n",
    "\n",
    "    b=b@tf.transpose(a)\n",
    "    b=tf.nn.top_k(b,NUM_STOCKS)\n",
    "\n",
    "\n",
    "    tickers=inv_look([list(x) for x in b[1].numpy()]).numpy().astype('U13')\n",
    "    \n",
    "    \n",
    "    return [pd.DataFrame([data_df[x] for x in sub]).transpose().dropna() for sub in tickers]\n",
    "\n",
    "v=choose_stocks_df(exmple)\n",
    "v[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04aa725f",
   "metadata": {},
   "source": [
    "# time handeling \n",
    "\n",
    "problems with the data in curent time format:\n",
    "\n",
    "1. there are null entries especialy from before a company was made \n",
    "2. the time diffrence between entries isnt clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16159624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True,  True, ...,  True, False, False],\n",
       "       [False,  True,  True, ...,  True, False, False],\n",
       "       [False,  True,  True, ...,  True, False, False],\n",
       "       ...,\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [ True,  True,  True, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=np.logical_not(data_df.isna().to_numpy())\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2540411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f75c44e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(TensorShape([17, 375]), tf.int32),\n",
       " (TensorShape([17, 375]), tf.float32),\n",
       " (TensorShape([17, 375]), tf.float32),\n",
       " (TensorShape([17, 375]), tf.int32),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 375]), tf.float64),\n",
       " (TensorShape([17, 10]), tf.string)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to add the tickers strings/ints\n",
    "def get_xs(v):\n",
    "    t=[x.index for x in v]\n",
    "    #for x in t:\n",
    "     #   print(type(x))\n",
    "    t=thread_distribute(t,time_encode,2)\n",
    "    #t=[[x[i] for x in t] for i in range(4)]\n",
    "    #print(\"time encoded\")\n",
    "    t=[thread_distribute(t,lambda x: x[i],2) for i in range(4)]\n",
    "    #thread_distribute(t,len,2)\n",
    "    t=[tf.ragged.constant(x) for x in t]\n",
    "    \n",
    "    x=thread_distribute(v,lambda x: x.to_numpy(),1)\n",
    "    vals=tf.concat(x,axis=0)\n",
    "    lengths=[len(s) for s in x]\n",
    "    x=tf.RaggedTensor.from_row_lengths(vals,lengths)\n",
    "    #[x.shape for x in x]\n",
    "    \n",
    "    \"padding\"\n",
    "    x=(x+1).to_tensor()-1\n",
    "    t=[(x+1).to_tensor()-1 for x in t] \n",
    "    \n",
    "    x=tf.transpose(x,[2,0,1])\n",
    "    t.extend(x) \n",
    "    \n",
    "    tickers=tf.constant([x.transpose().index for x in v])\n",
    "    t.append(tickers)\n",
    "    return t\n",
    "\n",
    "xs=get_xs(v)\n",
    "[(x.shape,x.dtype) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "755a743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[len(x) for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e8e380cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTAAU</th>\n",
       "      <th>VTEB</th>\n",
       "      <th>AB</th>\n",
       "      <th>PFMT</th>\n",
       "      <th>NYMTL</th>\n",
       "      <th>CWS</th>\n",
       "      <th>VEEE</th>\n",
       "      <th>OXLCM</th>\n",
       "      <th>MCR</th>\n",
       "      <th>MPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-28</th>\n",
       "      <td>0.998004</td>\n",
       "      <td>1.055554</td>\n",
       "      <td>1.931508</td>\n",
       "      <td>2.071429</td>\n",
       "      <td>0.982581</td>\n",
       "      <td>1.418542</td>\n",
       "      <td>0.555407</td>\n",
       "      <td>1.092997</td>\n",
       "      <td>1.201320</td>\n",
       "      <td>0.923236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.054978</td>\n",
       "      <td>1.920872</td>\n",
       "      <td>2.044643</td>\n",
       "      <td>0.981789</td>\n",
       "      <td>1.412781</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>1.090837</td>\n",
       "      <td>1.211109</td>\n",
       "      <td>0.934386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>0.999002</td>\n",
       "      <td>1.054786</td>\n",
       "      <td>1.930720</td>\n",
       "      <td>2.169643</td>\n",
       "      <td>0.969121</td>\n",
       "      <td>1.423848</td>\n",
       "      <td>0.562083</td>\n",
       "      <td>1.091701</td>\n",
       "      <td>1.209711</td>\n",
       "      <td>0.934386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>1.006487</td>\n",
       "      <td>1.054402</td>\n",
       "      <td>1.924023</td>\n",
       "      <td>2.151786</td>\n",
       "      <td>0.971892</td>\n",
       "      <td>1.429555</td>\n",
       "      <td>0.535381</td>\n",
       "      <td>1.091701</td>\n",
       "      <td>1.191530</td>\n",
       "      <td>0.929182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03</th>\n",
       "      <td>0.997804</td>\n",
       "      <td>1.053825</td>\n",
       "      <td>1.919296</td>\n",
       "      <td>2.232143</td>\n",
       "      <td>0.972447</td>\n",
       "      <td>1.403939</td>\n",
       "      <td>0.514019</td>\n",
       "      <td>1.093429</td>\n",
       "      <td>1.192928</td>\n",
       "      <td>0.935873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-13</th>\n",
       "      <td>1.021058</td>\n",
       "      <td>0.946292</td>\n",
       "      <td>1.547768</td>\n",
       "      <td>2.098214</td>\n",
       "      <td>0.883215</td>\n",
       "      <td>1.172294</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>1.089109</td>\n",
       "      <td>0.916224</td>\n",
       "      <td>0.855459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16</th>\n",
       "      <td>1.028443</td>\n",
       "      <td>0.947060</td>\n",
       "      <td>1.533182</td>\n",
       "      <td>2.008929</td>\n",
       "      <td>0.863816</td>\n",
       "      <td>1.172669</td>\n",
       "      <td>0.445928</td>\n",
       "      <td>1.090837</td>\n",
       "      <td>0.921897</td>\n",
       "      <td>0.855459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-17</th>\n",
       "      <td>1.028443</td>\n",
       "      <td>0.944372</td>\n",
       "      <td>1.602467</td>\n",
       "      <td>1.964286</td>\n",
       "      <td>0.855107</td>\n",
       "      <td>1.188424</td>\n",
       "      <td>0.453939</td>\n",
       "      <td>1.090102</td>\n",
       "      <td>0.917642</td>\n",
       "      <td>0.903485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-18</th>\n",
       "      <td>1.028443</td>\n",
       "      <td>0.943412</td>\n",
       "      <td>1.580587</td>\n",
       "      <td>1.812500</td>\n",
       "      <td>0.853127</td>\n",
       "      <td>1.146865</td>\n",
       "      <td>0.447263</td>\n",
       "      <td>1.093429</td>\n",
       "      <td>0.920478</td>\n",
       "      <td>0.855459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-19</th>\n",
       "      <td>1.028443</td>\n",
       "      <td>0.945716</td>\n",
       "      <td>1.561949</td>\n",
       "      <td>1.848214</td>\n",
       "      <td>0.853127</td>\n",
       "      <td>1.144641</td>\n",
       "      <td>0.437917</td>\n",
       "      <td>1.088763</td>\n",
       "      <td>0.917642</td>\n",
       "      <td>0.822442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               UTAAU      VTEB        AB      PFMT     NYMTL       CWS  \\\n",
       "2021-12-28  0.998004  1.055554  1.931508  2.071429  0.982581  1.418542   \n",
       "2021-12-29  1.000000  1.054978  1.920872  2.044643  0.981789  1.412781   \n",
       "2021-12-30  0.999002  1.054786  1.930720  2.169643  0.969121  1.423848   \n",
       "2021-12-31  1.006487  1.054402  1.924023  2.151786  0.971892  1.429555   \n",
       "2022-01-03  0.997804  1.053825  1.919296  2.232143  0.972447  1.403939   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2022-05-13  1.021058  0.946292  1.547768  2.098214  0.883215  1.172294   \n",
       "2022-05-16  1.028443  0.947060  1.533182  2.008929  0.863816  1.172669   \n",
       "2022-05-17  1.028443  0.944372  1.602467  1.964286  0.855107  1.188424   \n",
       "2022-05-18  1.028443  0.943412  1.580587  1.812500  0.853127  1.146865   \n",
       "2022-05-19  1.028443  0.945716  1.561949  1.848214  0.853127  1.144641   \n",
       "\n",
       "                VEEE     OXLCM       MCR       MPX  \n",
       "2021-12-28  0.555407  1.092997  1.201320  0.923236  \n",
       "2021-12-29  0.579439  1.090837  1.211109  0.934386  \n",
       "2021-12-30  0.562083  1.091701  1.209711  0.934386  \n",
       "2021-12-31  0.535381  1.091701  1.191530  0.929182  \n",
       "2022-01-03  0.514019  1.093429  1.192928  0.935873  \n",
       "...              ...       ...       ...       ...  \n",
       "2022-05-13  0.420561  1.089109  0.916224  0.855459  \n",
       "2022-05-16  0.445928  1.090837  0.921897  0.855459  \n",
       "2022-05-17  0.453939  1.090102  0.917642  0.903485  \n",
       "2022-05-18  0.447263  1.093429  0.920478  0.855459  \n",
       "2022-05-19  0.437917  1.088763  0.917642  0.822442  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_seq(x,LEN=100):\n",
    "    l=len(x)\n",
    "    if(l<LEN):\n",
    "        return x \n",
    "    \n",
    "    start=np.random.randint(l-LEN)\n",
    "    return x.iloc[start:start+LEN]\n",
    "sample_seq(v[-1]) \n",
    "sample_seq(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af077c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(17, 99), dtype=int32, numpy=\n",
       " array([[ 2,  3,  4, ...,  1,  2,  3],\n",
       "        [ 1,  2,  3, ...,  0,  1,  2],\n",
       "        [ 0,  1,  2, ..., -1, -1, -1],\n",
       "        ...,\n",
       "        [ 4,  0,  1, ...,  4,  0,  1],\n",
       "        [ 1,  2,  3, ...,  0,  1,  2],\n",
       "        [ 3,  4,  1, ...,  3,  4,  0]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float32, numpy=\n",
       " array([[ 0.16666663,  0.20000005,  0.23333335, ...,  0.79999995,\n",
       "          0.83333325,  0.8666667 ],\n",
       "        [ 0.33333337,  0.36666667,  0.39999998, ...,  0.9       ,\n",
       "          0.9333334 ,  0.9666667 ],\n",
       "        [ 0.13333333,  0.16666663,  0.20000005, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.33333337,  0.4333334 ,  0.4666667 , ...,  0.9666667 ,\n",
       "          0.06666672,  0.10000002],\n",
       "        [ 0.9333334 ,  0.9666667 ,  1.        , ...,  0.5333333 ,\n",
       "          0.5666666 ,  0.6       ],\n",
       "        [ 0.4333334 ,  0.4666667 ,  0.6       , ...,  0.06666672,\n",
       "          0.10000002,  0.20000005]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float32, numpy=\n",
       " array([[ 0.08333337,  0.08333337,  0.08333337, ...,  0.41666663,\n",
       "          0.41666663,  0.41666663],\n",
       "        [ 0.66666675,  0.66666675,  0.66666675, ...,  1.        ,\n",
       "          1.        ,  1.        ],\n",
       "        [ 0.33333337,  0.33333337,  0.33333337, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  0.33333337,\n",
       "          0.41666663,  0.41666663],\n",
       "        [ 1.        ,  1.        ,  1.        , ...,  0.41666663,\n",
       "          0.41666663,  0.41666663],\n",
       "        [ 0.08333337,  0.08333337,  0.08333337, ...,  0.5       ,\n",
       "          0.5       ,  0.5       ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=int32, numpy=\n",
       " array([[ 2,  2,  2, ...,  2,  2,  2],\n",
       "        [ 1,  1,  1, ...,  1,  1,  1],\n",
       "        [ 2,  2,  2, ..., -1, -1, -1],\n",
       "        ...,\n",
       "        [ 1,  1,  1, ...,  2,  2,  2],\n",
       "        [ 1,  1,  1, ...,  2,  2,  2],\n",
       "        [ 2,  2,  2, ...,  2,  2,  2]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.00399201,  0.99900197,  0.99800395, ...,  1.01197604,\n",
       "          1.02994004,  1.00938122],\n",
       "        [ 1.33304762,  1.34166181,  1.34489211, ...,  1.40653751,\n",
       "          1.40626836,  1.41003706],\n",
       "        [ 1.20674235,  1.21298871,  1.23936237, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.78016088,  0.78284184,  0.76407504, ...,  0.75603215,\n",
       "          0.7453083 ,  0.74798926],\n",
       "        [ 0.25130436,  0.24521739,  0.25913044, ...,  0.14347826,\n",
       "          0.13913044,  0.13043478],\n",
       "        [ 1.59672885,  1.60968954,  1.53107189, ...,  1.45313302,\n",
       "          1.44163759,  1.45099436]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.05248133,  1.05132916,  1.04883283, ...,  0.96011795,\n",
       "          0.96607071,  0.97144735],\n",
       "        [ 2.91506882,  2.85650076,  2.89050322, ...,  2.05662071,\n",
       "          2.02097055,  2.06411023],\n",
       "        [ 0.31562501,  0.30562499,  0.29499999, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 2.60995256,  2.59064328,  2.57718211, ...,  1.55610728,\n",
       "          1.57442355,  1.58380225],\n",
       "        [ 0.3236994 ,  0.31791907,  0.32947977, ...,  0.09865125,\n",
       "          0.10019267,  0.09518304],\n",
       "        [ 1.02154379,  1.01643275,  1.01046991, ...,  0.91884993,\n",
       "          0.91771412,  0.91298168]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.8444467 ,  1.84799219,  1.91535663, ...,  1.605708  ,\n",
       "          1.66324276,  1.71267414],\n",
       "        [ 1.3084918 ,  1.31634165,  1.31703943, ...,  1.38978185,\n",
       "          1.39431738,  1.39763183],\n",
       "        [ 1.        ,  1.0032    ,  0.99456001, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 5.75025078,  5.62086253,  5.55967892, ...,  2.81945836,\n",
       "          2.87061184,  2.893681  ],\n",
       "        [ 0.7889504 ,  0.76014007,  0.80115243, ...,  0.69483672,\n",
       "          0.72579365,  0.73144273],\n",
       "        [ 1.10258198,  1.10220541,  1.09316786, ...,  0.9722905 ,\n",
       "          0.97304364,  0.97078427]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 2.03571425,  2.00892856,  1.97321431, ...,  1.90178581,\n",
       "          1.98214287,  2.0714285 ],\n",
       "        [ 0.99390859,  0.99390859,  0.99451768, ...,  1.00609132,\n",
       "          1.00507606,  1.00406091],\n",
       "        [ 1.91104862,  1.78370774,  1.65543069, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.35608588,  1.33803338,  1.29075312, ...,  1.18243815,\n",
       "          1.20822744,  1.19963098],\n",
       "        [ 0.88892667,  0.89928   ,  0.90390084, ...,  0.83208948,\n",
       "          0.83615418,  0.82498518],\n",
       "        [ 1.00709217,  1.00709217,  1.00709217, ...,  1.01975681,\n",
       "          1.01975681,  1.01975681]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 0.97466352,  0.97228817,  0.97232781, ...,  0.8393903 ,\n",
       "          0.84125098,  0.85213774],\n",
       "        [ 0.16784917,  0.16660698,  0.16482136, ...,  0.12538224,\n",
       "          0.12561515,  0.1253046 ],\n",
       "        [ 1.23190101,  1.19256265,  1.17193863, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.76055163,  0.7342248 ,  0.72670285, ...,  0.59465104,\n",
       "          0.60718761,  0.57877143],\n",
       "        [ 1.25397777,  1.25397777,  1.25397777, ...,  0.99959301,\n",
       "          1.00049025,  1.00004167],\n",
       "        [ 7.81918031,  8.58641309, 10.15284665, ...,  4.89510478,\n",
       "          4.91928066,  4.95354625]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.39096998,  1.38531622,  1.37596469, ...,  1.15527873,\n",
       "          1.16468381,  1.18574489],\n",
       "        [ 0.99808754,  1.00133868,  0.99502769, ...,  0.98336197,\n",
       "          0.97991969,  0.97915471],\n",
       "        [ 0.33012864,  0.30683488,  0.29719609, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.05154977,  1.0469045 ,  1.03962841, ...,  0.96341366,\n",
       "          0.96982648,  0.97591053],\n",
       "        [ 0.97299995,  0.97299995,  0.97600002, ...,  0.979     ,\n",
       "          0.979     ,  0.979     ],\n",
       "        [ 2.23199997,  2.16666667,  2.2253334 , ...,  3.98666662,\n",
       "          4.01999995,  4.05199992]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 0.51134847,  0.51401869,  0.5327103 , ...,  0.43257678,\n",
       "          0.43124167,  0.43257678],\n",
       "        [ 1.05261236,  1.05261236,  1.05261236, ...,  1.03885271,\n",
       "          1.03925742,  1.03925742],\n",
       "        [ 1.0040201 ,  1.0040201 ,  1.0040201 , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.19431451,  1.19706956,  1.18880455, ...,  1.08173829,\n",
       "          1.06052772,  1.06335579],\n",
       "        [ 0.99689122,  0.99689122,  0.99689122, ...,  1.00362703,\n",
       "          1.00414507,  1.00518137],\n",
       "        [ 1.37140882,  1.37140882,  1.34256908, ...,  1.27928178,\n",
       "          1.26831484,  1.27436461]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.09342894,  1.09515704,  1.09515704, ...,  1.09930433,\n",
       "          1.09662591,  1.09040485],\n",
       "        [ 0.75492961,  0.7605634 ,  0.7605634 , ...,  0.63380283,\n",
       "          0.62816903,  0.63380283],\n",
       "        [ 0.996004  ,  0.996004  ,  0.996004  , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.99790274,  0.99870172,  0.99780292, ...,  0.94297414,\n",
       "          0.94217516,  0.94287433],\n",
       "        [ 0.66177981,  0.65798368,  0.65696368, ...,  0.51391471,\n",
       "          0.52288575,  0.51006993],\n",
       "        [ 1.01994755,  1.03396012,  1.01154006, ...,  1.03824628,\n",
       "          1.03198184,  1.03280616]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 1.18034187,  1.17614638,  1.17334947, ...,  0.93040656,\n",
       "          0.92898829,  0.93891637],\n",
       "        [ 1.34755591,  1.37489642,  1.35211268, ...,  1.69055519,\n",
       "          1.70712511,  1.69221208],\n",
       "        [ 1.38935139,  1.37056567,  1.35457768, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.1952055 ,  1.20113552,  1.19105438, ...,  1.24605581,\n",
       "          1.2354311 ,  1.25025623],\n",
       "        [ 0.35789474,  0.35438597,  0.36140351, ...,  0.22350879,\n",
       "          0.23508773,  0.23894737],\n",
       "        [ 1.00201821,  1.00302722,  1.00302722, ...,  1.01009086,\n",
       "          1.01210897,  1.01412718]])>,\n",
       " <tf.Tensor: shape=(17, 99), dtype=float64, numpy=\n",
       " array([[ 0.90242204,  0.9180323 ,  0.90762546, ...,  0.78191998,\n",
       "          0.79092481,  0.79542726],\n",
       "        [ 0.88919465,  0.9059608 ,  0.90243112, ...,  0.94772918,\n",
       "          0.95743585,  0.96949571],\n",
       "        [ 1.45713512,  1.42763224,  1.40809144, ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 0.23621399,  0.22798354,  0.21893006, ...,  0.12345679,\n",
       "          0.12427984,  0.12921812],\n",
       "        [ 1.52690204,  1.5276738 ,  1.50182019, ...,  1.59134301,\n",
       "          1.6106367 ,  1.56471764],\n",
       "        [ 5.14035074,  5.24561407,  5.1754387 , ...,  2.25730983,\n",
       "          2.31578944,  2.16959062]])>,\n",
       " <tf.Tensor: shape=(17, 10), dtype=string, numpy=\n",
       " array([[b'UTAAU', b'VTEB', b'AB', b'PFMT', b'NYMTL', b'CWS', b'VEEE',\n",
       "         b'OXLCM', b'MCR', b'MPX'],\n",
       "        [b'FVAL', b'FIVN', b'RWL', b'OCAX', b'SPXS', b'EJUL', b'IBDO',\n",
       "         b'RSSS', b'ENVA', b'MOFG'],\n",
       "        [b'RYU', b'HNST', b'CAPE', b'DKNG', b'MGA', b'MLCO', b'KNSW.U',\n",
       "         b'HAIAU', b'XVV', b'FIVG'],\n",
       "        [b'PKBK', b'AVDV', b'KF', b'BGI', b'CLOE', b'MYI', b'XSHD',\n",
       "         b'AAPL', b'KEP', b'LUXA'],\n",
       "        [b'PLM', b'LABP', b'KEYS', b'AGYS', b'BCI', b'REGN', b'FTCS',\n",
       "         b'VSGX', b'DOMO', b'SIFY'],\n",
       "        [b'PNF', b'DFAI', b'CCNE', b'TEDU', b'KESG', b'XJH', b'UFAB',\n",
       "         b'ESGS', b'VVOS', b'SGA'],\n",
       "        [b'FNCB', b'MXCT', b'UNB', b'RFEM', b'LPSN', b'SSBK', b'WPCA.U',\n",
       "         b'SOLO', b'NKG', b'IBTJ'],\n",
       "        [b'QGRO', b'WTI', b'ALGS', b'RIET', b'PNAC', b'COOP', b'IXJ',\n",
       "         b'IXUS', b'URNM', b'YLD'],\n",
       "        [b'UXIN', b'AMPE', b'D', b'FBC', b'BSTP', b'ACON', b'CLEU',\n",
       "         b'NREF', b'RIDE', b'THAC'],\n",
       "        [b'ONEV', b'QTUM', b'HMACU', b'ARKF', b'DTOCU', b'ACET', b'ISHG',\n",
       "         b'WBEV', b'ASR', b'VERX'],\n",
       "        [b'NORW', b'KALV', b'GXII', b'BF-B', b'OMFS', b'ABSI', b'ARCO',\n",
       "         b'CSGP', b'ALOR', b'ONVO'],\n",
       "        [b'RE', b'CPA', b'EATZ', b'MHN', b'ELYS', b'FBRX', b'BZH',\n",
       "         b'GIA.U', b'HTIA', b'NSS'],\n",
       "        [b'DUOT', b'EES', b'GIPR', b'LD', b'FLQS', b'ESM', b'BKSC',\n",
       "         b'TBIL', b'AIBBU', b'DTW'],\n",
       "        [b'RIBT', b'QLS', b'ROL', b'WIZ', b'URE', b'KOSS', b'CHX',\n",
       "         b'OSUR', b'GNE', b'MACA'],\n",
       "        [b'IAG', b'SITE', b'OPRX', b'ZTO', b'VERX', b'XTOC', b'PCF',\n",
       "         b'DFSD', b'ECLN', b'HOOK'],\n",
       "        [b'HIPO', b'CLSN', b'MSGE', b'ALX', b'NUSI', b'ACII', b'CLBR',\n",
       "         b'AVAL', b'NAOV', b'ODP'],\n",
       "        [b'UI', b'BGRN', b'RZB', b'SANB', b'DWACU', b'TRQ', b'FTDS',\n",
       "         b'BF.A', b'DSAQ', b'AZ']], dtype=object)>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base=[sample_seq(x) for x in v]\n",
    "y=[s.iloc[1:,0] for s in base]\n",
    "x=[s[:-1] for s in base]\n",
    "x=get_xs(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dd0f22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9928314685821533\n"
     ]
    }
   ],
   "source": [
    "def get_numbers(tickers):\n",
    "    v=choose_stocks_df(tickers)\n",
    "    base=[sample_seq(x) for x in v]\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73d7c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 10), dtype=tf.string, name=None),\n",
       " TensorSpec(shape=(None, 99), dtype=tf.float64, name=None)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs=[tf.TensorSpec.from_tensor(x) for x in n]\n",
    "s=[list(x.shape) for x in specs]\n",
    "for x in s:\n",
    "    x[0]=None\n",
    "specs=[tf.TensorSpec(s[i],specs[i].dtype) for i in range(len(specs))]\n",
    "specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3332fee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2, 3), 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_x(*args):\n",
    "    return args[:-1]\n",
    "\n",
    "def gather_y(*args):\n",
    "    return args[-1]\n",
    "\n",
    "gather_x(1,2,3,4),gather_y(1,2,3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42151e2f",
   "metadata": {},
   "source": [
    "# train dataset \n",
    "because of the need to use the dataset as a refrence type in the pandas df we are forcing tensorflow to run the whole thing eagerly. \n",
    "\n",
    "it shouldnt be a major issue since most the heavy lifting is done in pandas which is optimized c code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aa0fa0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  3,  4, ...,  2,  3,  4],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 0,  1,  2, ...,  4,  0,  1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.39999998,  0.4333334 ,  0.4666667 , ...,  0.0333333 ,\n",
       "           0.06666672,  0.10000002],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.66666675,  0.70000005,  0.73333335, ...,  0.13333333,\n",
       "           0.23333335,  0.26666665],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.08333337,  0.08333337,  0.08333337, ...,  0.5       ,\n",
       "           0.5       ,  0.5       ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.75      ,  0.75      ,  0.75      , ...,  0.16666663,\n",
       "           0.16666663,  0.16666663],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ...,  2,  2,  2],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  1,  1, ...,  2,  2,  2],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.74223   ,  0.69537229,  0.6940531 , ...,  0.37966334,\n",
       "           0.38504566,  0.3590312 ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.91870966,  0.91322579,  0.90612904, ...,  0.57741934,\n",
       "           0.60612906,  0.62096774],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.4018963 ,  1.39140644,  1.45884134, ...,  2.3590151 ,\n",
       "           2.34548358,  2.38156791],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.83170004,  1.84022847,  1.91395866, ...,  1.84738145,\n",
       "           1.84270459,  1.92028635],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.96335582,  0.96335582,  0.96142723, ...,  0.97203472,\n",
       "           0.97299906,  0.97299906],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.03884292,  1.02727272,  1.03966938, ...,  1.26776857,\n",
       "           1.26198347,  1.31818176],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.23479408,  1.21424345,  1.19909797, ...,  1.13697252,\n",
       "           1.13802204,  1.13985882],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.94736844,  1.09806892,  1.19121542, ...,  1.28966307,\n",
       "           1.32487701,  1.29912918],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.21354145,  1.20794736,  1.20811318, ...,  1.15503161,\n",
       "           1.16767009,  1.15557024],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 2.36153097,  2.45416541,  2.4901897 , ...,  0.98263104,\n",
       "           0.99485366,  1.03055647],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.13535504,  1.12399538,  1.1219669 , ...,  0.96394624,\n",
       "           0.97408877,  0.95278947],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.90436506,  0.89574355,  0.89782461, ...,  0.8214986 ,\n",
       "           0.8214986 ,  0.83763574],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.93659751,  0.95440355,  0.95262297, ...,  0.9476373 ,\n",
       "           0.95048627,  0.96152599],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.48949976,  1.49763872,  1.52065676, ...,  1.50240109,\n",
       "           1.50903388,  1.50763077],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.28765722,  1.28029012,  1.28730478, ...,  1.17168709,\n",
       "           1.18550476,  1.17577592],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 2.57693659,  2.5794127 ,  2.51998573, ...,  2.20516446,\n",
       "           2.20587193,  2.25114957],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.00203463,  1.00203463,  1.00712103, ...,  1.00813834,\n",
       "           1.00712103,  1.00712103],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.5198697 ,  0.51530942,  0.49967426, ...,  0.27687296,\n",
       "           0.28273616,  0.27296417],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.21261503,  1.20496123,  1.20599551, ...,  1.13578711,\n",
       "           1.14447528,  1.13831084],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.03378496,  1.03394812,  1.0345601 , ...,  0.98784986,\n",
       "           0.98866578,  0.98642204],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 10), dtype=string, numpy=\n",
       "  array([[b'NWBI', b'UAPR', b'BUYW', b'OVF', b'GII', b'PUI', b'BKEM',\n",
       "          b'EVSTC', b'CLIM', b'DSEP'],\n",
       "         [b'DASH', b'MRO', b'KINZ', b'BME', b'AZAA', b'BBJP', b'GBLI',\n",
       "          b'FFHG', b'CBRG', b'AZAL'],\n",
       "         [b'ANF', b'HYGW', b'GIA.U', b'OSTRU', b'PACI.U', b'FBP', b'WFC',\n",
       "          b'CACG', b'TROO', b'SMFG'],\n",
       "         [b'IQM', b'PHVS', b'PICC.U', b'PLDR', b'FDN', b'KROP', b'JHMU',\n",
       "          b'NEXI', b'ALDX', b'SHYD'],\n",
       "         [b'AGE', b'YYY', b'ASLN', b'TEN', b'FDLS', b'LNTH', b'NSC',\n",
       "          b'ADMP', b'MMIN', b'NRUC'],\n",
       "         [b'BUFR', b'HZON.U', b'HMA.U', b'RMBI', b'DZZ', b'IBN', b'NAZ',\n",
       "          b'ECC', b'IFRX', b'GOF'],\n",
       "         [b'FUSN', b'BLUE', b'CLRO', b'DFAS', b'SPB', b'TUP', b'XLG',\n",
       "          b'MEOA', b'GLCN', b'ABUS'],\n",
       "         [b'GVP', b'CTSH', b'BSMR', b'LIXT', b'LCNB', b'MMIT', b'FLWS',\n",
       "          b'BSCM', b'BOCNU', b'SPYG'],\n",
       "         [b'CLIX', b'MTCR', b'SNPE', b'STET', b'OCC', b'EEIQ', b'TY',\n",
       "          b'BAC', b'PSFJ', b'TSEM'],\n",
       "         [b'ITRG', b'IBMQ', b'IJR', b'SLVM', b'CGXU', b'TEI', b'FFTG',\n",
       "          b'VBK', b'VOC', b'SKLZ'],\n",
       "         [b'UTL', b'FMAT', b'GURU', b'CCOR', b'GIM', b'TSIB', b'NISN',\n",
       "          b'VTEX', b'TLH', b'GSIE'],\n",
       "         [b'UPWK', b'RCEL', b'AXTI', b'BRK.A', b'YSG', b'VSTO', b'ANEW',\n",
       "          b'DC.W', b'WEED', b'WABC'],\n",
       "         [b'NBR', b'SSG', b'ESGN', b'ADEX', b'WERN', b'PTBD', b'CRKN',\n",
       "          b'CHI', b'AGI', b'AGGY'],\n",
       "         [b'PRCH', b'BPTH', b'METC', b'BSCW', b'FITE', b'PARR', b'REAX',\n",
       "          b'FTPA', b'CNXC', b'EMZA'],\n",
       "         [b'AOMR', b'HYLS', b'NREF', b'SPXC', b'FBHS', b'CVY', b'PZZA',\n",
       "          b'BHSEU', b'JSCP', b'VRAR'],\n",
       "         [b'TKNO', b'GBUG', b'HYRE', b'BSMX', b'FTAIN', b'AVYA', b'VERA',\n",
       "          b'BITI', b'NHIC', b'ISCF'],\n",
       "         [b'BGNE', b'IBTL', b'NTZ', b'BNDC', b'LVO', b'FTAA', b'MMTM',\n",
       "          b'NEWR', b'IPOD.U', b'STRE'],\n",
       "         [b'STNG', b'SPDV', b'DKS', b'PEGA', b'TECL', b'SNDA', b'TXT',\n",
       "          b'KBWR', b'OZ', b'CDAQU'],\n",
       "         [b'HORI', b'ASO', b'AGNCO', b'KLCD', b'AVACU', b'BCD', b'GHIXU',\n",
       "          b'RAYD', b'WRAP', b'BUSE'],\n",
       "         [b'AFGD', b'SAND', b'LEXX', b'CAF', b'FUN', b'JPM', b'SPUS',\n",
       "          b'SNBR', b'SDAC', b'IBHG'],\n",
       "         [b'WCN', b'CLXT', b'BHAC', b'CCTSU', b'FBRX', b'HYB', b'HSII',\n",
       "          b'TFLO', b'SCOA', b'RTM'],\n",
       "         [b'UHAL', b'DHHC', b'NARI', b'FLQS', b'ASGI', b'CRDO', b'NFLT',\n",
       "          b'FTQI', b'RCUS', b'DJCB'],\n",
       "         [b'SNPS', b'VTAQ', b'QSI', b'RACY', b'BHFAN', b'ASAQ.U', b'USPH',\n",
       "          b'XRT', b'SA', b'ARCE'],\n",
       "         [b'HVT.A', b'SU', b'ENCPU', b'GAN', b'HIBL', b'BHAC', b'DWX',\n",
       "          b'DTB', b'HIO', b'SYLD'],\n",
       "         [b'CLOI', b'OXM', b'WISH', b'FIBK', b'ISIG', b'BAND', b'IBB',\n",
       "          b'GENY', b'SLAC.U', b'QDPL'],\n",
       "         [b'MNKD', b'REFR', b'IBTG', b'VYGG', b'BLDP', b'VABK', b'PTEN',\n",
       "          b'AMZA', b'TMCI', b'SXQG'],\n",
       "         [b'BKD', b'BOTJ', b'ARRW', b'TTOO', b'PNT', b'EVEN', b'DDM',\n",
       "          b'INGN', b'ENER', b'BPTH'],\n",
       "         [b'RGF', b'OCAX', b'CX', b'JGH', b'ALTO', b'DFIV', b'FRXB.U',\n",
       "          b'EIC', b'RILYG', b'HART'],\n",
       "         [b'SMH', b'TAIT', b'TJX', b'ATAKU', b'DG', b'NUWE', b'WEJO',\n",
       "          b'EMCB', b'AKO.B', b'XOMA'],\n",
       "         [b'AGL', b'WANT', b'CARS', b'VALN', b'TASK', b'FDP', b'MSI',\n",
       "          b'DAR', b'PSTX', b'BYLD'],\n",
       "         [b'USVM', b'CGV', b'XSHD', b'QDPL', b'SHCA', b'GLQ', b'TRT',\n",
       "          b'LPX', b'TMCI', b'HUGS'],\n",
       "         [b'FLRG', b'IDVO', b'RWK', b'CMPO', b'APLD', b'IAA', b'VVPR',\n",
       "          b'FRWAU', b'SYK', b'BIDS']], dtype=object)>),\n",
       " <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       " array([[ 1.00139303,  1.00139303,  1.00199   , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.99180333,  0.99180333,  0.99487705, ...,  0.91495906,\n",
       "          0.91524595,  0.90819673],\n",
       "        [ 1.02814068,  1.08442213,  1.09045232, ...,  1.00603019,\n",
       "          1.00603019,  1.00603019],\n",
       "        ...,\n",
       "        [ 1.03287523,  1.03225563,  1.03457582, ...,  1.03709696,\n",
       "          1.04105294,  1.04105294],\n",
       "        [ 0.50300002,  0.5085    ,  0.52199998, ...,  0.31099999,\n",
       "          0.30599999,  0.30650001],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]])>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "train_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=train_dataset.map(gather_x)\n",
    "dataset_y=train_dataset.map(gather_y)\n",
    "train_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=train_dataset.take(1).get_single_element()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04dd2a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 99), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 10), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcadff88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': (<tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  3,  4, ...,  2,  3,  4],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 0,  1,  2, ...,  4,  0,  1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.39999998,  0.4333334 ,  0.4666667 , ...,  0.0333333 ,\n",
       "           0.06666672,  0.10000002],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.66666675,  0.70000005,  0.73333335, ...,  0.13333333,\n",
       "           0.23333335,  0.26666665],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float32, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.08333337,  0.08333337,  0.08333337, ...,  0.5       ,\n",
       "           0.5       ,  0.5       ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.75      ,  0.75      ,  0.75      , ...,  0.16666663,\n",
       "           0.16666663,  0.16666663],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]], dtype=float32)>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=int32, numpy=\n",
       "  array([[-1, -1, -1, ..., -1, -1, -1],\n",
       "         [ 2,  2,  2, ...,  2,  2,  2],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         ...,\n",
       "         [ 1,  1,  1, ...,  2,  2,  2],\n",
       "         [-1, -1, -1, ..., -1, -1, -1],\n",
       "         [-1, -1, -1, ..., -1, -1, -1]])>),\n",
       " 'prices': (<tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.74223   ,  0.69537229,  0.6940531 , ...,  0.37966334,\n",
       "           0.38504566,  0.3590312 ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.91870966,  0.91322579,  0.90612904, ...,  0.57741934,\n",
       "           0.60612906,  0.62096774],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.4018963 ,  1.39140644,  1.45884134, ...,  2.3590151 ,\n",
       "           2.34548358,  2.38156791],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.83170004,  1.84022847,  1.91395866, ...,  1.84738145,\n",
       "           1.84270459,  1.92028635],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 0.96335582,  0.96335582,  0.96142723, ...,  0.97203472,\n",
       "           0.97299906,  0.97299906],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 1.03884292,  1.02727272,  1.03966938, ...,  1.26776857,\n",
       "           1.26198347,  1.31818176],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.23479408,  1.21424345,  1.19909797, ...,  1.13697252,\n",
       "           1.13802204,  1.13985882],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.94736844,  1.09806892,  1.19121542, ...,  1.28966307,\n",
       "           1.32487701,  1.29912918],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.21354145,  1.20794736,  1.20811318, ...,  1.15503161,\n",
       "           1.16767009,  1.15557024],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 2.36153097,  2.45416541,  2.4901897 , ...,  0.98263104,\n",
       "           0.99485366,  1.03055647],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>,\n",
       "  <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       "  array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [ 1.13535504,  1.12399538,  1.1219669 , ...,  0.96394624,\n",
       "           0.97408877,  0.95278947],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         ...,\n",
       "         [ 0.90436506,  0.89574355,  0.89782461, ...,  0.8214986 ,\n",
       "           0.8214986 ,  0.83763574],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ],\n",
       "         [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "          -1.        , -1.        ]])>),\n",
       " 'tickers': <tf.Tensor: shape=(32, 99), dtype=float64, numpy=\n",
       " array([[-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [ 0.93659751,  0.95440355,  0.95262297, ...,  0.9476373 ,\n",
       "          0.95048627,  0.96152599],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        ...,\n",
       "        [ 1.48949976,  1.49763872,  1.52065676, ...,  1.50240109,\n",
       "          1.50903388,  1.50763077],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ],\n",
       "        [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "         -1.        , -1.        ]])>}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cut23(x):\n",
    "    return {\"time\":x[:4],\"prices\":x[4:NUM_STOCKS],\"tickers\":x[NUM_STOCKS]}\n",
    "\n",
    "cut23(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6797d8",
   "metadata": {},
   "source": [
    "# validation dataset \n",
    "on infrance the best results would probably be achived by runing on every time entry with at least some memory of the past\n",
    "\n",
    "that means there would need to be some precomputation which we can make diffrent for timesetep. \n",
    "\n",
    "this is rediclously slow and combersom to write so our validation is just gona look mostly like the training. \n",
    "after choosing the stocks we would want to work with we are going to think of test behivior \n",
    "\n",
    "we may want to just train a new model from scratch only on that subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1591baa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7330348491668701\n"
     ]
    }
   ],
   "source": [
    "def get_val_numbers(tickers):\n",
    "    base=choose_stocks_df(tickers,test_df)\n",
    "    \n",
    "    y=[s.iloc[1:,0].to_numpy() for s in base]\n",
    "    y=tf.ragged.constant(y)\n",
    "    y=(y+1).to_tensor()-1\n",
    "    \n",
    "    x=[s[:-1] for s in base]\n",
    "    x=get_xs(x)\n",
    "    #x.append(tickers)\n",
    "    x.append(y)\n",
    "    return x\n",
    "t=time.time()\n",
    "n=get_val_numbers(exmple)\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8457e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to do training and test set (test set should look diffrent)\n",
    "val_dataset=dataset.shuffle(1000).batch(32).map(lambda y: tf.py_function(get_val_numbers,inp=[y],Tout=specs))\n",
    "\n",
    "dataset_x=val_dataset.map(gather_x)\n",
    "dataset_y=val_dataset.map(gather_y)\n",
    "val_dataset=tf.data.Dataset.zip((dataset_x,dataset_y))\n",
    "\n",
    "x=val_dataset.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c57d6604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorSpec(shape=(32, 68), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.int32, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 68), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(32, 10), dtype=tf.string, name=None)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tf.TensorSpec.from_tensor(x) for x in x[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10f40e",
   "metadata": {},
   "source": [
    "# the model\n",
    "\n",
    "**the dataset is dependent on the model!!!** this means we have some considerations on how it should look like:\n",
    "\n",
    "* there has to be an attention mechanisem on embeding space. (using only the sampling embedings dot product) \n",
    "* embedings convergnce and stabilety greatly effects the models training. (we may want to consider reverse regularization)\n",
    "*  at least some part of the model should be seprable by stock, in order to reduce noise from data sampeling\n",
    "* it would defintly help if we add residual conections to the embedings to alow gradients to flow to the embedings\n",
    "\n",
    "*side note: the padding used is -1, seems like it should propgate to the loss*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee7b9d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 32) dtype=float32 (created by layer 'concatenate_153')>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up the inputs\n",
    "inputs=[layers.Input([None,],dtype=x.dtype) for x in specs[:-2]]\n",
    "inputs.append(layers.Input(specs[-2].shape[1:],dtype=specs[-2].dtype,name=\"tickers\"))\n",
    "\n",
    "#for testing\n",
    "#inputs=numbers[:-1]\n",
    "\n",
    "#time encoding\n",
    "time_depndent=[tf.expand_dims(x,-1) for x in inputs[:-1]] \n",
    "time_depndent=[layers.Masking(-1)(x) for x in time_depndent] \n",
    "\n",
    "\n",
    "day_embeding=layers.Embedding(7,7)(time_depndent[0])\n",
    "year_embeding=layers.Embedding(3,5)(time_depndent[3]) \n",
    "\n",
    "day_embeding=layers.TimeDistributed(layers.Reshape([7]))(day_embeding)\n",
    "year_embeding=layers.TimeDistributed(layers.Reshape([5]))(year_embeding)\n",
    "\n",
    "t=layers.Concatenate(-1)(time_depndent[1:3])\n",
    "t=layers.Dense(20)(t) \n",
    "\n",
    "time_encoding=layers.Concatenate(-1)([day_embeding,t,year_embeding])\n",
    "time_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35a4d0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1, 10) dtype=float32 (created by layer 'tf.nn.softmax_1')>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tickers=look(inputs[-1])\n",
    "#tickers=tick_embed(tickers)\n",
    "tickers=layers.Reshape([NUM_STOCKS,1])(inputs[-1])\n",
    "tickers=layers.TimeDistributed(ticker_model)(tickers)\n",
    "tickers=layers.Reshape([NUM_STOCKS,512])(tickers)\n",
    "origin=tf.expand_dims(tickers[:,0],-2)\n",
    "origin=layers.Permute([2,1])(origin)\n",
    "attention=tickers@origin\n",
    "attention=layers.Permute([2,1])(attention)\n",
    "attention=tf.nn.softmax(attention)\n",
    "attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba123b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10, 33) dtype=float32 (created by layer 'dense_3')>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp=layers.Dense(33)(tickers)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2aae664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 10, 16) dtype=float32 (created by layer 'concatenate_164')>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"need to add stock conditioning\"\n",
    "prices=time_depndent[4:4+NUM_STOCKS]\n",
    "s=[layers.Concatenate(-1)([time_encoding,x]) for x in prices]\n",
    "\n",
    "#adding ticker information (while not alowing it to effect the mask)\n",
    "#masks=[x._keras_mask for x in s] \n",
    "s=[layers.Add()([s[i],comp[:,i]]) for i in range(len(s))]\n",
    "\n",
    "stock_layer=layers.LSTM(16,return_sequences=True)\n",
    "s=[stock_layer(s[i]) for i in range(len(s))]#,mask=masks[i])\n",
    "stock_layer=layers.GRU(16,return_sequences=True)\n",
    "s=[stock_layer(x) for x in s]\n",
    "\n",
    "s=[tf.expand_dims(x,-2) for x in s]\n",
    "s=layers.Concatenate(-2)(s)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "637e0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 16) dtype=float32 (created by layer 'time_distributed_6')>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sumorized=attention@tf.transpose(s,[1,0,2,3])\n",
    "sumorized=tf.transpose(sumorized,[1,0,2,3])\n",
    "sumorized=layers.TimeDistributed(layers.Reshape([16]))(sumorized)\n",
    "sumorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1afd6598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None) dtype=float32 (created by layer 'global_max_pooling1d')>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=layers.LSTM(8,return_sequences=True)(sumorized)\n",
    "x=layers.LayerNormalization()(x)\n",
    "x=layers.Permute([2,1])(x)\n",
    "x=layers.GlobalMaxPool1D()(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a457a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_57 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_58 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_59 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_60 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " tickers (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.expand_dims_55 (TFOpLambda)  (None, None, 1)     0           ['input_57[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_56 (TFOpLambda)  (None, None, 1)     0           ['input_58[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_57 (TFOpLambda)  (None, None, 1)     0           ['input_59[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_58 (TFOpLambda)  (None, None, 1)     0           ['input_60[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 10, 1)        0           ['tickers[0][0]']                \n",
      "                                                                                                  \n",
      " masking_54 (Masking)           (None, None, 1)      0           ['tf.expand_dims_55[0][0]']      \n",
      "                                                                                                  \n",
      " masking_55 (Masking)           (None, None, 1)      0           ['tf.expand_dims_56[0][0]']      \n",
      "                                                                                                  \n",
      " masking_56 (Masking)           (None, None, 1)      0           ['tf.expand_dims_57[0][0]']      \n",
      "                                                                                                  \n",
      " masking_57 (Masking)           (None, None, 1)      0           ['tf.expand_dims_58[0][0]']      \n",
      "                                                                                                  \n",
      " time_distributed_5 (TimeDistri  (None, 10, 1, 512)  5416448     ['reshape_6[0][0]']              \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, None, 1, 7)   49          ['masking_54[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate_152 (Concatenate)  (None, None, 2)      0           ['masking_55[0][0]',             \n",
      "                                                                  'masking_56[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, None, 1, 5)   15          ['masking_57[0][0]']             \n",
      "                                                                                                  \n",
      " input_61 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_62 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_63 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_64 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_65 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_66 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_67 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_68 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_69 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_70 (InputLayer)          [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 10, 512)      0           ['time_distributed_5[0][0]']     \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, None, 7)     0           ['embedding_4[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, None, 20)     60          ['concatenate_152[0][0]']        \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, None, 5)     0           ['embedding_5[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " tf.expand_dims_59 (TFOpLambda)  (None, None, 1)     0           ['input_61[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_60 (TFOpLambda)  (None, None, 1)     0           ['input_62[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_61 (TFOpLambda)  (None, None, 1)     0           ['input_63[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_62 (TFOpLambda)  (None, None, 1)     0           ['input_64[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_63 (TFOpLambda)  (None, None, 1)     0           ['input_65[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_64 (TFOpLambda)  (None, None, 1)     0           ['input_66[0][0]']               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tf.expand_dims_65 (TFOpLambda)  (None, None, 1)     0           ['input_67[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_66 (TFOpLambda)  (None, None, 1)     0           ['input_68[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_67 (TFOpLambda)  (None, None, 1)     0           ['input_69[0][0]']               \n",
      "                                                                                                  \n",
      " tf.expand_dims_68 (TFOpLambda)  (None, None, 1)     0           ['input_70[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_153 (Concatenate)  (None, None, 32)     0           ['time_distributed_3[0][0]',     \n",
      "                                                                  'dense_2[0][0]',                \n",
      "                                                                  'time_distributed_4[0][0]']     \n",
      "                                                                                                  \n",
      " masking_58 (Masking)           (None, None, 1)      0           ['tf.expand_dims_59[0][0]']      \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10, 33)       16929       ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " masking_59 (Masking)           (None, None, 1)      0           ['tf.expand_dims_60[0][0]']      \n",
      "                                                                                                  \n",
      " masking_60 (Masking)           (None, None, 1)      0           ['tf.expand_dims_61[0][0]']      \n",
      "                                                                                                  \n",
      " masking_61 (Masking)           (None, None, 1)      0           ['tf.expand_dims_62[0][0]']      \n",
      "                                                                                                  \n",
      " masking_62 (Masking)           (None, None, 1)      0           ['tf.expand_dims_63[0][0]']      \n",
      "                                                                                                  \n",
      " masking_63 (Masking)           (None, None, 1)      0           ['tf.expand_dims_64[0][0]']      \n",
      "                                                                                                  \n",
      " masking_64 (Masking)           (None, None, 1)      0           ['tf.expand_dims_65[0][0]']      \n",
      "                                                                                                  \n",
      " masking_65 (Masking)           (None, None, 1)      0           ['tf.expand_dims_66[0][0]']      \n",
      "                                                                                                  \n",
      " masking_66 (Masking)           (None, None, 1)      0           ['tf.expand_dims_67[0][0]']      \n",
      "                                                                                                  \n",
      " masking_67 (Masking)           (None, None, 1)      0           ['tf.expand_dims_68[0][0]']      \n",
      "                                                                                                  \n",
      " concatenate_154 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_58[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_152 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_155 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_59[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_153 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_156 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_60[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_154 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_157 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_61[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_155 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_158 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_62[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_156 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_159 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_63[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_157 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_160 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_64[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_158 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_161 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_65[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_159 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_162 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'masking_66[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_160 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " concatenate_163 (Concatenate)  (None, None, 33)     0           ['concatenate_153[0][0]',        \n",
      "                                                                  'masking_67[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_161 (  (None, 33)          0           ['dense_3[0][0]']                \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_151 (  (None, 512)         0           ['reshape_7[0][0]']              \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " add_150 (Add)                  (None, None, 33)     0           ['concatenate_154[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_152[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_151 (Add)                  (None, None, 33)     0           ['concatenate_155[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_153[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_152 (Add)                  (None, None, 33)     0           ['concatenate_156[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_154[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_153 (Add)                  (None, None, 33)     0           ['concatenate_157[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_155[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_154 (Add)                  (None, None, 33)     0           ['concatenate_158[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_156[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_155 (Add)                  (None, None, 33)     0           ['concatenate_159[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_157[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_156 (Add)                  (None, None, 33)     0           ['concatenate_160[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_158[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_157 (Add)                  (None, None, 33)     0           ['concatenate_161[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_159[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_158 (Add)                  (None, None, 33)     0           ['concatenate_162[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_160[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " add_159 (Add)                  (None, None, 33)     0           ['concatenate_163[0][0]',        \n",
      "                                                                  'tf.__operators__.getitem_161[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " tf.expand_dims_69 (TFOpLambda)  (None, 1, 512)      0           ['tf.__operators__.getitem_151[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)                  (None, None, 16)     3200        ['add_150[0][0]',                \n",
      "                                                                  'add_151[0][0]',                \n",
      "                                                                  'add_152[0][0]',                \n",
      "                                                                  'add_153[0][0]',                \n",
      "                                                                  'add_154[0][0]',                \n",
      "                                                                  'add_155[0][0]',                \n",
      "                                                                  'add_156[0][0]',                \n",
      "                                                                  'add_157[0][0]',                \n",
      "                                                                  'add_158[0][0]',                \n",
      "                                                                  'add_159[0][0]']                \n",
      "                                                                                                  \n",
      " permute_2 (Permute)            (None, 512, 1)       0           ['tf.expand_dims_69[0][0]']      \n",
      "                                                                                                  \n",
      " gru_3 (GRU)                    (None, None, 16)     1632        ['lstm_3[0][0]',                 \n",
      "                                                                  'lstm_3[1][0]',                 \n",
      "                                                                  'lstm_3[2][0]',                 \n",
      "                                                                  'lstm_3[3][0]',                 \n",
      "                                                                  'lstm_3[4][0]',                 \n",
      "                                                                  'lstm_3[5][0]',                 \n",
      "                                                                  'lstm_3[6][0]',                 \n",
      "                                                                  'lstm_3[7][0]',                 \n",
      "                                                                  'lstm_3[8][0]',                 \n",
      "                                                                  'lstm_3[9][0]']                 \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_1 (TFOpLambda  (None, 10, 1)       0           ['reshape_7[0][0]',              \n",
      " )                                                                'permute_2[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " tf.expand_dims_70 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[0][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_71 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[1][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_72 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[2][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_73 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[3][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_74 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[4][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_75 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[5][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_76 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[6][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_77 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[7][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_78 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[8][0]']                  \n",
      "                                                                                                  \n",
      " tf.expand_dims_79 (TFOpLambda)  (None, None, 1, 16)  0          ['gru_3[9][0]']                  \n",
      "                                                                                                  \n",
      " permute_3 (Permute)            (None, 1, 10)        0           ['tf.linalg.matmul_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_164 (Concatenate)  (None, None, 10, 16  0           ['tf.expand_dims_70[0][0]',      \n",
      "                                )                                 'tf.expand_dims_71[0][0]',      \n",
      "                                                                  'tf.expand_dims_72[0][0]',      \n",
      "                                                                  'tf.expand_dims_73[0][0]',      \n",
      "                                                                  'tf.expand_dims_74[0][0]',      \n",
      "                                                                  'tf.expand_dims_75[0][0]',      \n",
      "                                                                  'tf.expand_dims_76[0][0]',      \n",
      "                                                                  'tf.expand_dims_77[0][0]',      \n",
      "                                                                  'tf.expand_dims_78[0][0]',      \n",
      "                                                                  'tf.expand_dims_79[0][0]']      \n",
      "                                                                                                  \n",
      " tf.nn.softmax_1 (TFOpLambda)   (None, 1, 10)        0           ['permute_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TFOpLa  (None, None, 10, 16  0          ['concatenate_164[0][0]']        \n",
      " mbda)                          )                                                                 \n",
      "                                                                                                  \n",
      " tf.linalg.matmul_2 (TFOpLambda  (None, None, 1, 16)  0          ['tf.nn.softmax_1[0][0]',        \n",
      " )                                                                'tf.compat.v1.transpose[0][0]'] \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose_1 (TFOp  (None, None, 1, 16)  0          ['tf.linalg.matmul_2[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, None, 16)    0           ['tf.compat.v1.transpose_1[0][0]'\n",
      " buted)                                                          ]                                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, None, 8)      800         ['time_distributed_6[0][0]']     \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, None, 8)     16          ['lstm_4[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " permute_4 (Permute)            (None, 8, None)      0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, None)        0           ['permute_4[0][0]']              \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,439,149\n",
      "Trainable params: 5,439,149\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.Model(inputs,x)\n",
    "#model(numbers[:-1])\n",
    "model.compile(optimizer=\"adam\",loss=\"mae\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0962b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers=get_numbers(exmple.numpy())\n",
    "x=numbers[:-1]\n",
    "y=numbers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cfc94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  5/331 [..............................] - ETA: 14:51 - loss: 0.9637"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nValueError: high <= 0\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 812, in wrapped_func\n    out = func(*structured_inp)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/3836857378.py\", line 3, in get_numbers\n    base=[sample_seq(x) for x in v]\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/3836857378.py\", line 3, in <listcomp>\n    base=[sample_seq(x) for x in v]\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/1607689951.py\", line 6, in sample_seq\n    start=np.random.randint(l-LEN)\n\n  File \"mtrand.pyx\", line 746, in numpy.random.mtrand.RandomState.randint\n\n  File \"_bounded_integers.pyx\", line 1338, in numpy.random._bounded_integers._rand_int32\n\nValueError: high <= 0\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_552931]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1408/2279769933.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nValueError: high <= 0\nTraceback (most recent call last):\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 153, in _call\n    ret = self._func(*args)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 812, in wrapped_func\n    out = func(*structured_inp)\n\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 642, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/3836857378.py\", line 3, in get_numbers\n    base=[sample_seq(x) for x in v]\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/3836857378.py\", line 3, in <listcomp>\n    base=[sample_seq(x) for x in v]\n\n  File \"C:\\Users\\Owner\\AppData\\Local\\Temp/ipykernel_1408/1607689951.py\", line 6, in sample_seq\n    start=np.random.randint(l-LEN)\n\n  File \"mtrand.pyx\", line 746, in numpy.random.mtrand.RandomState.randint\n\n  File \"_bounded_integers.pyx\", line 1338, in numpy.random._bounded_integers._rand_int32\n\nValueError: high <= 0\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_552931]"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed0a38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=train_dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "509b31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_3\" expects 15 input(s), but it received 16 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 99) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(32, 99) dtype=int32>, <tf.Tensor 'IteratorGetNext:4' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:5' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:7' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:8' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:9' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:10' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:11' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:12' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:13' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:14' shape=(32, 10) dtype=string>, <tf.Tensor 'IteratorGetNext:15' shape=(32, 99) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1408/3691018149.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0merror_maker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_maker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2142\u001b[0m                                                     class_weight)\n\u001b[0;32m   2143\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2144\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mstep_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[0;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mrun_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m         \u001b[1;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;31m# Run forward pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m       \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\u001b[0m\u001b[0;32m    201\u001b[0m                      \u001b[1;34mf' but it received {len(inputs)} input tensors. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                      f'Inputs received: {inputs}')\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_3\" expects 15 input(s), but it received 16 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(32, 99) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:2' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:3' shape=(32, 99) dtype=int32>, <tf.Tensor 'IteratorGetNext:4' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:5' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:6' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:7' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:8' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:9' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:10' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:11' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:12' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:13' shape=(32, 99) dtype=float32>, <tf.Tensor 'IteratorGetNext:14' shape=(32, 10) dtype=string>, <tf.Tensor 'IteratorGetNext:15' shape=(32, 99) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_dataset)):\n",
    "    print(i)\n",
    "    error_maker=d.next()\n",
    "    model.train_on_batch(error_maker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f9585365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01655307,  0.01655307,  0.01752678, ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [ 0.90534258,  0.91476835,  0.8695248 , ...,  1.08437055,\n",
       "         1.12746121,  1.13124944],\n",
       "       [ 1.0442689 ,  1.04242881,  1.05520076, ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       ...,\n",
       "       [ 1.17322823,  1.16866311,  1.17532058, ...,  1.0404602 ,\n",
       "         1.02448238,  1.06423671],\n",
       "       [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ],\n",
       "       [-1.        , -1.        , -1.        , ..., -1.        ,\n",
       "        -1.        , -1.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(error_maker[1])\n",
    "error_maker[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1341450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25e0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
